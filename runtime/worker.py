import time
import json
import logging
import redis
from config import Config
from core.stores.qdrant_store import QdrantStore
from core.managers.etl_manager import ETLManager
from loader import load_enterprise_plugins
import core.connectors.file

logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger("ETL-Worker")

def run_worker():
    # 1. åŠ è½½ä¼ä¸šæ’ä»¶ (ç¡®ä¿å›¾è°±èƒ½åŠ›è¢«æ¿€æ´»)
    load_enterprise_plugins()

    # 2. åˆå§‹åŒ–æ ¸å¿ƒç»„ä»¶
    qdrant = QdrantStore()
    # å°è¯•è¿æ¥ Nebula
    nebula = None
    if getattr(Config, "NEBULA_HOST", None):
        try:
            from enterprise.core.stores.graph_store import NebulaStore
            nebula = NebulaStore(Config)
        except:
            logger.warning("Worker running without Nebula support")

    etl_mgr = ETLManager(qdrant, nebula)

    # 3. è¿æ¥ Redis
    r = redis.Redis(host=Config.REDIS_HOST, port=Config.REDIS_PORT, password=getattr(Config, "REDIS_PASSWORD", None))
    try:
        r.ping()
        logger.info(f"âœ… Successful connection to Redis at {Config.REDIS_HOST}:{Config.REDIS_PORT}")
    except Exception as e:
        logger.error(f"âŒ Failed to connect to Redis: {e}")
        return
    queue_name = "chimera_etl_tasks"

    try:
        # å¼ºåˆ¶åœ¨è¿™é‡Œåˆå§‹åŒ– VLMï¼Œå¦‚æœæ˜¾å­˜ä¸å¤Ÿï¼Œè¿™é‡Œä¼šç›´æ¥æŠ¥é”™
        from skills.vlm_service import VLMService
        _ = VLMService.get_instance()
        logger.info("ğŸ¨ VLM è§†è§‰å¼•æ“å·²å°±ç»ª")
    except Exception as e:
        logger.error(f"âŒ VLM åˆå§‹åŒ–å¤±è´¥ï¼ŒWorker åœæ­¢: {e}")
        return # ğŸ‘ˆ å…³é”®ï¼šå¤±è´¥å°±åœæ­¢ï¼Œä¸è¦ç©ºè½¬

    logger.info(f"ğŸ”¥ ETL Worker is ready, listening on queue: {queue_name}")

    while True:
        try:
            # 4. é˜»å¡å¼å¼¹å‡ºä»»åŠ¡ (BLPOP)
            _, task_json = r.blpop(queue_name)
            task = json.loads(task_json)

            ds_id = task['ds_id']
            logger.info(f"ğŸš€ [Worker] Received task for DS:{ds_id}")

            # 5. æ‰§è¡ŒåŒæ­¥ä»»åŠ¡ (Manager ç°åœ¨æ˜¯ç”Ÿæˆå™¨)
            iterator = etl_mgr.sync_datasource(
                kb_id=task['kb_id'],
                source_id=ds_id,
                source_type=task['type'],
                config_json=task['config_json']
            )

            # æ¶ˆè´¹ç”Ÿæˆå™¨ï¼Œæ‰§è¡ŒåŒæ­¥
            for progress in iterator:
                # åç»­å¯åœ¨æ­¤æ›´æ–°ä»»åŠ¡è¿›åº¦åˆ° Redis
                pass

            logger.info(f"âœ… [Worker] Task completed for DS:{ds_id}")

        except Exception as e:
            logger.error(f"âŒ [Worker] Error processing task: {e}")
            time.sleep(2)

if __name__ == "__main__":
    run_worker()