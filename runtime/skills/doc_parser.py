import logging
import io
import uuid
import os
import hashlib
from pathlib import Path
from typing import List, Dict, Any

from docling.document_converter import DocumentConverter, PdfFormatOption
from docling.datamodel.base_models import InputFormat
from docling.datamodel.pipeline_options import PdfPipelineOptions
from docling.datamodel.document import DocumentStream
from docling.chunking import HybridChunker
from docling_core.types.doc import DocItemLabel

logger = logging.getLogger(__name__)

class DoclingParser:
    _converter = None
    _chunker = None

    @classmethod
    def _get_components(cls):
        if cls._converter is None:
            logger.info("ğŸ¢ [Init] å¯åŠ¨ Docling v2 é«˜å…¼å®¹æ€§æ¨¡å¼...")
            pipeline_options = PdfPipelineOptions()
            pipeline_options.do_ocr = True
            pipeline_options.do_table_structure = True

            # å¼€å¯å›¾ç‰‡è¯†åˆ«
            pipeline_options.generate_picture_images = True
            pipeline_options.images_scale = 2.0

            cls._converter = DocumentConverter(
                format_options={
                    InputFormat.PDF: PdfFormatOption(pipeline_options=pipeline_options)
                }
            )

            cls._chunker = HybridChunker(
                tokenizer="sentence-transformers/all-MiniLM-L6-v2",
                max_tokens=512,
                merge_peers=True,
            )
        return cls._converter, cls._chunker

    @staticmethod
    def parse_and_chunk(file_source, filename="temp.pdf") -> List[Dict[str, Any]]:
        converter, chunker = DoclingParser._get_components()

        try:
            if isinstance(file_source, bytes):
                input_doc = DocumentStream(name=filename, stream=io.BytesIO(file_source))
            else:
                input_doc = Path(file_source)

            # 1. æ‰§è¡Œè½¬æ¢
            conv_result = converter.convert(input_doc)

            # 2. ğŸ”¥ æ ¸å¿ƒä¿®æ­£ï¼šä½¿ç”¨ Markdown å¯¼å‡ºä½œä¸ºå†…å®¹åŸºå‡†
            # è¿™æ˜¯é¿å¼€â€œå…ƒç´ æ•°é‡ä¸º1â€ Bug çš„æœ€å¼ºæ‰‹æ®µ
            markdown_content = conv_result.document.export_to_markdown()

            if not markdown_content or len(markdown_content.strip()) < 5:
                logger.error("âŒ æ–‡æ¡£å†…å®¹æå–å¤±è´¥ï¼ˆMarkdown ä¸ºç©ºï¼‰")
                return []

            logger.info(f"ğŸ“ [Docling] æˆåŠŸæå–æ–‡æœ¬å†…å®¹ï¼Œé•¿åº¦: {len(markdown_content)} å­—ç¬¦")

            # 3. ä½¿ç”¨ HybridChunker è¿›è¡Œåˆ‡åˆ†
            # æ³¨æ„ï¼šåœ¨æŸäº› Docling ç‰ˆæœ¬ä¸‹ï¼Œchunker.chunk å¯ä»¥ç›´æ¥æ¥æ”¶ doc å¯¹è±¡
            chunk_iter = chunker.chunk(conv_result.document)
            final_chunks = []

            for i, chunk in enumerate(chunk_iter):
                # å°è¯•å®šä½å›¾ç‰‡
                image_path = None
                is_table = False
                page_num = 1

                # å¤„ç†å›¾ç‰‡è·¯å¾„ (Task 2.2)
                if chunk.meta.doc_items:
                    for item in chunk.meta.doc_items:
                        if item.label == DocItemLabel.TABLE:
                            is_table = True
                            try:
                                # å°è¯•è·å–è¡¨æ ¼å›¾ç‰‡
                                image_obj = conv_result.document.get_image(item)
                                if image_obj:
                                    img_id = str(uuid.uuid4())[:8]
                                    image_path = f"/tmp/chimera_table_{img_id}.jpg"
                                    image_obj.save(image_path)

                                    # ğŸ’¡ å…³é”®ï¼šå‘ä¸Šå›æº¯å¯»æ‰¾â€œTable xâ€å­—æ ·
                                    # è¿™é‡Œæˆ‘ä»¬å¯ä»¥ç®€å•åœ°æŠŠå½“å‰ chunk çš„ textï¼ˆé€šå¸¸åŒ…å«æ ‡é¢˜ï¼‰ä½œä¸º context
                                    logger.info(f"ğŸ“¸ [Table-Found] é”å®šè¡¨æ ¼ï¼Œå‡†å¤‡è§†è§‰è½¬å½•...")
                            except: pass
                            break
                        if item.label == DocItemLabel.PICTURE:
                            try:
                                img_id = str(uuid.uuid4())[:8]
                                temp_img = f"/tmp/chimera_img_{img_id}.jpg"
                                image_obj = conv_result.document.get_image(item)
                                if image_obj:
                                    image_obj.save(temp_img)
                                    image_path = temp_img
                                    logger.info(f"ğŸ“¸ æ•æ‰åˆ°åˆ‡ç‰‡å…³è”æ’å›¾: {temp_img}")
                                    break
                            except: pass

                # æå–å“ˆå¸Œ
                c_hash = hashlib.md5(chunk.text.encode()).hexdigest()

                final_chunks.append({
                    "content": chunk.text,
                    "metadata": {
                        "content_hash": c_hash,
                        "image_path": image_path,
                        "page_number": 1, # é»˜è®¤ 1ï¼Œå¦‚æœæœ‰ prov åˆ™åœ¨ä¸‹é¢è¦†ç›–
                        "breadcrumb": "",
                        "file_name": filename
                    }
                })

            # 4. ğŸ”¥ æœ€ç»ˆè¡¥å¿é€»è¾‘ï¼šå¦‚æœ Chunker ä¾ç„¶è¿”å› 0
            if not final_chunks and len(markdown_content) > 10:
                logger.warning("âš ï¸ Chunker æ— æ³•è¯†åˆ«æ–‡æ¡£ç»“æ„ï¼Œæ‰§è¡Œæµå¼è¡¥å¿åˆ‡åˆ†...")
                # ç®€å•æŒ‰é•¿åº¦åˆ‡åˆ†ï¼Œä¿è¯ç³»ç»Ÿä¸ç©ºè½¬
                text = markdown_content
                step = 1000
                for j in range(0, len(text), step):
                    sub_text = text[j:j+step]
                    final_chunks.append({
                        "content": sub_text,
                        "metadata": {
                            "content_hash": hashlib.md5(sub_text.encode()).hexdigest(),
                            "file_name": filename
                        }
                    })

            logger.info(f"âœ‚ï¸ [Tree-T] è§£æå®Œæ¯•ï¼Œæœ€ç»ˆäº§å‡º {len(final_chunks)} ä¸ªåˆ‡ç‰‡")
            return final_chunks

        except Exception as e:
            logger.error(f"âŒ [Docling] ä¸¥é‡å´©æºƒ: {e}", exc_info=True)
            return []

    @staticmethod
    def _table_to_propositions(table_item, doc) -> tuple[str, str]:
        """
        è¿”å›: (ç»“æ„åŒ–æ–‡æœ¬, ä¸´æ—¶æˆªå›¾è·¯å¾„)
        """
        table_text = ""
        temp_img_path = None

        try:
            df = table_item.export_to_dataframe(doc)
            if df is None or df.empty:
                # å‘½é¢˜åŒ–é€»è¾‘...
                table_text = "...(æ­¤å¤„çœç•¥ä¹‹å‰å†™è¿‡çš„å‘½é¢˜é€»è¾‘)..."
        except:
            pass

        # 2. å¼ºåˆ¶å¤‡ä»½ï¼šä¸ç®¡ç»“æ„åŒ–æˆä¸æˆåŠŸï¼Œéƒ½ç»™è¡¨æ ¼å­˜ä¸€å¼ å›¾
        # å¾ˆå¤šæ—¶å€™ç»“æ„åŒ–ä¼šä¸¢æ‰åˆå¹¶å•å…ƒæ ¼çš„ä¿¡æ¯ï¼ŒVLM èƒ½è¡¥å…¨
        try:
            img_id = str(uuid.uuid4())[:8]
            temp_img_path = f"/tmp/chimera_table_{img_id}.jpg"
            image_obj = doc.get_image(table_item)
            if image_obj:
                image_obj.save(temp_img_path)
        except:
            pass

        return table_text, temp_img_path