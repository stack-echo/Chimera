This file is a merged representation of the entire codebase, combined into a single document by Repomix.

<file_summary>
This section contains a summary of this file.

<purpose>
This file contains a packed representation of the entire repository's contents.
It is designed to be easily consumable by AI systems for analysis, code review,
or other automated processes.
</purpose>

<file_format>
The content is organized as follows:
1. This summary section
2. Repository information
3. Directory structure
4. Repository files (if enabled)
5. Multiple file entries, each consisting of:
  - File path as an attribute
  - Full contents of the file
</file_format>

<usage_guidelines>
- This file should be treated as read-only. Any changes should be made to the
  original repository files, not this packed version.
- When processing this file, use the file path to distinguish
  between different files in the repository.
- Be aware that this file may contain sensitive information. Handle it with
  the same level of security as you would the original repository.
</usage_guidelines>

<notes>
- Some files may have been excluded based on .gitignore rules and Repomix's configuration
- Binary files are not included in this packed representation. Please refer to the Repository Structure section for a complete list of file paths, including binary files
- Files matching patterns in .gitignore are excluded
- Files matching default ignore patterns are excluded
- Files are sorted by Git change count (files with more changes are at the bottom)
</notes>

</file_summary>

<directory_structure>
.vite/
  deps/
    _metadata.json
    package.json
api/
  runtime/
    v1/
      runtime.proto
deploy/
  docker-compose.yml
docs/
  architecture/
    architecture_v0.5.0.md
    architecture_v0.6.0.md
runtime/
  agents/
    chat/
      query_analysis.py
    kg/
      ner.py
      relation.py
      resolution.py
    __init__.py
    base.py
  core/
    connectors/
      __init__.py
      base.py
      file.py
    interfaces/
      __init__.py
    llm/
      __init__.py
      embedding.py
      extractor.py
      llm.py
    managers/
      __init__.py
      etl_manager.py
      inference_manager.py
    stores/
      minio_store.py
      qdrant_store.py
    telemetry/
      __init__.py
      exporter.py
      metrics.py
      tracing.py
    __init__.py
  memory/
    __init__.py
    episodic.py
    semantic.py
    shot-term.py
  prompts/
    chat/
      synthesis.yaml
    kg/
      ner.yaml
      relation.yaml
      resolution.yaml
  rpc/
    api/
      runtime/
        v1/
          runtime_pb2_grpc.py
          runtime_pb2.py
    __init__.py
    runtime_pb2_grpc.py
    runtime_pb2.py
  runtime/
    __init__.py
    state.py
  service/
    __init__.py
    runtime_service.py
  skills/
    __init__.py
    graph_ops.py
    graph_skill.py
    splitter.py
  tools/
    __init__.py
    doc_parser.py
    image_parser.py
  workflows/
    __init__.py
    chat_flow.py
  __init__.py
  .dockerignore
  config.py
  Dockerfile
  Dockerfile.ee
  loader.py
  main.py
  requirements.txt
scripts/
  dev_infra.sh
  dev_setup.sh
  install_plugins.sh
server/
  api/
    runtime/
      v1/
        runtime_grpc.pb.go
        runtime.pb.go
  cmd/
    server/
      main.go
    test_client/
      main.go
  internal/
    biz/
      dto.go
    bootstrap/
      boot.go
    conf/
      config.go
    core/
      datasource.go
    data/
      data.go
      queue.go
      storage.go
    dto/
      auth_dto.go
      chat_dto.go
      datasource_dto.go
      file_dto.go
      kb_dto.go
      log_dto.go
      org_dto.go
    handler/
      auth_handler.go
      chat_handler.go
      datasource_handler.go
      file_handler.go
      kb_handler.go
      log_handler.go
      org_handler.go
    middleware/
      jwt.go
    model/
      application.go
      base.go
      datasource.go
      knowledge_base.go
      organization.go
      run_log.go
      user.go
    repository/
      user_repo.go
    service/
      adapter.go
      auth_service.go
      chat_service.go
      datasource_service.go
      kb_service.go
      log_service.go
      org_service.go
    utils/
      jwt.go
      password.go
  Dockerfile
  Dockerfile.ee
  main.go
test/
  test_pb2.py
  test.pb.go
  test.proto
web/
  public/
    vite.svg
  src/
    api/
      insight.js
      request.js
    assets/
      vue.svg
    router/
      index.js
    store/
      user.js
    views/
      AdminDashboard.vue
      Home.vue
      Insights.vue
      Login.vue
      Register.vue
    App.vue
    main.js
  .gitignore
  Dockerfile
  index.html
  nginx.conf
  package.json
  README.md
  vite.config.js
.gitignore
go.mod
LICENSE
Makefile
README_EN.md
README.md
</directory_structure>

<files>
This section contains the contents of the repository's files.

<file path=".vite/deps/_metadata.json">
{
  "hash": "088d753e",
  "configHash": "ff9b072e",
  "lockfileHash": "e3b0c442",
  "browserHash": "7ec46956",
  "optimized": {},
  "chunks": {}
}
</file>

<file path=".vite/deps/package.json">
{
  "type": "module"
}
</file>

<file path="api/runtime/v1/runtime.proto">
syntax = "proto3";

package chimera.v1;

option go_package = "Chimera/server/api/runtime/v1;v1";

service RuntimeService {
  rpc RunAgent (RunAgentRequest) returns (stream RunAgentResponse) {}
  rpc SyncDataSource (SyncRequest) returns (SyncResponse) {}
}

// --- è¿è¡Œç›¸å…³ ---

message RunAgentRequest {
  string app_id = 1;
  string query = 2;
  string session_id = 3;
  string app_config_json = 4;
  repeated Message history = 5;
}

message Message {
  string role = 1;
  string content = 2;
}

message RunAgentResponse {
  // type: "thought" | "delta" | "reference" | "error" | "summary"
  string type = 1;
  string payload = 2;
  AgentMeta meta = 3;

  // ğŸ”¥ æ–°å¢ï¼šæ‰§è¡Œæ‘˜è¦ (ä»…åœ¨ type="summary" æ—¶å­˜åœ¨ï¼Œä¸”ä½œä¸ºæµçš„æœ€åä¸€å¸§)
  RunSummary summary = 4;
}

message AgentMeta {
  string node_name = 1;
  string trace_id = 2;
  int64 duration_ms = 3;
}

// ğŸ”¥ æ–°å¢ï¼šç»Ÿè®¡æ•°æ®ç»“æ„
message RunSummary {
  int32 total_tokens = 1;
  int32 prompt_tokens = 2;
  int32 completion_tokens = 3;
  int64 total_duration_ms = 4; // Python ä¾§è®¡ç®—çš„æ€»è€—æ—¶
  string final_status = 5;     // "success" | "failed"
}

// --- ETL ç›¸å…³ (ä¿æŒä¸å˜) ---
message SyncRequest {
  int64 kb_id = 1;
  int64 datasource_id = 2;
  string type = 3;
  string config_json = 4;
}

message SyncResponse {
  bool success = 1;
  string error_msg = 2;
  int32 chunks_count = 3;
  int32 page_count = 4;
}
</file>

<file path="docs/architecture/architecture_v0.5.0.md">
å¥½çš„ï¼ŒåŸºäºæˆ‘ä»¬åˆšæ‰çš„è®¨è®ºï¼Œæˆ‘å·²ç»å¯¹ **Chimera-RAG v0.5.0 æ¶æ„ç™½çš®ä¹¦** è¿›è¡Œäº†å…¨é¢æ›´æ–°ã€‚

ä¸»è¦å˜æ›´ç‚¹ï¼š
1.  **é¢†åŸŸæ¨¡å‹**ï¼šæ­£å¼çº³å…¥ **User** å’Œ **OrganizationMember**ï¼Œæ˜ç¡®äº†å¤šç§Ÿæˆ·ä¸‹çš„ç”¨æˆ·å½’å±å…³ç³»ã€‚
2.  **é€šä¿¡åè®®**ï¼šæ›´æ–° `runtime.proto` å®šä¹‰ï¼Œå¢åŠ äº† **`RunSummary`** æ¶ˆæ¯ä»¥æ”¯æŒä¸šåŠ¡ç›‘æ§æ•°æ®å›ä¼ ã€‚
3.  **å¼€å‘è·¯çº¿å›¾**ï¼šæ˜ç¡®äº†ç›‘æ§ä¸­å°çš„ **â€œv0.5.0 å­˜æ•°æ®ï¼Œv0.6.0 åšå±•ç¤ºâ€** çš„åˆ†æœŸç­–ç•¥ã€‚

---

# ğŸ¦„ Chimera-RAG v0.5.0 æŠ€æœ¯æ¶æ„ç™½çš®ä¹¦

> **ç‰ˆæœ¬**: v0.5.0 (Platform Era)  
> **æ ¸å¿ƒå®šä½**: é¢å‘ä¼ä¸šçš„å¯è§‚æµ‹å¤šæ™ºèƒ½ä½“ PaaS å¹³å°  
> **æœ€åæ›´æ–°**: 2025-12-30

---

## 1. æ ¸å¿ƒæ„¿æ™¯ (Vision)

Chimera ä»å•ä¸€ RAG å·¥å…·è½¬å‹ä¸º **AI åŸºç¡€è®¾æ–½å¹³å°**ã€‚
æ ¸å¿ƒå·®å¼‚åŒ–å–ç‚¹ï¼š
1.  **å…¨é“¾è·¯å¯è§‚æµ‹æ€§ (Observability)**ï¼šä¸ä»…ä»…ç›‘æ§æœåŠ¡å™¨çŠ¶æ€ï¼Œæ›´è¦ç›‘æ§æ™ºèƒ½ä½“çš„â€œæ€è€ƒè·¯å¾„â€ã€Token æ¶ˆè€—ä¸æ¨ç†è€—æ—¶ã€‚
2.  **èµ„æºè§£è€¦ (Decoupling)**ï¼šå®ç°â€œåº”ç”¨â€ä¸â€œçŸ¥è¯†â€çš„åˆ†ç¦»ã€‚çŸ¥è¯†åº“ä½œä¸ºåº•å±‚èµ„äº§ï¼Œå¯è¢«å¤šä¸ªåº”ç”¨å¤ç”¨ã€‚
3.  **å¤šæ¨¡æ€ ETL**: æ”¯æŒ PDFã€é£ä¹¦ã€ç½‘é¡µç­‰å¤šç§æ•°æ®æºçš„ç»Ÿä¸€æ¥å…¥ã€‚

---

## 2. ç³»ç»Ÿæ¶æ„æ¦‚è§ˆ (System Architecture)

ç³»ç»Ÿé‡‡ç”¨ **åŒæ ¸åˆ†ç¦»æ¶æ„**ï¼ŒGo è´Ÿè´£ä¸šåŠ¡æ§åˆ¶ä¸æ•°æ®æŒä¹…åŒ–ï¼ŒPython è´Ÿè´£ AI æ ¸å¿ƒè®¡ç®—ã€‚

```mermaid
graph TD
    User[ç”¨æˆ·/å‰ç«¯] -->|HTTP/SSE| Gateway[Go æ§åˆ¶é¢]
    
    subgraph "Control Plane (Go)"
        Gateway --> Auth[é‰´æƒæ¨¡å—]
        Gateway --> Biz[ä¸šåŠ¡é€»è¾‘]
        Gateway --> LogMgr[ç›‘æ§æ—¥å¿—å…¥åº“]
    end
    
    subgraph "Inference Plane (Python)"
        Gateway -->|gRPC (Runtime)| Runtime[Python è¿è¡Œæ—¶]
        Runtime -->|LangGraph| Workflow[æ™ºèƒ½ä½“å·¥ä½œæµ]
        Runtime -->|Connectors| ETL[æ•°æ®æºåŒæ­¥]
    end
    
    subgraph "Storage Layer"
        PG[(PostgreSQL)] -->|ç”¨æˆ·/åº”ç”¨/æ—¥å¿—| Gateway
        MinIO[(MinIO)] -->|æ–‡ä»¶å­˜å‚¨| Runtime
        Qdrant[(Qdrant)] -->|å‘é‡ç´¢å¼•| Runtime
        Nebula[(NebulaGraph)] -->|çŸ¥è¯†å›¾è°±| Runtime
    end
    
    subgraph "Observability"
        Runtime -.->|OTel Trace| SigNoz[SigNoz (è¿ç»´å±‚)]
        Gateway -.->|Biz Logs| PG[Postgres (ä¸šåŠ¡å±‚)]
    end
```

---

## 3. æ ¸å¿ƒé¢†åŸŸæ¨¡å‹ (Domain Models)

ä¸ºäº†æ”¯æ’‘å¤šç§Ÿæˆ·ä¸æƒé™ç®¡ç†ï¼Œæˆ‘ä»¬å®šä¹‰äº†ä»¥ä¸‹å®ä½“å…³ç³»ã€‚

| æ¦‚å¿µ | è¯´æ˜ | å¯¹åº”å…³ç³» |
| :--- | :--- | :--- |
| **User (ç”¨æˆ·)** | ç³»ç»Ÿçš„ç™»å½•ä¸»ä½“ä¸æ“ä½œæ‰§è¡Œè€…ã€‚ | N:N Organization (é€šè¿‡ Memberè¡¨) |
| **Organization (ç»„ç»‡)** | ç§Ÿæˆ·è¾¹ç•Œã€‚èµ„æºï¼ˆåº”ç”¨ã€çŸ¥è¯†åº“ï¼‰çš„æ‰€æœ‰æƒå•ä½ã€‚ | 1:N User |
| **OrganizationMember (æˆå‘˜)** | **æ ¸å¿ƒå…³è”è¡¨**ã€‚å®šä¹‰ User åœ¨ Organization ä¸­çš„è§’è‰² (Owner/Admin/Member)ã€‚ | - |
| **Application (åº”ç”¨)** | ä¸šåŠ¡å…¥å£ã€‚ä¾‹å¦‚"HRåŠ©æ‰‹"ã€‚åŒ…å« Promptã€å…³è”çš„ KB IDã€‚ | N:N KnowledgeBase |
| **KnowledgeBase (çŸ¥è¯†åº“)** | é€»è¾‘å®¹å™¨ã€‚ä»…ä½œä¸ºæ ‡ç­¾å­˜åœ¨ï¼Œä¸ç›´æ¥å­˜æ•°æ®ã€‚ | 1:N DataSource |
| **DataSource (æ•°æ®æº)** | çœŸæ­£çš„æ•°æ®å®ä½“ã€‚å¯ä»¥æ˜¯æ–‡ä»¶ã€é£ä¹¦é“¾æ¥ã€‚ | 1:N Vectors |

---

## 4. å…³é”®åè®®ä¸æ•°æ®æµ (Protocols & Data Flow)

### 4.1 é€šä¿¡åè®® (`api/proto/runtime.proto`)

ä¸ºæ”¯æŒç›‘æ§æ•°æ®å›ä¼ ï¼Œåè®®è¿›è¡Œäº†é‡è¦å‡çº§ï¼š

*   **`RunAgent`**: é€šç”¨æ‰§è¡Œæ¥å£ã€‚
*   **`RunAgentResponse`**:
    *   `type="thought"`: æ€è€ƒè¿‡ç¨‹ (Thought Chain)ã€‚
    *   `type="delta"`: ç­”æ¡ˆç‰‡æ®µ (Token Stream)ã€‚
    *   `type="summary"`: **(æ–°å¢)** æ‰§è¡Œæ‘˜è¦ï¼ŒåŒ…å« Token ç»Ÿè®¡ã€æ€»è€—æ—¶ã€æœ€ç»ˆçŠ¶æ€ã€‚

```protobuf
message RunAgentResponse {
  string type = 1;      // "thought", "delta", "summary"
  string payload = 2;   // å†…å®¹
  AgentMeta meta = 3;   // OTel TraceID
  RunSummary summary = 4; // ä»…åœ¨ type="summary" æ—¶å­˜åœ¨
}

message RunSummary {
  int32 total_tokens = 1;
  int32 prompt_tokens = 2;
  int32 completion_tokens = 3;
  int64 total_duration_ms = 4;
}
```

### 4.2 æ™ºèƒ½ä½“è¿è¡Œé—­ç¯ (The Loop)

1.  **Go**: æ ¡éªŒç”¨æˆ·æƒé™ (`OrganizationMember`)ã€‚
2.  **Go**: æ„é€  `RunAgentRequest`ï¼Œæ³¨å…¥ `app_config` (å« KB IDs)ã€‚
3.  **Python**: æ‰§è¡Œ LangGraph å·¥ä½œæµã€‚
4.  **Python**:
    *   æµå¼è¿”å› `thought` å’Œ `delta`ã€‚
    *   **ç»“æŸæ—¶**: ç»Ÿè®¡ Token ç”¨é‡ï¼Œå‘é€ `type="summary"` æ¶ˆæ¯ã€‚
5.  **Go**:
    *   è½¬å‘ `thought`/`delta` ç»™å‰ç«¯ã€‚
    *   **æ‹¦æˆª `summary`**: å°† TraceIDã€Tokenã€è€—æ—¶ã€ç”¨æˆ·ID å†™å…¥ Postgres çš„ `app_run_logs` è¡¨ã€‚

---

## 5. ç›‘æ§ä¸­å°åˆ†æœŸç­–ç•¥ (Observability Strategy)

ç›‘æ§ä¸­å°æ¶‰åŠå…¨æ ˆå¼€å‘ï¼Œä¸ºé™ä½ v0.5.0 é£é™©ï¼Œé‡‡å– **â€œåç«¯å…ˆè¡Œï¼Œå‰ç«¯è·Ÿè¿›â€** çš„ç­–ç•¥ã€‚

### âœ… Phase 1: æ•°æ®è“„æ°´æœŸ (v0.5.0)
**ç›®æ ‡**ï¼šç¡®ä¿ä¸šåŠ¡ç›‘æ§æ•°æ®è¢«å®Œæ•´ç”Ÿäº§å¹¶æŒä¹…åŒ–ã€‚
*   **Python**: å®ç° Token è®¡æ•°å™¨ï¼Œåœ¨ gRPC ç»“æŸå¸§å›ä¼ ç»Ÿè®¡æ•°æ®ã€‚
*   **Go**: å»ºç«‹ `app_run_logs` è¡¨ï¼Œå®Œæˆæ—¥å¿—æ¸…æ´—ä¸å…¥åº“ã€‚
*   **SigNoz**: ç¡®ä¿ TraceID èƒ½å¤Ÿä¸²è” Go å’Œ Python çš„é“¾è·¯ã€‚
*   *æ­¤æ—¶æš‚æ— å‰ç«¯å›¾è¡¨ï¼Œæ•°æ®æ²‰æ·€åœ¨æ•°æ®åº“ä¸­ã€‚*

### ğŸ“… Phase 2: æ•°æ®å¯è§†åŒ–æœŸ (v0.6.0)
**ç›®æ ‡**ï¼šåŸºäºæ²‰æ·€çš„æ•°æ®æ„å»º `/admin/insights` é¢æ¿ã€‚
*   **Dashboard**: Token æ¶ˆè€—è¶‹åŠ¿å›¾ã€å¹³å‡å“åº”æ—¶é—´ã€æ´»è·ƒåº”ç”¨æ’è¡Œã€‚
*   **Trace View**: ç‚¹å‡»æŸæ¬¡å¯¹è¯ï¼Œå±•ç¤ºè¯¦ç»†çš„â€œç€‘å¸ƒæµâ€ä¸ Prompt è¯¦æƒ…ã€‚

---

## 6. å¼€å‘è§„èŒƒ (Guidelines)

### 6.1 Go (Control Plane)
*   **é‰´æƒä¼˜å…ˆ**: ä»»ä½•ä¸šåŠ¡æ“ä½œå‰ï¼Œå¿…é¡»å…ˆæŸ¥è¯¢ `OrganizationMember` ç¡®è®¤ç”¨æˆ·æƒé™ã€‚
*   **æ—¥å¿—å…¥åº“**: åœ¨ `StreamChat` å¾ªç¯ç»“æŸæ—¶ï¼Œå¿…é¡»ç¡®ä¿ `AppRunLog` å†™å…¥æˆåŠŸï¼Œè¿™æ˜¯è®¡è´¹å’Œå®¡è®¡çš„åŸºç¡€ã€‚

### 6.2 Python (Runtime)
*   **Token ç»Ÿè®¡**: åœ¨ `LLMClient` ä¸­å¿…é¡»å‡†ç¡®è·å– `usage` ä¿¡æ¯ã€‚
*   **æ— çŠ¶æ€**: ä¸è¦ä¾èµ– Python å†…å­˜å­˜ç”¨æˆ·çŠ¶æ€ï¼Œæ‰€æœ‰ä¸Šä¸‹æ–‡ä¾èµ– Redis æˆ– gRPC å…¥å‚ã€‚

### 6.3 å‰ç«¯ (Frontend)
*   **SSE è§£æ**: é¢„ç•™ JSON è§£æèƒ½åŠ›ã€‚
    *   å½“å‰: `THOUGHT: ...` (å­—ç¬¦ä¸²å‰ç¼€)
    *   æœªæ¥: `data: {"type": "thought", ...}` (JSON å¯¹è±¡)
*   **çŠ¶æ€åé¦ˆ**: çŸ¥è¯†åº“å¯¼å…¥æ˜¯å¼‚æ­¥çš„ï¼Œéœ€è½®è¯¢ `DataSource` çŠ¶æ€ (`pending` -> `active`/`error`)ã€‚

---

## 7. ç‰ˆæœ¬äº¤ä»˜æ¸…å• (Release Checklist)

### v0.5.0 (Current)
*   [x] æ ¸å¿ƒé‡æ„ï¼š`RuntimeService` å–ä»£ `RagService`ã€‚
*   [x] å­˜å‚¨å±‚ï¼šQdrant å‘é‡å­˜å‚¨å®ç°ã€‚
*   [ ] **åè®®å‡çº§**ï¼šæ·»åŠ  `RunSummary` åˆ° Proto å¹¶é‡æ–°ç”Ÿæˆã€‚
*   [ ] **æ•°æ®åŸ‹ç‚¹**ï¼šPython ç«¯å®ç° Token ç»Ÿè®¡ä¸å›ä¼ ã€‚
*   [ ] **æ—¥å¿—è½ç›˜**ï¼šGo ç«¯å®ç° `AppRunLog` è¡¨ä¸å†™å…¥é€»è¾‘ã€‚

### v0.6.0 (Next)
*   [ ] ç›‘æ§ä¸­å°å‰ç«¯ UI (`/admin/insights`)ã€‚
*   [ ] é£ä¹¦/é’‰é’‰è¿æ¥å™¨é›†æˆã€‚
*   [ ] NebulaGraph å›¾è°±æ„å»ºæµæ°´çº¿ã€‚

---

*æœ¬ç™½çš®ä¹¦ä½äºé¡¹ç›®æ ¹ç›®å½• `docs/architecture_v0.5.0.md`ï¼Œä½œä¸ºå›¢é˜Ÿåä½œçš„åŸºå‡†æ–‡æ¡£ã€‚*
</file>

<file path="runtime/agents/chat/query_analysis.py">
from typing import List
from agents.base import BaseAgent
from core.telemetry.tracing import trace_agent

class QueryAnalysisAgent(BaseAgent):
    def __init__(self):
        # æˆ‘ä»¬å¯ä»¥å¤ç”¨ kg/ner.yaml çš„ Promptï¼Œæˆ–è€…åˆ›å»ºä¸€ä¸ªæ›´é€šç”¨çš„
        # è¿™é‡Œæš‚æ—¶å¤ç”¨ ner çš„ Promptï¼Œå› ä¸ºå®ƒæœ¬èº«å°±æ˜¯æå–å®ä½“çš„
        super().__init__(agent_id="Query_Analysis_Expert", prompt_file="kg/ner.yaml")

    @trace_agent(agent_name="Query_Analysis_Expert")
    def run(self, query: str) -> List[str]:
        """
        ä»ç”¨æˆ· Query ä¸­æå–å…³é”®å®ä½“å
        """
        # å¤ç”¨ NER Agent çš„ Prompt é€»è¾‘
        result = self.ask_llm(input_vars={"text": query})

        entities = []
        if isinstance(result, dict) and "entities" in result:
            entities = result["entities"]
        elif isinstance(result, list):
            entities = result

        # æå–å®ä½“ååˆ—è¡¨
        entity_names = [e.get("name") for e in entities if isinstance(e, dict) and e.get("name")]

        return entity_names
</file>

<file path="runtime/agents/kg/ner.py">
from agents.base import BaseAgent
from core.telemetry.tracing import trace_agent

class NERAgent(BaseAgent):
    def __init__(self):
        # å¯¹åº” prompts/kg/ner.yaml
        super().__init__(agent_id="KG_NER_Expert", prompt_file="kg/ner.yaml")

    @trace_agent(agent_name="KG_NER_Expert")
    def run(self, text: str):
        # 1. è°ƒç”¨ LLM
        result = self.ask_llm(input_vars={"text": text})

        # 2. æ ¼å¼æ ¡éªŒ (Prompt å¯èƒ½è¿”å› {"entities": [...]})
        if isinstance(result, dict) and "entities" in result:
            return result["entities"]
        if isinstance(result, list):
            return result

        return []
</file>

<file path="runtime/agents/kg/relation.py">
import json
from agents.base import BaseAgent
from core.telemetry.tracing import trace_agent

class RelationAgent(BaseAgent):
    def __init__(self):
        super().__init__(agent_id="KG_Relation_Expert", prompt_file="kg/relation.yaml")

    @trace_agent(agent_name="KG_Relation_Expert")
    def run(self, text: str, entities: list):
        if not entities:
            return []

        # æå–çº¯å®ä½“ååˆ—è¡¨ï¼Œå‡å°‘ Token æ¶ˆè€—
        entity_names = [e.get("name") for e in entities if isinstance(e, dict) and e.get("name")]

        result = self.ask_llm(input_vars={
            "text": text,
            # å°†åˆ—è¡¨è½¬ä¸º JSON å­—ç¬¦ä¸²ä¼ å…¥æ¨¡æ¿
            "entities": json.dumps(entity_names, ensure_ascii=False)
        })

        return result if isinstance(result, list) else []
</file>

<file path="runtime/agents/kg/resolution.py">
import json
from agents.base import BaseAgent
from core.telemetry.tracing import trace_agent

class ResolutionAgent(BaseAgent):
    def __init__(self):
        super().__init__(agent_id="KG_Resolution_Expert", prompt_file="kg/resolution.yaml")

    @trace_agent(agent_name="KG_Resolution_Expert")
    def run(self, entities: list, relations: list):
        # æ„é€ ä¸Šä¸‹æ–‡æ•°æ®
        graph_data = {
            "entities": entities,
            "relations": relations
        }

        result = self.ask_llm(input_vars={
            "graph_data": json.dumps(graph_data, ensure_ascii=False)
        })

        # å¦‚æœ LLM æ¸…æ´—å¤±è´¥ï¼Œå…œåº•è¿”å›åŸå§‹æ•°æ®
        if not result:
            return {"entities": entities, "relations": relations}

        return result
</file>

<file path="runtime/agents/__init__.py">

</file>

<file path="runtime/agents/base.py">
import os
import yaml
import json
import re
import logging
from jinja2 import Template
from core.llm.llm import LLMClient
# å‡è®¾ trace_agent åœ¨è¿™é‡Œï¼Œæ ¹æ®ä½ çš„é¡¹ç›®ç»“æ„è°ƒæ•´
from core.telemetry.tracing import trace_agent

logger = logging.getLogger(__name__)

class BaseAgent:
    def __init__(self, agent_id: str, prompt_file: str):
        """
        :param agent_id: æ™ºèƒ½ä½“å”¯ä¸€æ ‡è¯† (ç”¨äºæ—¥å¿—/ç›‘æ§)
        :param prompt_file: æç¤ºè¯æ–‡ä»¶å (ç›¸å¯¹ prompts/ ç›®å½•)
        """
        self.agent_id = agent_id
        self.llm = LLMClient()

        # è·¯å¾„å¤„ç†ï¼šå…¼å®¹æœ¬åœ°è¿è¡Œå’Œ Docker
        base_dir = os.getcwd()
        if "chimera-agents-runtime" not in base_dir and os.path.exists("chimera-agents-runtime"):
            base_dir = os.path.join(base_dir, "chimera-agents-runtime")

        self.prompt_path = os.path.join(base_dir, "prompts", prompt_file)
        self.config = self._load_config()

    def _load_config(self):
        """ä» YAML åŠ è½½ Agent é…ç½®"""
        if not os.path.exists(self.prompt_path):
            raise FileNotFoundError(f"âŒ æœªæ‰¾åˆ°æç¤ºè¯æ–‡ä»¶: {self.prompt_path}")
        with open(self.prompt_path, 'r', encoding='utf-8') as f:
            return yaml.safe_load(f)

    def render_prompt(self, template_str: str, **kwargs):
        """ä½¿ç”¨ Jinja2 æ¸²æŸ“åŠ¨æ€æç¤ºè¯"""
        if not template_str:
            return ""
        return Template(template_str).render(**kwargs)

    def parse_json_safely(self, text: str):
        """
        é²æ£’çš„ JSON è§£æå™¨ï¼šè‡ªåŠ¨æ¸…æ´— Markdown æ ‡è®°
        """
        text = text.strip()
        try:
            # 1. å°è¯•ç›´æ¥è§£æ
            return json.loads(text)
        except json.JSONDecodeError:
            try:
                # 2. å°è¯•æå– ```json å—
                match = re.search(r"```json\s*(.*?)```", text, re.DOTALL)
                if match:
                    return json.loads(match.group(1))

                # 3. å°è¯•æå– [...] æˆ– {...}
                match = re.search(r"(\[.*\]|\{.*\})", text, re.DOTALL)
                if match:
                    return json.loads(match.group(1))

                raise ValueError("No JSON found")
            except Exception as e:
                logger.warning(f"âš ï¸ Agent [{self.agent_id}] JSON è§£æå¤±è´¥: {text[:50]}... Error: {e}")
                return [] # é»˜è®¤è¿”å›ç©ºåˆ—è¡¨ï¼Œé˜²æ­¢ Crash

    def ask_llm(self, input_vars: dict, response_format="json"):
        """
        é€šç”¨çš„ LLM è°ƒç”¨æ–¹æ³•
        :param input_vars: æ¸²æŸ“æ¨¡æ¿æ‰€éœ€çš„å˜é‡å­—å…¸
        """
        # 1. æ¸²æŸ“ System å’Œ User Prompt
        sys_tmpl = self.config.get("system", "")
        user_tmpl = self.config.get("user", "")

        sys_prompt = self.render_prompt(sys_tmpl, **input_vars)
        user_prompt = self.render_prompt(user_tmpl, **input_vars)

        # 2. è°ƒç”¨ LLM (å¤ç”¨ LLMClient)
        try:
            # è¿™é‡Œæˆ‘ä»¬ç›´æ¥ä½¿ç”¨ client.chat.completions ä»¥è·å¾—éæµå¼ç»“æœ
            # å¦‚æœ LLMClient å°è£…äº† ask() æ–¹æ³•æ›´å¥½ï¼Œè¿™é‡Œå‡è®¾ç›´æ¥è°ƒ client
            response = self.llm.client.chat.completions.create(
                model=self.llm.model_name,
                messages=[
                    {"role": "system", "content": sys_prompt},
                    {"role": "user", "content": user_prompt}
                ],
                temperature=0.1,
                response_format={"type": "json_object"} if response_format == "json" else None
            )
            content = response.choices[0].message.content

            # 3. è§£æç»“æœ
            if response_format == "json":
                return self.parse_json_safely(content)
            return content

        except Exception as e:
            logger.error(f"âŒ Agent [{self.agent_id}] LLM è°ƒç”¨å¼‚å¸¸: {e}")
            # è¿”å›ç©ºç»“æ„ä»¥ä¿è¯æµç¨‹ä¸ä¸­æ–­
            return [] if response_format == "json" else ""

    def run(self, *args, **kwargs):
        raise NotImplementedError("å­ç±»å¿…é¡»å®ç° run æ–¹æ³•")
</file>

<file path="runtime/core/connectors/__init__.py">

</file>

<file path="runtime/core/connectors/base.py">
from abc import ABC, abstractmethod
from typing import Iterator, Dict, Any, Type, Optional
from dataclasses import dataclass
import logging

logger = logging.getLogger(__name__)

@dataclass
class DocumentChunk:
    content: str
    metadata: Dict[str, Any]  # å¿…é¡»åŒ…å« source_id, kb_id

class BaseConnector(ABC):
    """
    æ‰€æœ‰æ•°æ®æºè¿æ¥å™¨çš„åŸºç±» (Core & Enterprise)
    """
    def __init__(self, kb_id: int, source_id: int, config: dict):
        self.kb_id = kb_id
        self.source_id = source_id
        self.config = config

    @abstractmethod
    def load(self) -> Iterator[DocumentChunk]:
        """
        ç”Ÿæˆå™¨ï¼šæµå¼è¿”å›æ–‡æ¡£åˆ‡ç‰‡ï¼Œé¿å…å†…å­˜çˆ†ç‚¸
        """
        pass

# ğŸ”¥ æ ¸å¿ƒé‡æ„ï¼šè¿æ¥å™¨å·¥å‚
class ConnectorFactory:
    _registry: Dict[str, Type[BaseConnector]] = {}

    @classmethod
    def register(cls, type_name: str, connector_cls: Type[BaseConnector]):
        """
        æ’ä»¶æ³¨å†Œå…¥å£ã€‚
        ä¾‹å¦‚: ConnectorFactory.register("feishu", FeishuConnector)
        """
        if type_name in cls._registry:
            logger.warning(f"ğŸ”Œ Connector '{type_name}' is being overwritten by {connector_cls.__name__}")
        else:
            logger.info(f"ğŸ”Œ Connector registered: '{type_name}' -> {connector_cls.__name__}")

        cls._registry[type_name] = connector_cls

    @classmethod
    def get_connector(cls, type_name: str) -> Optional[Type[BaseConnector]]:
        """
        è·å–è¿æ¥å™¨ç±»ã€‚å¦‚æœæœªæ³¨å†Œï¼ˆå¦‚ä¼ä¸šç‰ˆæœªåŠ è½½ï¼‰ï¼Œè¿”å› None
        """
        return cls._registry.get(type_name)

    @classmethod
    def list_available(cls):
        return list(cls._registry.keys())
</file>

<file path="runtime/core/connectors/file.py">
import os
import logging
from .base import BaseConnector, DocumentChunk, ConnectorFactory  # å¼•å…¥å·¥å‚
from tools.doc_parser import DoclingParser
from core.stores.minio_store import MinioStore

logger = logging.getLogger(__name__)

class FileConnector(BaseConnector):
    def __init__(self, kb_id, source_id, config):
        super().__init__(kb_id, source_id, config)
        # config ç¤ºä¾‹: {"storage_path": "kbs/1/xxx.pdf", "file_name": "manual.pdf"}
        self.storage_path = config.get("storage_path")
        self.file_name = config.get("file_name", "unknown.pdf")
        self.minio = MinioStore()

    def load(self):
        """
        æµç¨‹: MinIOä¸‹è½½ -> ä¸´æ—¶æ–‡ä»¶ -> Doclingè§£æ -> Yield Chunk
        """
        temp_path = f"/tmp/{self.file_name}"

        try:
            # 1. ä» MinIO ä¸‹è½½æ–‡ä»¶åˆ°æœ¬åœ°ä¸´æ—¶ç›®å½•
            logger.info(f"ğŸ“¥ [FileConnector] ä¸‹è½½æ–‡ä»¶: {self.storage_path}")
            data_bytes = self.minio.download_file(self.storage_path)

            with open(temp_path, "wb") as f:
                f.write(data_bytes)

            # 2. è°ƒç”¨ Docling è§£æ
            chunks = DoclingParser.parse_and_chunk(temp_path, self.file_name)

            # 3. è½¬æ¢ä¸ºæ ‡å‡† DocumentChunk å¹¶ Yield
            for chunk in chunks:
                yield DocumentChunk(
                    content=chunk["content"],
                    metadata={
                        "page_number": chunk["page"],
                        "file_name": self.file_name,
                        "file_path": self.storage_path,
                        "source": "file"
                    }
                )

        except Exception as e:
            logger.error(f"âŒ FileConnector Error: {e}")
            raise e
        finally:
            # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
            if os.path.exists(temp_path):
                os.remove(temp_path)

# ğŸ”¥ æ ¸å¿ƒé‡æ„ï¼šè‡ªåŠ¨æ³¨å†Œ
ConnectorFactory.register("file", FileConnector)
</file>

<file path="runtime/core/interfaces/__init__.py">

</file>

<file path="runtime/core/llm/__init__.py">

</file>

<file path="runtime/core/llm/embedding.py">
from sentence_transformers import SentenceTransformer
from config import Config
import logging

class EmbeddingModel:
    _instance = None

    @classmethod
    def get_instance(cls):
        if cls._instance is None:
            logging.info("ğŸ“¥ Loading Embedding Model...")
            try:
                # ç”Ÿäº§ç¯å¢ƒå¯ä»¥ç”¨ modelscope çš„ snapshot_download
                cls._instance = SentenceTransformer(Config.EMBEDDING_MODEL_NAME)
            except:
                cls._instance = SentenceTransformer('all-MiniLM-L6-v2')
            logging.info("âœ… Embedding Model Loaded")
        return cls._instance

    @staticmethod
    def encode(text: str):
        model = EmbeddingModel.get_instance()
        return model.encode(text).tolist()
</file>

<file path="runtime/core/llm/extractor.py">
import json
import logging
import re
import yaml
import os
from .llm import LLMClient
from jinja2 import Template

logger = logging.getLogger(__name__)

class KGExtractor:
    def __init__(self):
        self.llm = LLMClient()
        self._load_prompt()

    def _load_prompt(self):
        # åŠ è½½ yaml
        path = os.path.join(os.getcwd(), "prompts", "kg", "extraction.yaml")
        if not os.path.exists(path):
            raise FileNotFoundError(f"Prompt file not found: {path}")
        with open(path, "r", encoding="utf-8") as f:
            self.config = yaml.safe_load(f)

    def extract(self, text: str) -> list:
        """
        è¾“å…¥æ–‡æœ¬ï¼Œè¾“å‡ºä¸‰å…ƒç»„åˆ—è¡¨
        """
        if len(text) < 50:
            return []

        # 1. æ¸²æŸ“ Prompt
        sys_tmpl = Template(self.config["system"])
        user_tmpl = Template(self.config["user"])

        sys_prompt = sys_tmpl.render()
        user_prompt = user_tmpl.render(text_chunk=text)

        # 2. è°ƒç”¨ LLM (éæµå¼ï¼Œç›´æ¥æ‹¿ç»“æœ)
        # æˆ‘ä»¬éœ€è¦åœ¨ LLMClient å¢åŠ ä¸€ä¸ªéæµå¼æ–¹æ³• ask()ï¼Œæˆ–è€…ç”¨ stream æ‹¼å‡‘
        # è¿™é‡Œå‡è®¾ LLMClient æœ‰ä¸€ä¸ª ask æ–¹æ³•ï¼Œæˆ–è€…æˆ‘ä»¬æ‰‹åŠ¨è°ƒç”¨ client
        try:
            # ä¸´æ—¶ç›´æ¥è°ƒç”¨ openai clientï¼Œåç»­å»ºè®®å°è£…è¿› LLMClient.ask()
            response = self.llm.client.chat.completions.create(
                model=self.llm.model_name,
                messages=[
                    {"role": "system", "content": sys_prompt},
                    {"role": "user", "content": user_prompt}
                ],
                temperature=0.1, # ä½æ¸©åº¦ä¿è¯æ ¼å¼ç¨³å®š
                response_format={"type": "json_object"} # å¦‚æœæ¨¡å‹æ”¯æŒ JSON æ¨¡å¼æœ€å¥½
            )
            content = response.choices[0].message.content
            return self._parse_json(content)

        except Exception as e:
            logger.error(f"KG Extraction Failed: {e}")
            return []

    def _parse_json(self, text: str):
        """é²æ£’çš„ JSON è§£æ"""
        try:
            # 1. å°è¯•ç›´æ¥è§£æ
            return json.loads(text)
        except:
            # 2. å°è¯•æå– ```json ... ```
            match = re.search(r"```json\s*(.*?)```", text, re.DOTALL)
            if match:
                try:
                    return json.loads(match.group(1))
                except:
                    pass
            # 3. å°è¯•æå– [ ... ]
            match = re.search(r"(\[.*\])", text, re.DOTALL)
            if match:
                try:
                    return json.loads(match.group(1))
                except:
                    pass

            logger.warning(f"æ— æ³•è§£æ JSON: {text[:100]}...")
            return []
</file>

<file path="runtime/core/llm/llm.py">
from openai import OpenAI
from config import Config
import logging

logger = logging.getLogger(__name__)

class LLMClient:
    def __init__(self):
        self.client = OpenAI(
            api_key=Config.DEEPSEEK_API_KEY,
            base_url=Config.DEEPSEEK_BASE_URL
        )
        self.model_name = "deepseek-chat" # æˆ–ä» Config è¯»å–

    def stream_chat(self, query: str, system_prompt: str, history: list = None):
        """
        æµå¼å¯¹è¯
        :param history: æ ¼å¼ [{"role": "user", "content": "..."}]
        """
        messages = []

        # 1. æ·»åŠ  System Prompt
        if system_prompt:
            messages.append({"role": "system", "content": system_prompt})

        # 2. æ·»åŠ å†å²è®°å½• (é™åˆ¶æœ€è¿‘ 5 è½®ï¼Œé˜²æ­¢ Token æº¢å‡º)
        if history:
            # ç®€å•çš„è½¬æ¢é€»è¾‘ï¼Œç¡®ä¿æ ¼å¼æ­£ç¡®
            for msg in history[-10:]:
                # å…¼å®¹ proto çš„ Message å¯¹è±¡æˆ– dict
                role = getattr(msg, 'role', None) or msg.get('role')
                content = getattr(msg, 'content', None) or msg.get('content')
                if role and content:
                    messages.append({"role": role, "content": content})

        # 3. æ·»åŠ å½“å‰é—®é¢˜ (å¦‚æœ query å·²ç»åœ¨ prompts é‡Œäº†ï¼Œè¿™é‡Œå¯ä»¥ä¸åŠ ï¼Œå–å†³äº prompts ç­–ç•¥)
        messages.append({"role": "user", "content": query})

        try:
            response = self.client.chat.completions.create(
                model=self.model_name,
                messages=messages,
                stream=True,
                temperature=0.3,
                stream_options={"include_usage": True},
            )

            for chunk in response:
                # 1. å¤„ç†å†…å®¹å¢é‡
                if chunk.choices and chunk.choices[0].delta.content:
                    yield {
                        "type": "content",
                        "data": chunk.choices[0].delta.content
                    }
                # 2. ğŸ”¥ å¤„ç† Token ç»Ÿè®¡ (é€šå¸¸åœ¨æœ€åä¸€å—)
                if hasattr(chunk, 'usage') and chunk.usage:
                    yield {
                        "type": "usage",
                        "data": {
                            "prompt_tokens": chunk.usage.prompt_tokens,
                            "completion_tokens": chunk.usage.completion_tokens,
                            "total_tokens": chunk.usage.total_tokens
                        }
                    }

        except Exception as e:
            logger.error(f"OpenAI API Error: {e}")
            raise e
</file>

<file path="runtime/core/managers/__init__.py">

</file>

<file path="runtime/core/managers/etl_manager.py">
import json
import time
import uuid
import logging
import traceback
from typing import Generator, Dict, Any, Optional

from core.llm.embedding import EmbeddingModel
from core.stores.qdrant_store import QdrantStore
from core.connectors.base import ConnectorFactory

logger = logging.getLogger(__name__)

class ETLManager:
    def __init__(self, qdrant_store: QdrantStore, nebula_store: Any = None):
        """
        åˆå§‹åŒ– ETL ç®¡ç†å™¨
        :param qdrant_store: å‘é‡æ•°æ®åº“å®ä¾‹ (å¿…é¡»)
        :param nebula_store: å›¾æ•°æ®åº“å®ä¾‹ (å¯é€‰ï¼Œå¦‚æœä¸º None åˆ™ä¸æ„å»ºå›¾è°±)
        """
        self.qdrant = qdrant_store
        self.nebula = nebula_store
        self.embed_model = EmbeddingModel.get_instance()

        # ğŸ”¥ åŠ¨æ€åˆå§‹åŒ– KG Builder (ä¼ä¸šç‰ˆåŠŸèƒ½)
        self.kg_builder = None
        if self.nebula:
            try:
                # å°è¯•å¯¼å…¥ KG Builder
                # æ³¨æ„ï¼šåœ¨ Phase 3 ç‰©ç†æ‹†åˆ†åï¼Œè¿™ä¸ªè·¯å¾„å¯èƒ½ä¼šå˜ï¼Œæˆ–è€…é€šè¿‡ enterprise_loader æ³¨å†Œ
                # è¿™é‡Œæš‚æ—¶ä¿æŒåŸæœ‰è·¯å¾„ï¼Œä½†åŠ ä¸Š try-except ä»¥é˜²æ–‡ä»¶è¢«ç§»èµ°
                from workflows.kg_builder.graph import MultiAgentKGBuilder
                self.kg_builder = MultiAgentKGBuilder(self.nebula)
                logger.info("ğŸ§  [ETL] Knowledge Graph Builder activated.")
            except ImportError:
                logger.warning("âš ï¸ [ETL] Enterprise KG Builder module not found.")
            except Exception as e:
                logger.error(f"âŒ [ETL] KG Builder init failed: {e}")

    def sync_datasource(self, kb_id: int, source_id: int, source_type: str, config_json: str) -> Generator[Dict[str, Any], None, None]:
        """
        æ‰§è¡Œæ•°æ®æºåŒæ­¥ä»»åŠ¡ (ç”Ÿæˆå™¨)
        :yield: è¿›åº¦ä¿¡æ¯ {"chunks": int, "pages": int}
        """
        start_time = time.time()
        logger.info(f"ğŸ”„ [ETL Start] KB={kb_id} Source={source_id} Type={source_type}")

        try:
            config = json.loads(config_json)

            # 1. è·å–è¿æ¥å™¨
            connector_cls = ConnectorFactory.get_connector(source_type)
            if not connector_cls:
                raise ValueError(f"Unsupported/Missing connector type: '{source_type}'. Please check Enterprise License.")

            connector = connector_cls(kb_id, source_id, config)

            chunks_buffer = []
            total_chunks = 0

            # 2. éå†æ–‡æ¡£åˆ‡ç‰‡
            for chunk in connector.load():
                # ç”Ÿæˆå…¨å±€å”¯ä¸€ ID
                chunk_uuid = str(uuid.uuid4())

                # å‘é‡åŒ–
                vector = self.embed_model.encode(chunk.content)

                # å‡†å¤‡ Qdrant Payload
                payload = {
                    "content": chunk.content,
                    "kb_id": kb_id,
                    "source_id": source_id,
                    **chunk.metadata
                }

                chunks_buffer.append({
                    "id": chunk_uuid,
                    "vector": vector,
                    "payload": payload
                })

                # 3. è§¦å‘å›¾è°±æ„å»º (å¦‚æœå¯ç”¨äº†)
                if self.kg_builder:
                    try:
                        # è¿™æ˜¯ä¸€ä¸ªè€—æ—¶æ“ä½œï¼Œç›®å‰åŒæ­¥æ‰§è¡Œ
                        self.kg_builder.run(chunk.content, chunk.metadata, chunk_uuid)
                    except Exception as kg_e:
                        logger.warning(f"âš ï¸ KG Build failed for chunk {chunk_uuid}: {kg_e}")

                # 4. æ‰¹å¤„ç†å†™å…¥å‘é‡åº“ (æ¯ 50 æ¡)
                if len(chunks_buffer) >= 50:
                    self.qdrant.upsert_chunks(chunks_buffer)
                    total_chunks += len(chunks_buffer)
                    chunks_buffer = []
                    # å®æ—¶æ±‡æŠ¥è¿›åº¦ (å¯é€‰)
                    # yield {"chunks": total_chunks}

            # å†™å…¥å‰©ä½™ buffer
            if chunks_buffer:
                self.qdrant.upsert_chunks(chunks_buffer)
                total_chunks += len(chunks_buffer)

            duration = time.time() - start_time
            logger.info(f"âœ… [ETL Done] Chunks={total_chunks} Time={duration:.2f}s")

            # è¿”å›æœ€ç»ˆç»Ÿè®¡
            yield {
                "success": True,
                "chunks": total_chunks,
                "pages": 0  # å¦‚æœ connector èƒ½æä¾›æ€»é¡µæ•°æ›´å¥½
            }

        except Exception as e:
            logger.error(f"âŒ [ETL Error] {str(e)}")
            logger.error(traceback.format_exc())
            raise e  # æŠ›å‡ºå¼‚å¸¸ç”± Service å±‚æ•è·å°è£… gRPC é”™è¯¯
</file>

<file path="runtime/core/managers/inference_manager.py">
import json
import time
import logging
import traceback
from typing import Generator, Dict, Any, List

from opentelemetry import trace
from workflows.chat_flow import ChatWorkflow

logger = logging.getLogger(__name__)
tracer = trace.get_tracer(__name__)

class InferenceManager:
    def __init__(self, qdrant_store, nebula_store=None):
        """
        åˆå§‹åŒ–æ¨ç†ç®¡ç†å™¨
        :param qdrant_store: å‘é‡å­˜å‚¨ (Core)
        :param nebula_store: å›¾å­˜å‚¨ (Enterprise, å¯é€‰)
        """
        self.qdrant = qdrant_store
        self.nebula = nebula_store

    def run_chat(self, query: str, history: List[Any], app_config_json: str) -> Generator[Dict[str, Any], None, None]:
        """
        æ‰§è¡Œå¯¹è¯å·¥ä½œæµ
        :param query: ç”¨æˆ·é—®é¢˜
        :param history: å†å²è®°å½• (gRPC Message list)
        :param app_config_json: åº”ç”¨é…ç½® (å« kb_ids, org_id)
        :yield: æ ‡å‡†åŒ–çš„äº‹ä»¶å­—å…¸ (type, payload, meta)
        """
        start_time = time.time()

        # 1. å‡†å¤‡ç»Ÿè®¡æ•°æ®
        usage_stats = {
            "prompt_tokens": 0,
            "completion_tokens": 0,
            "total_tokens": 0
        }

        # è·å–å½“å‰ TraceID (ç”¨äºè¿”å›ç»™å‰ç«¯å±•ç¤º)
        current_span = trace.get_current_span()
        trace_id = format(current_span.get_span_context().trace_id, "032x")

        try:
            # 2. è§£æé…ç½®
            app_config = json.loads(app_config_json)
            kb_ids = app_config.get("kb_ids", [])

            # 3. åˆå§‹åŒ–å·¥ä½œæµ (æ¯æ¬¡è¯·æ±‚å¯èƒ½é’ˆå¯¹ä¸åŒçš„ KBï¼Œæ‰€ä»¥åœ¨è¿™é‡Œåˆå§‹åŒ–)
            # æ³¨æ„ï¼šChatWorkflow å†…éƒ¨å·²ç»åšäº†å¯¹ nebula ä¸º None çš„å®¹é”™å¤„ç† (è§ Phase 1 æ­¥éª¤ 4)
            workflow = ChatWorkflow(self.nebula, self.qdrant, kb_ids)

            # 4. æ„é€ åˆå§‹çŠ¶æ€
            initial_state = {
                "query": query,
                "history": history,
                "app_config": app_config
            }

            # 5. æ‰§è¡Œå·¥ä½œæµå¹¶å¤„ç†æµå¼äº‹ä»¶
            for event in workflow.run_stream(initial_state):

                # A. æ€è€ƒ/æ¨ç†è¿‡ç¨‹
                if event["type"] == "thought":
                    yield {
                        "type": "thought",
                        "payload": event["content"],
                        "meta": {
                            "node_name": event.get("node", "Agent"),
                            "trace_id": trace_id,
                            "duration_ms": event.get("duration", 0)
                        }
                    }

                # B. ç­”æ¡ˆç‰‡æ®µ
                elif event["type"] == "delta":
                    yield {
                        "type": "delta",
                        "payload": event["content"]
                    }

                # C. å¼•ç”¨æ–‡æ¡£
                elif event["type"] == "reference":
                    yield {
                        "type": "reference",
                        "payload": json.dumps(event["docs"]) # åºåˆ—åŒ–åè¿”å›
                    }

                # D. Token ç»Ÿè®¡
                elif event["type"] == "usage":
                    u = event["usage"]
                    usage_stats["prompt_tokens"] += u.get("prompt_tokens", 0)
                    usage_stats["completion_tokens"] += u.get("completion_tokens", 0)
                    usage_stats["total_tokens"] += u.get("total_tokens", 0)

        except Exception as e:
            logger.error(f"âŒ [Inference] Error: {str(e)}")
            logger.error(traceback.format_exc())
            yield {
                "type": "error",
                "payload": f"Inference Error: {str(e)}"
            }

        finally:
            # 6. ç”Ÿæˆæœ€ç»ˆæ‘˜è¦ (Summary)
            duration = int((time.time() - start_time) * 1000)
            logger.info(f"ğŸ“Š [Inference Done] Tokens={usage_stats['total_tokens']} Time={duration}ms")

            yield {
                "type": "summary",
                "summary": {
                    "total_tokens": usage_stats["total_tokens"],
                    "prompt_tokens": usage_stats["prompt_tokens"],
                    "completion_tokens": usage_stats["completion_tokens"],
                    "total_duration_ms": duration,
                    "final_status": "success"
                }
            }
</file>

<file path="runtime/core/stores/minio_store.py">
import io
from minio import Minio
from opentelemetry import trace
from config import Config

tracer = trace.get_tracer(__name__)

class MinioStore:
    def __init__(self):
        self.client = Minio(
            Config.MINIO_ENDPOINT,
            access_key=Config.MINIO_ACCESS_KEY,
            secret_key=Config.MINIO_SECRET_KEY,
            secure=False # æœ¬åœ°å¼€å‘é€šå¸¸æ˜¯ http
        )
        # ğŸ”¥ ä¿®æ”¹ï¼šä½¿ç”¨ Config ä¸­çš„æ¡¶åï¼Œæˆ–è€…é»˜è®¤ä¸º chimera-docs (ä¸ Go ä¿æŒä¸€è‡´)
        self.bucket = getattr(Config, "MINIO_BUCKET", "chimera-docs")

    def download_file(self, storage_path: str) -> bytes:
        """
        ä» MinIO ä¸‹è½½æ–‡ä»¶å¹¶è®°å½• Trace
        """
        with tracer.start_as_current_span("Skill:Minio_Download") as span:
            span.set_attribute("minio.path", storage_path)
            try:
                # è¿™é‡Œçš„ bucket å¿…é¡»å’Œ Go ä¸Šä¼ æ—¶çš„ bucket ä¸€è‡´
                response = self.client.get_object(self.bucket, storage_path)
                data = response.read()
                span.set_attribute("file.size", len(data))
                return data
            except Exception as e:
                span.record_exception(e)
                raise Exception(f"MinIO ä¸‹è½½å¤±è´¥: {str(e)} (Bucket: {self.bucket}, Path: {storage_path})")
            finally:
                if 'response' in locals():
                    response.close()
                    response.release_conn()
</file>

<file path="runtime/core/stores/qdrant_store.py">
import logging
from typing import List, Dict, Any
from qdrant_client import QdrantClient
from qdrant_client.http import models
from config import Config

logger = logging.getLogger(__name__)

class QdrantStore:
    def __init__(self):
        self.client = QdrantClient(
            host=Config.QDRANT_HOST,
            port=Config.QDRANT_PORT,
        )
        # ğŸ”¥ ä¿®æ­£ï¼šç»Ÿä¸€é›†åˆåç§°ä¸º chimera_docs (ä¸ Go ç«¯ä¿æŒä¸€è‡´)
        self.collection_name = "chimera_docs"
        self.vector_size = 384

        self._ensure_collection()

    def _ensure_collection(self):
        try:
            self.client.get_collection(self.collection_name)
            logger.info(f"âœ… Qdrant é›†åˆ '{self.collection_name}' å·²å°±ç»ª")
        except Exception:
            logger.info(f"ğŸš§ Qdrant é›†åˆä¸å­˜åœ¨ï¼Œæ­£åœ¨åˆ›å»º: {self.collection_name}")
            self.client.create_collection(
                collection_name=self.collection_name,
                vectors_config=models.VectorParams(
                    size=self.vector_size,
                    distance=models.Distance.COSINE
                )
            )
            # åˆ›å»ºç´¢å¼•
            self.client.create_payload_index(
                collection_name=self.collection_name,
                field_name="kb_id",
                field_schema=models.PayloadSchemaType.INTEGER
            )

    def upsert_chunks(self, chunks: List[Dict[str, Any]]):
        points = []
        for idx, chunk in enumerate(chunks):
            # ç¡®ä¿ id å­˜åœ¨
            import uuid
            point_id = chunk.get("id") or str(uuid.uuid4())

            points.append(models.PointStruct(
                id=point_id,
                vector=chunk["vector"],
                payload=chunk["payload"]
            ))

        self.client.upsert(
            collection_name=self.collection_name,
            points=points
        )
        logger.info(f"ğŸ’¾ å·²å‘ Qdrant å†™å…¥ {len(points)} æ¡å‘é‡æ•°æ®")

    def search(self, query_vector: List[float], kb_ids: List[int], top_k: int = 5):
        """
        å¸¦è¿‡æ»¤çš„æœç´¢
        """
        # æ„é€ è¿‡æ»¤å™¨
        search_filter = None
        if kb_ids:
            # å…¼å®¹å¤„ç†ï¼šç¡®ä¿ kb_ids æ˜¯ list
            if not isinstance(kb_ids, list):
                kb_ids = [kb_ids]

            search_filter = models.Filter(
                must=[
                    models.FieldCondition(
                        key="kb_id",
                        match=models.MatchAny(any=kb_ids)
                    )
                ]
            )

        # ğŸ”¥ æ ¸å¿ƒä¿®å¤ï¼šé˜²æ­¢ search æ–¹æ³•æŠ¥é”™ï¼Œå¢åŠ  fallback
        try:
            # ä¼˜å…ˆå°è¯•æ ‡å‡†çš„ search æ–¹æ³•
            results = self.client.search(
                collection_name=self.collection_name,
                query_vector=query_vector,
                query_filter=search_filter,
                limit=top_k
            )
        except AttributeError:
            # å¦‚æœçœŸçš„æŠ¥ AttributeErrorï¼Œå°è¯•ç”¨ search_batch (æ—§ç‰ˆ) æˆ– query_points (æ–°ç‰ˆåº•å±‚)
            logger.warning("âš ï¸ QdrantClient.search æ–¹æ³•æœªæ‰¾åˆ°ï¼Œå°è¯•ä½¿ç”¨ query_points...")
            results = self.client.query_points(
                collection_name=self.collection_name,
                query=query_vector,
                query_filter=search_filter,
                limit=top_k
            ).points

        # æ ¼å¼åŒ–ç»“æœ
        formatted = []
        for hit in results:
            formatted.append({
                "content": hit.payload.get("content", ""),
                "score": hit.score,
                "metadata": hit.payload
            })

        return formatted
</file>

<file path="runtime/core/telemetry/__init__.py">

</file>

<file path="runtime/core/telemetry/exporter.py">

</file>

<file path="runtime/core/telemetry/metrics.py">

</file>

<file path="runtime/core/telemetry/tracing.py">
import functools
import json
from opentelemetry import trace
from opentelemetry.trace import Status, StatusCode
from opentelemetry.sdk.resources import Resource
from opentelemetry.sdk.trace import TracerProvider
from opentelemetry.sdk.trace.export import BatchSpanProcessor
from opentelemetry.exporter.otlp.proto.grpc.trace_exporter import OTLPSpanExporter
from google.protobuf.message import Message
from google.protobuf.json_format import MessageToDict

# --- OTel åˆå§‹åŒ– ---
resource = Resource(attributes={
    "service.name": "chimera-agents-runtime",
    "service.version": "v0.5.0"
})
provider = TracerProvider(resource=resource)
# é»˜è®¤å‘é€åˆ° SigNoz çš„ 4317 ç«¯å£
processor = BatchSpanProcessor(OTLPSpanExporter(endpoint="http://localhost:4317", insecure=True))
provider.add_span_processor(processor)
trace.set_tracer_provider(provider)

tracer = trace.get_tracer("chimera.runtime")

def setup_otel(service_name="chimera-agents-runtime", endpoint="http://localhost:4317"):
    """
    åˆå§‹åŒ– OpenTelemetry å¹¶åœ¨å…¨å±€æ³¨å†Œã€‚
    è¿™ä¸ªå‡½æ•°éœ€è¦åœ¨ main.py å¯åŠ¨æ—¶æœ€å…ˆè°ƒç”¨ã€‚
    """
    # 1. å®šä¹‰èµ„æºä¿¡æ¯ï¼ˆæ˜¾ç¤ºåœ¨ SigNoz çš„æœåŠ¡åˆ—è¡¨é‡Œï¼‰
    resource = Resource(attributes={
        "service.name": service_name
    })

    # 2. åˆ›å»º Tracer æä¾›è€…
    provider = TracerProvider(resource=resource)

    # 3. é…ç½®å¯¼å‡ºå™¨ï¼ˆæŒ‡å‘ SigNoz çš„æ•°æ®æ¥æ”¶ç«¯å£ï¼‰
    # insecure=True æ˜¯å› ä¸ºæœ¬åœ° SigNoz é»˜è®¤æ²¡å¼€ TLS
    otlp_exporter = OTLPSpanExporter(endpoint=endpoint, insecure=True)

    # 4. æ·»åŠ å¤„ç†å™¨ï¼ˆBatch æ¨¡å¼æ€§èƒ½æ›´å¥½ï¼‰
    span_processor = BatchSpanProcessor(otlp_exporter)
    provider.add_span_processor(span_processor)

    # 5. è®¾ç½®å…¨å±€å…¨å±€è¿½è¸ªå™¨
    trace.set_tracer_provider(provider)

    print(f"âœ… OpenTelemetry initialized for {service_name}, exporting to {endpoint}")

def trace_agent(agent_name: str):
    """
    äº®ç‚¹ï¼šè‡ªåŠ¨æ•è· Agent æ‰§è¡Œå…¨è¿‡ç¨‹çš„ Payload å’Œä¸Šä¸‹æ–‡
    """
    def decorator(func):
        @functools.wraps(func)
        def wrapper(self, *args, **kwargs):
            # 1. ç²¾å‡†æå– Payload (è·³è¿‡ self)
            raw_input = args[0] if args else kwargs

            # 2. è½¬æ¢ Protobuf å¯¹è±¡ä¸ºå¯åºåˆ—åŒ–å­—å…¸
            if isinstance(raw_input, Message):
                serializable_input = MessageToDict(raw_input)
            else:
                serializable_input = raw_input

            with tracer.start_as_current_span(f"ğŸ¤– Agent:{agent_name}") as span:
                span.set_attribute("chimera.agents.name", agent_name)
                # è®°å½•æ ¼å¼åŒ–åçš„è¾“å…¥
                span.set_attribute("chimera.input.payload",
                                   json.dumps(serializable_input, ensure_ascii=False))

                if hasattr(self, 'prompt_path'):
                    span.set_attribute("chimera.prompts.path", self.prompt_path)

                try:
                    result = func(self, *args, **kwargs)

                    # 3. ğŸ”¥ æ ¸å¿ƒé€»è¾‘ï¼šå¤„ç†æµå¼å“åº” (ChatStream)
                    if hasattr(result, '__iter__') and not isinstance(result, (list, dict, str)):
                        def generator_wrapper():
                            full_response = []
                            try:
                                for chunk in result:
                                    # å¦‚æœ chunk æ˜¯ Protobuf æ¶ˆæ¯ä¹Ÿéœ€è¦è½¬æ¢
                                    c_data = MessageToDict(chunk) if isinstance(chunk, Message) else chunk
                                    full_response.append(c_data)
                                    yield chunk
                                # æµç»“æŸåï¼Œä¸€æ¬¡æ€§è®°å½•å®Œæ•´çš„å˜å¼‚è¾“å‡ºåˆ° SigNoz
                                span.set_attribute("chimera.output.payload",
                                                   json.dumps(full_response, ensure_ascii=False))
                                span.set_status(Status(StatusCode.OK))
                            except Exception as ge:
                                span.record_exception(ge)
                                span.set_status(Status(StatusCode.ERROR, str(ge)))
                                raise ge
                        return generator_wrapper()

                    # 4. å¤„ç†æ™®é€šéæµå¼è¿”å›
                    serializable_output = MessageToDict(result) if isinstance(result, Message) else result
                    span.set_attribute("chimera.output.payload",
                                       json.dumps(serializable_output, ensure_ascii=False))
                    span.set_status(Status(StatusCode.OK))
                    return result

                except Exception as e:
                    span.record_exception(e)
                    span.set_status(Status(StatusCode.ERROR, str(e)))
                    raise e
        return wrapper
    return decorator
</file>

<file path="runtime/core/__init__.py">

</file>

<file path="runtime/memory/__init__.py">

</file>

<file path="runtime/memory/episodic.py">

</file>

<file path="runtime/memory/semantic.py">
from core.telemetry.tracing import trace_agent

class MemoryAgent:
    def __init__(self, nebula_store, qdrant_client):
        self.graph = nebula_store
        self.vector = qdrant_client

    @trace_agent("Agent:Memory_Recall")
    def recall(self, query: str):
        # 1. å‘é‡æ£€ç´¢ï¼šå¯»æ‰¾ç›¸ä¼¼çš„æƒ…æ™¯æ‘˜è¦
        vector_res = self.vector.search(query)

        # 2. å›¾æ£€ç´¢ï¼šå¯»æ‰¾ Query æ¶‰åŠå®ä½“çš„é•¿å°¾å±æ€§
        # æ¯”å¦‚ç”¨æˆ·é—®â€œChimeraâ€ï¼Œå®ƒä¼šå» Nebula æŸ¥å‡ºå…¶ version, status ç­‰
        graph_res = self.graph.execute(f"LOOKUP ON Entity WHERE Entity.name == '{query}'...")

        # 3. äº®ç‚¹ï¼šåœ¨ SigNoz ä¸­ï¼Œä½ ä¼šçœ‹åˆ°è¿™ä¸¤ä¸ªæ£€ç´¢æ˜¯å¹¶è¡Œçš„è¿˜æ˜¯ä¸²è¡Œçš„ï¼Œä»¥åŠå„è‡ªå¬å›äº†ä»€ä¹ˆ
        return {
            "episodic": vector_res, # æƒ…æ™¯è®°å¿†
            "semantic": graph_res   # è¯­ä¹‰è®°å¿†ï¼ˆçŸ¥è¯†å›¾è°±ï¼‰
        }
</file>

<file path="runtime/memory/shot-term.py">

</file>

<file path="runtime/prompts/chat/synthesis.yaml">
system: |
  ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„ä¼ä¸šçŸ¥è¯†åŠ©æ‰‹ã€‚è¯·æ ¹æ®ä»¥ä¸‹ã€æ–‡æ¡£ç‰‡æ®µã€‘å’Œã€çŸ¥è¯†å›¾è°±ã€‘å›ç­”ç”¨æˆ·é—®é¢˜ã€‚
  
  ã€å›ç­”è¦æ±‚ã€‘ï¼š
  1. å¦‚æœå‚è€ƒèµ„æ–™æ— æ³•å›ç­”é—®é¢˜ï¼Œè¯·è¯šå®è¯´æ˜ï¼šâ€œçŸ¥è¯†åº“ä¸­æœªæ‰¾åˆ°ç›¸å…³ä¿¡æ¯â€ã€‚
  2. ç»¼åˆä¸¤è·¯ä¿¡æ¯ï¼Œç»™å‡ºå‡†ç¡®ã€æœ‰æ·±åº¦çš„å›ç­”ã€‚
  3. å¦‚æœä¿¡æ¯å†²çªï¼Œä¼˜å…ˆä½¿ç”¨ã€æ–‡æ¡£ç‰‡æ®µã€‘ä¸­çš„ä¿¡æ¯ã€‚
  4. é¿å…é‡å¤å†…å®¹ï¼Œç”¨æ¸…æ™°ã€ç®€æ´çš„è¯­è¨€ã€‚

  ã€å‚è€ƒèµ„æ–™ã€‘ï¼š
  {{ full_context }}

user: |
  {{ query }}
</file>

<file path="runtime/prompts/kg/ner.yaml">
system: |
  ä½ æ˜¯ä¸€ä¸ªèµ„æ·±çš„æ•°æ®åˆ†æå¸ˆã€‚è¯·ä»ç»™å®šçš„æ–‡æœ¬ä¸­æå–æ‰€æœ‰å…³é”®å®ä½“ã€‚

  ã€æå–ç±»åˆ«å‚è€ƒã€‘ï¼š
  - ç»„ç»‡/å…¬å¸ (Org)
  - æŠ€æœ¯/æ¨¡å‹ (Tech)
  - äººç‰© (Person)
  - åœ°ç‚¹ (Loc)
  - æ¦‚å¿µ/æœ¯è¯­ (Concept)
  - æ—¶é—´/äº‹ä»¶ (Event)

  ã€è¦æ±‚ã€‘ï¼š
  1. åªè¦å®ä½“ï¼Œä¸è¦å…³ç³»ã€‚
  2. ä¿æŒåŸå­æ€§ï¼ˆä¾‹å¦‚ "å¾®è½¯çš„CEO" -> æå– "å¾®è½¯", "CEO"ï¼‰ã€‚
  3. è¿”å› JSON åˆ—è¡¨: [{"name": "å®ä½“å", "type": "ç±»å‹", "desc": "ç®€çŸ­æè¿°ä¸Šä¸‹æ–‡"}]

user: |
  {{ text }}
</file>

<file path="runtime/prompts/kg/relation.yaml">
system: |
  ä½ æ˜¯ä¸€ä¸ªå…³ç³»æŠ½å–ä¸“å®¶ã€‚
  æˆ‘å°†ç»™ä½ ä¸€æ®µæ–‡æœ¬å’Œä¸€ç»„å·²è¯†åˆ«çš„å®ä½“ã€‚è¯·åˆ¤æ–­è¿™äº›å®ä½“ä¹‹é—´æ˜¯å¦å­˜åœ¨ç›´æ¥çš„ã€æ˜ç¡®çš„å…³ç³»ã€‚

  ã€å·²çŸ¥å®ä½“åˆ—è¡¨ã€‘ï¼š
  {{ entities }}

  ã€åŸæ–‡ã€‘ï¼š
  {{ text }}

  ã€è¦æ±‚ã€‘ï¼š
  1. ä»…æå–å‡ºç°åœ¨åˆ—è¡¨ä¸­çš„å®ä½“ä¹‹é—´çš„å…³ç³»ã€‚
  2. å…³ç³»æè¿°å¿…é¡»ç®€ç»ƒï¼ˆå¦‚ "developed_by", "contains", "released_at"ï¼‰ã€‚
  3. å¦‚æœæ²¡æœ‰å…³ç³»ï¼Œä¸è¦ç¼–é€ ã€‚
  4. è¿”å› JSON åˆ—è¡¨: [{"src": "å®ä½“A", "dst": "å®ä½“B", "relation": "å…³ç³»æè¿°"}]
</file>

<file path="runtime/prompts/kg/resolution.yaml">
system: |
  ä½ æ˜¯ä¸€ä¸ªçŸ¥è¯†å›¾è°±æ¸…æ´—ä¸“å®¶ã€‚ä½ éœ€è¦å¯¹è¾“å…¥çš„â€œå®ä½“â€å’Œâ€œå…³ç³»â€è¿›è¡Œæ ‡å‡†åŒ–å¤„ç†ã€‚

  ã€å¤„ç†ä»»åŠ¡ã€‘ï¼š
  1. **å®ä½“åˆå¹¶**ï¼šå°†æŒ‡ä»£åŒä¸€äº‹ç‰©çš„å®ä½“åˆå¹¶ï¼ˆå¦‚ "V3" å’Œ "DeepSeek-V3" -> ä¿ç•™å…¨ç§° "DeepSeek-V3"ï¼‰ã€‚
  2. **å™ªå£°è¿‡æ»¤**ï¼šåˆ é™¤æ³›æŒ‡è¯ï¼ˆå¦‚"æˆ‘ä»¬"ã€"æ–‡æ¡£"ã€"ç”¨æˆ·"ã€"å›¾ç‰‡"ï¼‰ã€‚
  3. **æ ¼å¼ä¿®æ­£**ï¼šç¡®ä¿è¾“å‡ºæ ¼å¼è§„èŒƒã€‚

  ã€è¾“å…¥æ•°æ®ã€‘ï¼š
  {{ graph_data }}

  ã€è¾“å‡ºã€‘ï¼š
  è¿”å›æ¸…æ´—åçš„æœ€ç»ˆ JSON: 
  {
    "entities": [{"name": "...", "type": "..."}],
    "relations": [{"src": "...", "dst": "...", "relation": "..."}]
  }
</file>

<file path="runtime/rpc/api/runtime/v1/runtime_pb2_grpc.py">
# Generated by the gRPC Python protocol compiler plugin. DO NOT EDIT!
"""Client and server classes corresponding to protobuf-defined services."""
import grpc
import warnings

from api.runtime.v1 import runtime_pb2 as api_dot_runtime_dot_v1_dot_runtime__pb2

GRPC_GENERATED_VERSION = '1.76.0'
GRPC_VERSION = grpc.__version__
_version_not_supported = False

try:
    from grpc._utilities import first_version_is_lower
    _version_not_supported = first_version_is_lower(GRPC_VERSION, GRPC_GENERATED_VERSION)
except ImportError:
    _version_not_supported = True

if _version_not_supported:
    raise RuntimeError(
        f'The grpc package installed is at version {GRPC_VERSION},'
        + ' but the generated code in api/runtime/v1/runtime_pb2_grpc.py depends on'
        + f' grpcio>={GRPC_GENERATED_VERSION}.'
        + f' Please upgrade your grpc module to grpcio>={GRPC_GENERATED_VERSION}'
        + f' or downgrade your generated code using grpcio-tools<={GRPC_VERSION}.'
    )


class RuntimeServiceStub(object):
    """Missing associated documentation comment in .proto file."""

    def __init__(self, channel):
        """Constructor.

        Args:
            channel: A grpc.Channel.
        """
        self.RunAgent = channel.unary_stream(
                '/chimera.v1.RuntimeService/RunAgent',
                request_serializer=api_dot_runtime_dot_v1_dot_runtime__pb2.RunAgentRequest.SerializeToString,
                response_deserializer=api_dot_runtime_dot_v1_dot_runtime__pb2.RunAgentResponse.FromString,
                _registered_method=True)
        self.SyncDataSource = channel.unary_unary(
                '/chimera.v1.RuntimeService/SyncDataSource',
                request_serializer=api_dot_runtime_dot_v1_dot_runtime__pb2.SyncRequest.SerializeToString,
                response_deserializer=api_dot_runtime_dot_v1_dot_runtime__pb2.SyncResponse.FromString,
                _registered_method=True)


class RuntimeServiceServicer(object):
    """Missing associated documentation comment in .proto file."""

    def RunAgent(self, request, context):
        """Missing associated documentation comment in .proto file."""
        context.set_code(grpc.StatusCode.UNIMPLEMENTED)
        context.set_details('Method not implemented!')
        raise NotImplementedError('Method not implemented!')

    def SyncDataSource(self, request, context):
        """Missing associated documentation comment in .proto file."""
        context.set_code(grpc.StatusCode.UNIMPLEMENTED)
        context.set_details('Method not implemented!')
        raise NotImplementedError('Method not implemented!')


def add_RuntimeServiceServicer_to_server(servicer, server):
    rpc_method_handlers = {
            'RunAgent': grpc.unary_stream_rpc_method_handler(
                    servicer.RunAgent,
                    request_deserializer=api_dot_runtime_dot_v1_dot_runtime__pb2.RunAgentRequest.FromString,
                    response_serializer=api_dot_runtime_dot_v1_dot_runtime__pb2.RunAgentResponse.SerializeToString,
            ),
            'SyncDataSource': grpc.unary_unary_rpc_method_handler(
                    servicer.SyncDataSource,
                    request_deserializer=api_dot_runtime_dot_v1_dot_runtime__pb2.SyncRequest.FromString,
                    response_serializer=api_dot_runtime_dot_v1_dot_runtime__pb2.SyncResponse.SerializeToString,
            ),
    }
    generic_handler = grpc.method_handlers_generic_handler(
            'chimera.v1.RuntimeService', rpc_method_handlers)
    server.add_generic_rpc_handlers((generic_handler,))
    server.add_registered_method_handlers('chimera.v1.RuntimeService', rpc_method_handlers)


 # This class is part of an EXPERIMENTAL API.
class RuntimeService(object):
    """Missing associated documentation comment in .proto file."""

    @staticmethod
    def RunAgent(request,
            target,
            options=(),
            channel_credentials=None,
            call_credentials=None,
            insecure=False,
            compression=None,
            wait_for_ready=None,
            timeout=None,
            metadata=None):
        return grpc.experimental.unary_stream(
            request,
            target,
            '/chimera.v1.RuntimeService/RunAgent',
            api_dot_runtime_dot_v1_dot_runtime__pb2.RunAgentRequest.SerializeToString,
            api_dot_runtime_dot_v1_dot_runtime__pb2.RunAgentResponse.FromString,
            options,
            channel_credentials,
            insecure,
            call_credentials,
            compression,
            wait_for_ready,
            timeout,
            metadata,
            _registered_method=True)

    @staticmethod
    def SyncDataSource(request,
            target,
            options=(),
            channel_credentials=None,
            call_credentials=None,
            insecure=False,
            compression=None,
            wait_for_ready=None,
            timeout=None,
            metadata=None):
        return grpc.experimental.unary_unary(
            request,
            target,
            '/chimera.v1.RuntimeService/SyncDataSource',
            api_dot_runtime_dot_v1_dot_runtime__pb2.SyncRequest.SerializeToString,
            api_dot_runtime_dot_v1_dot_runtime__pb2.SyncResponse.FromString,
            options,
            channel_credentials,
            insecure,
            call_credentials,
            compression,
            wait_for_ready,
            timeout,
            metadata,
            _registered_method=True)
</file>

<file path="runtime/rpc/api/runtime/v1/runtime_pb2.py">
# -*- coding: utf-8 -*-
# Generated by the protocol buffer compiler.  DO NOT EDIT!
# NO CHECKED-IN PROTOBUF GENCODE
# source: api/runtime/v1/runtime.proto
# Protobuf Python Version: 6.31.1
"""Generated protocol buffer code."""
from google.protobuf import descriptor as _descriptor
from google.protobuf import descriptor_pool as _descriptor_pool
from google.protobuf import runtime_version as _runtime_version
from google.protobuf import symbol_database as _symbol_database
from google.protobuf.internal import builder as _builder
_runtime_version.ValidateProtobufRuntimeVersion(
    _runtime_version.Domain.PUBLIC,
    6,
    31,
    1,
    '',
    'api/runtime/v1/runtime.proto'
)
# @@protoc_insertion_point(imports)

_sym_db = _symbol_database.Default()




DESCRIPTOR = _descriptor_pool.Default().AddSerializedFile(b'\n\x1c\x61pi/runtime/v1/runtime.proto\x12\nchimera.v1\"\x83\x01\n\x0fRunAgentRequest\x12\x0e\n\x06\x61pp_id\x18\x01 \x01(\t\x12\r\n\x05query\x18\x02 \x01(\t\x12\x12\n\nsession_id\x18\x03 \x01(\t\x12\x17\n\x0f\x61pp_config_json\x18\x04 \x01(\t\x12$\n\x07history\x18\x05 \x03(\x0b\x32\x13.chimera.v1.Message\"(\n\x07Message\x12\x0c\n\x04role\x18\x01 \x01(\t\x12\x0f\n\x07\x63ontent\x18\x02 \x01(\t\"\x7f\n\x10RunAgentResponse\x12\x0c\n\x04type\x18\x01 \x01(\t\x12\x0f\n\x07payload\x18\x02 \x01(\t\x12#\n\x04meta\x18\x03 \x01(\x0b\x32\x15.chimera.v1.AgentMeta\x12\'\n\x07summary\x18\x04 \x01(\x0b\x32\x16.chimera.v1.RunSummary\"E\n\tAgentMeta\x12\x11\n\tnode_name\x18\x01 \x01(\t\x12\x10\n\x08trace_id\x18\x02 \x01(\t\x12\x13\n\x0b\x64uration_ms\x18\x03 \x01(\x03\"\x85\x01\n\nRunSummary\x12\x14\n\x0ctotal_tokens\x18\x01 \x01(\x05\x12\x15\n\rprompt_tokens\x18\x02 \x01(\x05\x12\x19\n\x11\x63ompletion_tokens\x18\x03 \x01(\x05\x12\x19\n\x11total_duration_ms\x18\x04 \x01(\x03\x12\x14\n\x0c\x66inal_status\x18\x05 \x01(\t\"V\n\x0bSyncRequest\x12\r\n\x05kb_id\x18\x01 \x01(\x03\x12\x15\n\rdatasource_id\x18\x02 \x01(\x03\x12\x0c\n\x04type\x18\x03 \x01(\t\x12\x13\n\x0b\x63onfig_json\x18\x04 \x01(\t\"\\\n\x0cSyncResponse\x12\x0f\n\x07success\x18\x01 \x01(\x08\x12\x11\n\terror_msg\x18\x02 \x01(\t\x12\x14\n\x0c\x63hunks_count\x18\x03 \x01(\x05\x12\x12\n\npage_count\x18\x04 \x01(\x05\x32\xa2\x01\n\x0eRuntimeService\x12I\n\x08RunAgent\x12\x1b.chimera.v1.RunAgentRequest\x1a\x1c.chimera.v1.RunAgentResponse\"\x00\x30\x01\x12\x45\n\x0eSyncDataSource\x12\x17.chimera.v1.SyncRequest\x1a\x18.chimera.v1.SyncResponse\"\x00\x42\x1aZ\x18\x43himera/server/api/v1;v1b\x06proto3')

_globals = globals()
_builder.BuildMessageAndEnumDescriptors(DESCRIPTOR, _globals)
_builder.BuildTopDescriptorsAndMessages(DESCRIPTOR, 'api.runtime.v1.runtime_pb2', _globals)
if not _descriptor._USE_C_DESCRIPTORS:
  _globals['DESCRIPTOR']._loaded_options = None
  _globals['DESCRIPTOR']._serialized_options = b'Z\030Chimera/server/api/v1;v1'
  _globals['_RUNAGENTREQUEST']._serialized_start=45
  _globals['_RUNAGENTREQUEST']._serialized_end=176
  _globals['_MESSAGE']._serialized_start=178
  _globals['_MESSAGE']._serialized_end=218
  _globals['_RUNAGENTRESPONSE']._serialized_start=220
  _globals['_RUNAGENTRESPONSE']._serialized_end=347
  _globals['_AGENTMETA']._serialized_start=349
  _globals['_AGENTMETA']._serialized_end=418
  _globals['_RUNSUMMARY']._serialized_start=421
  _globals['_RUNSUMMARY']._serialized_end=554
  _globals['_SYNCREQUEST']._serialized_start=556
  _globals['_SYNCREQUEST']._serialized_end=642
  _globals['_SYNCRESPONSE']._serialized_start=644
  _globals['_SYNCRESPONSE']._serialized_end=736
  _globals['_RUNTIMESERVICE']._serialized_start=739
  _globals['_RUNTIMESERVICE']._serialized_end=901
# @@protoc_insertion_point(module_scope)
</file>

<file path="runtime/rpc/__init__.py">

</file>

<file path="runtime/rpc/runtime_pb2_grpc.py">
# Generated by the gRPC Python protocol compiler plugin. DO NOT EDIT!
"""Client and server classes corresponding to protobuf-defined services."""
import grpc
import warnings

from . import runtime_pb2 as runtime__pb2

GRPC_GENERATED_VERSION = '1.76.0'
GRPC_VERSION = grpc.__version__
_version_not_supported = False

try:
    from grpc._utilities import first_version_is_lower
    _version_not_supported = first_version_is_lower(GRPC_VERSION, GRPC_GENERATED_VERSION)
except ImportError:
    _version_not_supported = True

if _version_not_supported:
    raise RuntimeError(
        f'The grpc package installed is at version {GRPC_VERSION},'
        + ' but the generated code in runtime_pb2_grpc.py depends on'
        + f' grpcio>={GRPC_GENERATED_VERSION}.'
        + f' Please upgrade your grpc module to grpcio>={GRPC_GENERATED_VERSION}'
        + f' or downgrade your generated code using grpcio-tools<={GRPC_VERSION}.'
    )


class RuntimeServiceStub(object):
    """Missing associated documentation comment in .proto file."""

    def __init__(self, channel):
        """Constructor.

        Args:
            channel: A grpc.Channel.
        """
        self.RunAgent = channel.unary_stream(
                '/chimera.v1.RuntimeService/RunAgent',
                request_serializer=runtime__pb2.RunAgentRequest.SerializeToString,
                response_deserializer=runtime__pb2.RunAgentResponse.FromString,
                _registered_method=True)
        self.SyncDataSource = channel.unary_unary(
                '/chimera.v1.RuntimeService/SyncDataSource',
                request_serializer=runtime__pb2.SyncRequest.SerializeToString,
                response_deserializer=runtime__pb2.SyncResponse.FromString,
                _registered_method=True)


class RuntimeServiceServicer(object):
    """Missing associated documentation comment in .proto file."""

    def RunAgent(self, request, context):
        """Missing associated documentation comment in .proto file."""
        context.set_code(grpc.StatusCode.UNIMPLEMENTED)
        context.set_details('Method not implemented!')
        raise NotImplementedError('Method not implemented!')

    def SyncDataSource(self, request, context):
        """Missing associated documentation comment in .proto file."""
        context.set_code(grpc.StatusCode.UNIMPLEMENTED)
        context.set_details('Method not implemented!')
        raise NotImplementedError('Method not implemented!')


def add_RuntimeServiceServicer_to_server(servicer, server):
    rpc_method_handlers = {
            'RunAgent': grpc.unary_stream_rpc_method_handler(
                    servicer.RunAgent,
                    request_deserializer=runtime__pb2.RunAgentRequest.FromString,
                    response_serializer=runtime__pb2.RunAgentResponse.SerializeToString,
            ),
            'SyncDataSource': grpc.unary_unary_rpc_method_handler(
                    servicer.SyncDataSource,
                    request_deserializer=runtime__pb2.SyncRequest.FromString,
                    response_serializer=runtime__pb2.SyncResponse.SerializeToString,
            ),
    }
    generic_handler = grpc.method_handlers_generic_handler(
            'chimera.v1.RuntimeService', rpc_method_handlers)
    server.add_generic_rpc_handlers((generic_handler,))
    server.add_registered_method_handlers('chimera.v1.RuntimeService', rpc_method_handlers)


 # This class is part of an EXPERIMENTAL API.
class RuntimeService(object):
    """Missing associated documentation comment in .proto file."""

    @staticmethod
    def RunAgent(request,
            target,
            options=(),
            channel_credentials=None,
            call_credentials=None,
            insecure=False,
            compression=None,
            wait_for_ready=None,
            timeout=None,
            metadata=None):
        return grpc.experimental.unary_stream(
            request,
            target,
            '/chimera.v1.RuntimeService/RunAgent',
            runtime__pb2.RunAgentRequest.SerializeToString,
            runtime__pb2.RunAgentResponse.FromString,
            options,
            channel_credentials,
            insecure,
            call_credentials,
            compression,
            wait_for_ready,
            timeout,
            metadata,
            _registered_method=True)

    @staticmethod
    def SyncDataSource(request,
            target,
            options=(),
            channel_credentials=None,
            call_credentials=None,
            insecure=False,
            compression=None,
            wait_for_ready=None,
            timeout=None,
            metadata=None):
        return grpc.experimental.unary_unary(
            request,
            target,
            '/chimera.v1.RuntimeService/SyncDataSource',
            runtime__pb2.SyncRequest.SerializeToString,
            runtime__pb2.SyncResponse.FromString,
            options,
            channel_credentials,
            insecure,
            call_credentials,
            compression,
            wait_for_ready,
            timeout,
            metadata,
            _registered_method=True)
</file>

<file path="runtime/rpc/runtime_pb2.py">
# -*- coding: utf-8 -*-
# Generated by the protocol buffer compiler.  DO NOT EDIT!
# NO CHECKED-IN PROTOBUF GENCODE
# source: runtime.proto
# Protobuf Python Version: 6.31.1
"""Generated protocol buffer code."""
from google.protobuf import descriptor as _descriptor
from google.protobuf import descriptor_pool as _descriptor_pool
from google.protobuf import runtime_version as _runtime_version
from google.protobuf import symbol_database as _symbol_database
from google.protobuf.internal import builder as _builder
_runtime_version.ValidateProtobufRuntimeVersion(
    _runtime_version.Domain.PUBLIC,
    6,
    31,
    1,
    '',
    'runtime.proto'
)
# @@protoc_insertion_point(imports)

_sym_db = _symbol_database.Default()




DESCRIPTOR = _descriptor_pool.Default().AddSerializedFile(b'\n\rruntime.proto\x12\nchimera.v1\"\x83\x01\n\x0fRunAgentRequest\x12\x0e\n\x06\x61pp_id\x18\x01 \x01(\t\x12\r\n\x05query\x18\x02 \x01(\t\x12\x12\n\nsession_id\x18\x03 \x01(\t\x12\x17\n\x0f\x61pp_config_json\x18\x04 \x01(\t\x12$\n\x07history\x18\x05 \x03(\x0b\x32\x13.chimera.v1.Message\"(\n\x07Message\x12\x0c\n\x04role\x18\x01 \x01(\t\x12\x0f\n\x07\x63ontent\x18\x02 \x01(\t\"\x7f\n\x10RunAgentResponse\x12\x0c\n\x04type\x18\x01 \x01(\t\x12\x0f\n\x07payload\x18\x02 \x01(\t\x12#\n\x04meta\x18\x03 \x01(\x0b\x32\x15.chimera.v1.AgentMeta\x12\'\n\x07summary\x18\x04 \x01(\x0b\x32\x16.chimera.v1.RunSummary\"E\n\tAgentMeta\x12\x11\n\tnode_name\x18\x01 \x01(\t\x12\x10\n\x08trace_id\x18\x02 \x01(\t\x12\x13\n\x0b\x64uration_ms\x18\x03 \x01(\x03\"\x85\x01\n\nRunSummary\x12\x14\n\x0ctotal_tokens\x18\x01 \x01(\x05\x12\x15\n\rprompt_tokens\x18\x02 \x01(\x05\x12\x19\n\x11\x63ompletion_tokens\x18\x03 \x01(\x05\x12\x19\n\x11total_duration_ms\x18\x04 \x01(\x03\x12\x14\n\x0c\x66inal_status\x18\x05 \x01(\t\"V\n\x0bSyncRequest\x12\r\n\x05kb_id\x18\x01 \x01(\x03\x12\x15\n\rdatasource_id\x18\x02 \x01(\x03\x12\x0c\n\x04type\x18\x03 \x01(\t\x12\x13\n\x0b\x63onfig_json\x18\x04 \x01(\t\"\\\n\x0cSyncResponse\x12\x0f\n\x07success\x18\x01 \x01(\x08\x12\x11\n\terror_msg\x18\x02 \x01(\t\x12\x14\n\x0c\x63hunks_count\x18\x03 \x01(\x05\x12\x12\n\npage_count\x18\x04 \x01(\x05\x32\xa2\x01\n\x0eRuntimeService\x12I\n\x08RunAgent\x12\x1b.chimera.v1.RunAgentRequest\x1a\x1c.chimera.v1.RunAgentResponse\"\x00\x30\x01\x12\x45\n\x0eSyncDataSource\x12\x17.chimera.v1.SyncRequest\x1a\x18.chimera.v1.SyncResponse\"\x00\x42\"Z Chimera/server/api/runtime/v1;v1b\x06proto3')

_globals = globals()
_builder.BuildMessageAndEnumDescriptors(DESCRIPTOR, _globals)
_builder.BuildTopDescriptorsAndMessages(DESCRIPTOR, 'runtime_pb2', _globals)
if not _descriptor._USE_C_DESCRIPTORS:
  _globals['DESCRIPTOR']._loaded_options = None
  _globals['DESCRIPTOR']._serialized_options = b'Z Chimera/server/api/runtime/v1;v1'
  _globals['_RUNAGENTREQUEST']._serialized_start=30
  _globals['_RUNAGENTREQUEST']._serialized_end=161
  _globals['_MESSAGE']._serialized_start=163
  _globals['_MESSAGE']._serialized_end=203
  _globals['_RUNAGENTRESPONSE']._serialized_start=205
  _globals['_RUNAGENTRESPONSE']._serialized_end=332
  _globals['_AGENTMETA']._serialized_start=334
  _globals['_AGENTMETA']._serialized_end=403
  _globals['_RUNSUMMARY']._serialized_start=406
  _globals['_RUNSUMMARY']._serialized_end=539
  _globals['_SYNCREQUEST']._serialized_start=541
  _globals['_SYNCREQUEST']._serialized_end=627
  _globals['_SYNCRESPONSE']._serialized_start=629
  _globals['_SYNCRESPONSE']._serialized_end=721
  _globals['_RUNTIMESERVICE']._serialized_start=724
  _globals['_RUNTIMESERVICE']._serialized_end=886
# @@protoc_insertion_point(module_scope)
</file>

<file path="runtime/runtime/__init__.py">

</file>

<file path="runtime/runtime/state.py">
from typing import Annotated, List, TypedDict
import operator

class AgentState(TypedDict):
    # ç”¨æˆ·è¾“å…¥
    query: str
    kb_id: int
    # è®°å¿†ç‰‡æ®µ (ç”±å„èŠ‚ç‚¹å¡«å……)
    short_term_context: str
    long_term_memory: str
    graph_context: str
    vector_context: str
    # æœ€ç»ˆç»“æœ
    answer: str
    # èŠå¤©å†å² (è‡ªåŠ¨è¿½åŠ )
    history: Annotated[List[str], operator.add]
</file>

<file path="runtime/service/__init__.py">

</file>

<file path="runtime/service/runtime_service.py">
import logging
from typing import Any

from rpc import runtime_pb2, runtime_pb2_grpc
from core.managers.etl_manager import ETLManager
from core.managers.inference_manager import InferenceManager
from core.stores.qdrant_store import QdrantStore

logger = logging.getLogger(__name__)

class ChimeraRuntimeService(runtime_pb2_grpc.RuntimeServiceServicer):
    def __init__(self, qdrant_store: QdrantStore, nebula_store: Any = None):
        """
        ä¾èµ–æ³¨å…¥ï¼šService å±‚ä¸å…³å¿ƒå…·ä½“çš„å­˜å‚¨å®ç°ç»†èŠ‚ï¼Œåªè´Ÿè´£ä¼ é€’ç»™ Manager
        """
        # åˆå§‹åŒ–ä¸šåŠ¡é€»è¾‘ç®¡ç†å™¨
        self.etl_mgr = ETLManager(qdrant_store, nebula_store)
        self.inf_mgr = InferenceManager(qdrant_store, nebula_store)
        logger.info("âœ… RuntimeService initialized (Controller Mode)")

    def SyncDataSource(self, request, context):
        """
        ETL æ•°æ®åŒæ­¥æ¥å£ (Unary Call)
        Go ç«¯è°ƒç”¨æ­¤æ¥å£è§¦å‘æ•°æ®æ¸…æ´—å’Œå…¥åº“
        """
        try:
            # è°ƒç”¨ Manager æ‰§è¡Œé€»è¾‘
            # Manager æ˜¯ä¸ªç”Ÿæˆå™¨ï¼Œä½†å› ä¸º Proto å®šä¹‰æ˜¯ Unary (éæµå¼)ï¼Œ
            # æˆ‘ä»¬åœ¨è¿™é‡Œæ¶ˆè´¹å®Œç”Ÿæˆå™¨ï¼Œåªè¿”å›æœ€åçš„ç»“æœã€‚
            # (å¦‚æœæœªæ¥éœ€è¦å®æ—¶è¿›åº¦æ¡ï¼Œéœ€ä¿®æ”¹ Proto ä¸º stream SyncResponse)
            final_stats = {"chunks": 0, "pages": 0}

            iterator = self.etl_mgr.sync_datasource(
                kb_id=request.kb_id,
                source_id=request.datasource_id,
                source_type=request.type,
                config_json=request.config_json
            )

            for progress in iterator:
                # å¯ä»¥åœ¨è¿™é‡Œæ‰“å°æ—¥å¿—æˆ–è€…å‘é€ metrics
                if "chunks" in progress:
                    final_stats = progress

            return runtime_pb2.SyncResponse(
                success=True,
                chunks_count=final_stats.get("chunks", 0),
                page_count=final_stats.get("pages", 0)
            )

        except Exception as e:
            logger.error(f"âŒ RPC Sync Failed: {str(e)}")
            return runtime_pb2.SyncResponse(
                success=False,
                error_msg=str(e)
            )

    def RunAgent(self, request, context):
        """
        æ™ºèƒ½ä½“å¯¹è¯æ¥å£ (Server Streaming)
        """
        try:
            # è°ƒç”¨ Manager è·å–äº‹ä»¶æµ
            iterator = self.inf_mgr.run_chat(
                query=request.query,
                history=request.history,
                app_config_json=request.app_config_json
            )

            # å°† Manager è¿”å›çš„ Dict è½¬æ¢ä¸º Protobuf Message
            for event in iterator:
                event_type = event.get("type")

                # 1. æ€è€ƒè¿‡ç¨‹
                if event_type == "thought":
                    meta = event.get("meta", {})
                    yield runtime_pb2.RunAgentResponse(
                        type="thought",
                        payload=event.get("payload", ""),
                        meta=runtime_pb2.AgentMeta(
                            node_name=meta.get("node_name", "Agent"),
                            trace_id=meta.get("trace_id", ""),
                            duration_ms=meta.get("duration_ms", 0)
                        )
                    )

                # 2. å¢é‡æ–‡æœ¬ (æ‰“å­—æœºæ•ˆæœ)
                elif event_type == "delta":
                    yield runtime_pb2.RunAgentResponse(
                        type="delta",
                        payload=event.get("payload", "")
                    )

                # 3. å¼•ç”¨æ¥æº
                elif event_type == "reference":
                    yield runtime_pb2.RunAgentResponse(
                        type="reference",
                        payload=event.get("payload", "[]")
                    )

                # 4. æ‰§è¡Œæ‘˜è¦ (End of Stream)
                elif event_type == "summary":
                    s = event.get("summary", {})
                    yield runtime_pb2.RunAgentResponse(
                        type="summary",
                        summary=runtime_pb2.RunSummary(
                            total_tokens=s.get("total_tokens", 0),
                            prompt_tokens=s.get("prompt_tokens", 0),
                            completion_tokens=s.get("completion_tokens", 0),
                            total_duration_ms=s.get("total_duration_ms", 0),
                            final_status=s.get("final_status", "success")
                        )
                    )

                # 5. é€»è¾‘é”™è¯¯
                elif event_type == "error":
                    yield runtime_pb2.RunAgentResponse(
                        type="error",
                        payload=event.get("payload", "Unknown Logic Error")
                    )

        except Exception as e:
            # ç³»ç»Ÿçº§å´©æºƒæ•è·
            logger.error(f"âŒ RPC RunAgent Crashed: {str(e)}")
            yield runtime_pb2.RunAgentResponse(
                type="error",
                payload=f"Internal Server Error: {str(e)}"
            )
</file>

<file path="runtime/skills/__init__.py">

</file>

<file path="runtime/skills/graph_ops.py">
from core.telemetry.tracing import trace_agent

class GraphSkill:
    def __init__(self, nebula_store):
        self.db = nebula_store

    @trace_agent("Skill:Graph_Query")
    def get_entity_relations(self, entity_name: str):
        """
        äº®ç‚¹ï¼šåœ¨å›¾ä¸­æ¢æµ‹è¯¥å®ä½“åŠå…¶å‘¨è¾¹çŸ¥è¯†
        """
        # nGQL è¯­å¥ï¼šæŸ¥æ‰¾ä¸è¯¥å®ä½“ç›¸å…³çš„ 1-2 æ­¥å…³ç³»
        nql = f"""
        MATCH (v:Entity)-[e:RELATION]->(v2)
        WHERE v.Entity.name == '{entity_name}'
        RETURN v.Entity.name, type(e), v2.Entity.name LIMIT 10
        """
        result = self.db.execute(nql)
        return self._format(result)
</file>

<file path="runtime/skills/graph_skill.py">
from core.telemetry.tracing import trace_agent

class GraphSkill:
    def __init__(self, nebula_store):
        self.db = nebula_store

    @trace_agent("Skill:Nebula_Search")
    def find_entity_context(self, entity_name: str):
        # äº®ç‚¹ï¼šä¸ä»…ä»…æ‰¾ç‚¹ï¼Œè¿˜è¦æ‰¾ç›¸å…³çš„ 2 æ­¥è·³è·ƒå…³ç³» (2-hop)
        nql = f"LOOKUP ON Entity WHERE Entity.name == '{entity_name}' YIELD id(vertex) AS vid | " \
              f"GO 1 TO 2 STEPS FROM $-.vid OVER * YIELD DISTINCT properties($$).name, properties(edge).type"

        result = self.db.execute("chimera_kb", nql)
        # æ ¼å¼åŒ–ä¸ºè‡ªç„¶è¯­è¨€ context ä¾› Agent ä½¿ç”¨
        return self._format_result(result)
</file>

<file path="runtime/skills/splitter.py">
from config import Config
from langchain_text_splitters import MarkdownHeaderTextSplitter

class TextSplitter:
    @staticmethod
    def sliding_window(text: str):
        """
        åŸºç¡€çš„æ»‘åŠ¨çª—å£åˆ‡åˆ†ç®—æ³•
        Args:
            text: åŸå§‹æ–‡æœ¬
        Returns:
            List[str]: åˆ‡åˆ†åçš„æ–‡æœ¬å—åˆ—è¡¨
        """
        chunks = []
        start = 0
        text_len = len(text)

        # é˜²æ­¢æ­»å¾ªç¯æˆ–ç©ºæ–‡æœ¬
        if text_len == 0:
            return []

        while start < text_len:
            end = start + Config.CHUNK_SIZE
            # æˆªå–ç‰‡æ®µ
            segment = text[start:end]
            chunks.append(segment)

            # å¦‚æœå‰©ä¸‹çš„æ–‡æœ¬ä¸è¶³ä»¥æ„æˆé‡å ï¼Œç›´æ¥ç»“æŸ
            if end >= text_len:
                break

            # æ»‘åŠ¨æŒ‡é’ˆ
            start += (Config.CHUNK_SIZE - Config.CHUNK_OVERLAP)

        return chunks

    @staticmethod
    def markdown_split(markdown_text: str):
        """
        ğŸ”¥ v0.3.0 æ ¸å¿ƒï¼šåŸºäº Markdown æ ‡é¢˜çš„è¯­ä¹‰åˆ‡åˆ†
        """
        # å®šä¹‰è¦åˆ‡åˆ†çš„æ ‡é¢˜çº§åˆ« (H1, H2, H3)
        headers_to_split_on = [
            ("#", "Header 1"),
            ("##", "Header 2"),
            ("###", "Header 3"),
        ]

        # åˆå§‹åŒ– LangChain åˆ‡åˆ†å™¨
        splitter = MarkdownHeaderTextSplitter(
            headers_to_split_on=headers_to_split_on,
            strip_headers=False # å»ºè®®ä¿ç•™æ ‡é¢˜åœ¨æ­£æ–‡ä¸­ï¼Œä¸Šä¸‹æ–‡æ›´å®Œæ•´
        )

        # æ‰§è¡Œåˆ‡åˆ†
        docs = splitter.split_text(markdown_text)

        final_chunks = []
        for doc in docs:
            # doc.page_content æ˜¯æ­£æ–‡
            # doc.metadata åŒ…å«æ ‡é¢˜è·¯å¾„ {'Header 1': '...', 'Header 2': '...'}

            # ğŸ’¡ æ ¸å¿ƒæŠ€å·§ï¼šå°†æ ‡é¢˜è·¯å¾„æ‹¼å›åˆ°å†…å®¹å‰é¢
            # è¿™æ · LLM å°±ç®—åªçœ‹åˆ°è¿™ä¸€æ®µï¼Œä¹ŸçŸ¥é“å®ƒå±äº "ç¬¬ä¸€ç«  > èƒŒæ™¯ä»‹ç»"
            header_path = " > ".join(doc.metadata.values())
            if header_path:
                content = f"ã€ç« èŠ‚: {header_path}ã€‘\n{doc.page_content}"
            else:
                content = doc.page_content

            final_chunks.append(content)

        return final_chunks
</file>

<file path="runtime/tools/__init__.py">

</file>

<file path="runtime/tools/doc_parser.py">
import logging
import io
from pathlib import Path

# Docling æ ¸å¿ƒç»„ä»¶
from docling.document_converter import DocumentConverter, PdfFormatOption
from docling.datamodel.base_models import InputFormat
from docling.datamodel.pipeline_options import PdfPipelineOptions
from docling.datamodel.document import DocumentStream

# ğŸ”¥ å…³é”®ï¼šHybridChunker åœ¨ docling.chunking ä¸‹
from docling.chunking import HybridChunker

class DoclingParser:
    _converter = None
    _chunker = None
    def __init__(self):
        # é¢„åŠ è½½æ¨¡å‹ï¼Œé¿å…åœ¨è¯·æ±‚ä¸­åˆå§‹åŒ–
        self.converter = DocumentConverter()

    @classmethod
    def _get_components(cls):
        """å•ä¾‹æ¨¡å¼åˆå§‹åŒ– Converter å’Œ Chunker"""
        if cls._converter is None:
            logging.info("ğŸ¢ [Init] æ­£åœ¨åˆå§‹åŒ– Docling æ¨¡å‹ (HybridChunker enabled)...")

            # 1. é…ç½®è½¬æ¢å™¨
            pipeline_options = PdfPipelineOptions()
            pipeline_options.do_ocr = False
            pipeline_options.do_table_structure = True

            cls._converter = DocumentConverter(
                format_options={
                    InputFormat.PDF: PdfFormatOption(pipeline_options=pipeline_options)
                }
            )

            # 2. é…ç½®åˆ‡åˆ†å™¨ (HybridChunker)
            # ä½¿ç”¨ sentence-transformers çš„ tokenizer æ¥è®¡ç®— token æ•°ï¼Œç¡®ä¿åˆ‡ç‰‡ä¸ä¼šè¶…é•¿
            cls._chunker = HybridChunker(
                tokenizer="sentence-transformers/all-MiniLM-L6-v2",
                max_tokens=500, # é€‚åˆ embedding æ¨¡å‹çš„çª—å£å¤§å°
                merge_peers=True,
            )

            logging.info("âœ… [Init] Docling ç»„ä»¶å°±ç»ª")
        return cls._converter, cls._chunker

    @staticmethod
    def parse_and_chunk(file_source, filename="temp.pdf"):
        """
        è§£æ PDF å¹¶è¿”å›å¸¦æœ‰ã€çœŸå®é¡µç ã€‘çš„è¯­ä¹‰åˆ‡ç‰‡
        :param file_source: å¯ä»¥æ˜¯ str (è·¯å¾„), Path (è·¯å¾„), æˆ– bytes (äºŒè¿›åˆ¶)
        """
        converter, chunker = DoclingParser._get_components()
        logging.info(f"ğŸ“„ [Docling] å¼€å§‹è§£æ: {filename}")

        try:
            # 1. æ™ºèƒ½æ„å»ºè¾“å…¥æº
            input_doc = None

            if isinstance(file_source, bytes):
                # Case A: ä¼ å…¥äºŒè¿›åˆ¶æµ (å†…å­˜å¤„ç†)
                logging.info(f"   âš™ï¸ Mode: Bytes Stream ({len(file_source)} bytes)")
                input_doc = DocumentStream(name=filename, stream=io.BytesIO(file_source))
            elif isinstance(file_source, (str, Path)):
                # Case B: ä¼ å…¥æ–‡ä»¶è·¯å¾„ (æ¨èï¼Œæ€§èƒ½æ›´å¥½ä¸”ç¨³å®š)
                logging.info(f"   âš™ï¸ Mode: File Path ({file_source})")
                input_doc = Path(file_source)
            else:
                raise ValueError(f"ä¸æ”¯æŒçš„è¾“å…¥ç±»å‹: {type(file_source)}")

            # 2. æ‰§è¡Œè½¬æ¢ (PDF -> DL Document)
            conv_result = converter.convert(input_doc)
            doc = conv_result.document
            logging.info(f"âœ… [Docling] è½¬æ¢å®Œæˆï¼Œå¼€å§‹ HybridChunker åˆ‡åˆ†...")

            # 3. ä½¿ç”¨ HybridChunker åˆ‡åˆ†
            chunk_iter = chunker.chunk(doc)

            final_chunks = []
            for i, chunk in enumerate(chunk_iter):
                # ğŸ”¥ æå–é¡µç  (è¿½æº¯ Provenance)
                page_num = 1
                if chunk.meta.doc_items:
                    first_item = chunk.meta.doc_items[0]
                    if hasattr(first_item, 'prov') and first_item.prov:
                        page_num = first_item.prov[0].page_no

                # åºåˆ—åŒ–ç»“æœ
                # chunk.text å·²ç»åŒ…å«äº†ä¸Šä¸‹æ–‡ï¼ˆå¦‚æ ‡é¢˜ï¼‰
                final_chunks.append({
                    "content": chunk.text,
                    "page": page_num
                })

            logging.info(f"âœ‚ï¸ [HybridChunker] ç”Ÿæˆäº† {len(final_chunks)} ä¸ªå¸¦æœ‰é¡µç çš„ç‰‡æ®µ")

            return final_chunks

        except Exception as e:
            logging.error(f"âŒ [Docling] è§£æå¤±è´¥: {e}", exc_info=True)
            return []
</file>

<file path="runtime/tools/image_parser.py">

</file>

<file path="runtime/workflows/__init__.py">

</file>

<file path="runtime/workflows/chat_flow.py">
import json
import logging
import os
import yaml
from typing import TypedDict, List, Dict, Any, Generator, Optional
from langgraph.graph import StateGraph, END
from jinja2 import Template

from core.llm.embedding import EmbeddingModel
from core.llm.llm import LLMClient
from core.stores.qdrant_store import QdrantStore
# âŒ å·²åˆ é™¤: from core.stores.graph_store import NebulaStore (è¿™æ˜¯ä¼ä¸šç‰ˆç»„ä»¶ï¼Œä¸èƒ½åœ¨ Core ç›´æ¥å¼•å…¥)
from agents.chat.query_analysis import QueryAnalysisAgent

logger = logging.getLogger(__name__)

# --- çŠ¶æ€å®šä¹‰ ---
class AgentState(TypedDict):
    query: str
    chat_history: List[Dict[str, str]]
    query_entities: List[str]
    retrieved_docs: List[Dict]
    graph_context: List[str]
    answer: str

class ChatWorkflow:
    # ğŸ”¥ ä¿®æ”¹ç‚¹ï¼šnebula ç±»å‹æ”¹ä¸º Anyï¼Œå…è®¸ä¼ å…¥ None
    def __init__(self, nebula: Any, qdrant: QdrantStore, kb_ids: List[int]):
        self.nebula = nebula
        self.qdrant = qdrant
        self.kb_ids = kb_ids

        self.embed_model = EmbeddingModel.get_instance()
        self.llm = LLMClient()
        self.query_analyzer = QueryAnalysisAgent()

        # åŠ è½½ç”Ÿæˆ Prompt
        self.synthesis_prompt_config = self._load_prompt("chat/synthesis.yaml")
        self.app = self._build_graph()

    def _load_prompt(self, filename):
        base_dir = os.getcwd()
        # å…¼å®¹ä¸åŒå¯åŠ¨è·¯å¾„
        if "runtime" not in base_dir and os.path.exists("runtime"):
            base_dir = os.path.join(base_dir, "runtime")

        # å‡è®¾ prompts ç›®å½•åœ¨ runtime/prompts
        path = os.path.join(base_dir, "prompts", filename)

        if not os.path.exists(path):
            # å›é€€å°è¯• (å¤„ç† Docker è·¯å¾„å¯èƒ½ä¸åŒ)
            path = os.path.join("/app/prompts", filename)

        if not os.path.exists(path):
            # å†æ¬¡å›é€€ï¼Œé˜²æ­¢æœ¬åœ°è°ƒè¯•è·¯å¾„é—®é¢˜
            if os.path.exists(f"prompts/{filename}"):
                path = f"prompts/{filename}"
            else:
                # æœ€åçš„å…œåº•ï¼Œå¦‚æœæ˜¯ runtimeservice å¯åŠ¨
                path = os.path.join(os.path.dirname(os.path.dirname(os.path.dirname(__file__))), "prompts", filename)

        if not os.path.exists(path):
            raise FileNotFoundError(f"âŒ æç¤ºè¯æ–‡ä»¶æœªæ‰¾åˆ°: {path}")

        with open(path, 'r', encoding='utf-8') as f:
            return yaml.safe_load(f)

    def _build_graph(self):
        workflow = StateGraph(AgentState)

        workflow.add_node("query_analysis", self.node_query_analysis)
        workflow.add_node("retrieve", self.node_retrieve)
        workflow.add_node("generate", self.node_generate)

        workflow.set_entry_point("query_analysis")
        workflow.add_edge("query_analysis", "retrieve")
        workflow.add_edge("retrieve", "generate")
        workflow.add_edge("generate", END)

        return workflow.compile()

    # --- èŠ‚ç‚¹é€»è¾‘ ---

    def node_query_analysis(self, state: AgentState):
        """æ­¥éª¤ 1: åˆ†æç”¨æˆ· Queryï¼Œæå–å…³é”®å®ä½“"""
        logger.info(f"ğŸ§  [Chat-1] Query Analysis: {state['query']}")
        entities = self.query_analyzer.run(state["query"])
        return {"query_entities": entities}

    def node_retrieve(self, state: AgentState):
        """æ­¥éª¤ 2: åŒè·¯æ£€ç´¢ (Vector + Graph)"""
        query = state["query"]
        entities = state.get("query_entities", [])
        if not entities: entities = [query]

        # A. å‘é‡æ£€ç´¢ (Core)
        vector_results = []
        try:
            query_vec = self.embed_model.encode(query)
            vector_results = self.qdrant.search(query_vec, self.kb_ids, top_k=3)
        except Exception as e:
            logger.error(f"Vector Search Error: {e}")

        # B. å›¾è°±æ£€ç´¢ (Enterprise)
        graph_triplets = []
        # ğŸ”¥ å…³é”®ä¿®æ”¹ï¼šå…ˆæ£€æŸ¥ self.nebula æ˜¯å¦å­˜åœ¨
        if self.nebula:
            try:
                # Duck Typing: åªè¦ä¼ å…¥çš„å¯¹è±¡æœ‰ retrieve_subgraph æ–¹æ³•å°±è¡Œ
                graph_triplets = self.nebula.retrieve_subgraph(entities)
                logger.info(f"ğŸ•¸ï¸ [Chat-2] KG Hit: {len(graph_triplets)} relations")
            except Exception as e:
                logger.error(f"Graph Search Error: {e}")
        else:
            logger.debug("ğŸ•¸ï¸ [Chat-2] Skipping KG (Enterprise feature disabled)")

        return {
            "retrieved_docs": vector_results,
            "graph_context": graph_triplets
        }

    def node_generate(self, state: AgentState):
        return {}

    # --- è¿è¡Œé€»è¾‘ ---

    def run_stream(self, initial_state: dict) -> Generator[Dict[str, Any], None, None]:
        final_state = self.app.invoke(initial_state)

        query = final_state["query"]
        vec_docs = final_state.get("retrieved_docs", [])
        graph_triplets = final_state.get("graph_context", [])

        # ç»„è£… Context
        doc_context_str = "\n".join([f"- {d['content']}" for d in vec_docs])
        if not doc_context_str: doc_context_str = "æ— ç›¸å…³æ–‡æ¡£ç‰‡æ®µã€‚"

        kg_context_str = "\n".join(graph_triplets)
        if not kg_context_str: kg_context_str = "æ— ç›¸å…³çŸ¥è¯†å›¾è°±ä¿¡æ¯ã€‚"

        full_context = f"ã€æ–‡æ¡£ç‰‡æ®µã€‘ï¼š\n{doc_context_str}\n\nã€çŸ¥è¯†å›¾è°±è·¯å¾„ã€‘ï¼š\n{kg_context_str}"

        # æ¸²æŸ“ Prompt
        sys_tmpl = self.synthesis_prompt_config.get("system", "")
        user_tmpl = self.synthesis_prompt_config.get("user", "")

        system_prompt = Template(sys_tmpl).render(full_context=full_context)
        user_prompt_content = Template(user_tmpl).render(query=query)

        # æµå¼ç”Ÿæˆ
        try:
            for event in self.llm.stream_chat(
                    query=user_prompt_content,
                    system_prompt=system_prompt,
                    history=initial_state.get("history", [])
            ):
                if event["type"] == "content":
                    yield {"type": "delta", "content": event["data"]}
                elif event["type"] == "usage":
                    yield {"type": "usage", "usage": event["data"]}
        except Exception as e:
            logger.error(f"LLM Generation Error: {e}")
            yield {"type": "error", "content": str(e)}
</file>

<file path="runtime/__init__.py">

</file>

<file path="runtime/.dockerignore">
# runtime/.dockerignore
enterprise/
__pycache__/
.env
</file>

<file path="runtime/config.py">
import os
from dotenv import load_dotenv

# åŠ è½½ .env æ–‡ä»¶ä¸­çš„ç¯å¢ƒå˜é‡
load_dotenv()

class Config:
    # --- åŸºç¡€æœåŠ¡é…ç½® ---
    PORT = int(os.getenv("PORT", 50051))
    # å…è®¸ä¼ è¾“çš„å¤§æ–‡ä»¶é™åˆ¶ (100MB)
    MAX_MESSAGE_LENGTH = 100 * 1024 * 1024
    # å¹¶è¡Œä»»åŠ¡æ•°
    MAX_WORKERS = int(os.getenv("MAX_WORKERS", 10))

    # --- é“¾è·¯è¿½è¸ªé…ç½® (OTel) ---
    OTEL_ENDPOINT = os.getenv("OTEL_ENDPOINT", "localhost:4317")
    SERVICE_NAME = "chimera-brain-python"

    # --- æ¨¡å‹ä¸ AI é…ç½® ---
    DEEPSEEK_API_KEY = os.getenv("DEEPSEEK_API_KEY")
    DEEPSEEK_BASE_URL = os.getenv("DEEPSEEK_BASE_URL", "https://api.deepseek.com")
    EMBEDDING_MODEL_PATH = os.getenv("EMBEDDING_MODEL_PATH", "AI-ModelScope/all-MiniLM-L6-v2")

    # --- å­˜å‚¨å±‚é…ç½® ---

    # 1. NebulaGraph é…ç½®
    NEBULA_HOST = os.getenv("NEBULA_HOST", "127.0.0.1")
    NEBULA_PORT = int(os.getenv("NEBULA_PORT", 9669))
    NEBULA_USER = os.getenv("NEBULA_USER", "root")
    NEBULA_PASSWORD = os.getenv("NEBULA_PASSWORD", "nebula")
    NEBULA_SPACE = os.getenv("NEBULA_SPACE", "chimera_kb")

    # 2. Qdrant é…ç½®
    QDRANT_HOST = os.getenv("QDRANT_HOST", "127.0.0.1")
    QDRANT_PORT = int(os.getenv("QDRANT_PORT", 6333))

    # 3. Redis é…ç½®
    REDIS_HOST = os.getenv("REDIS_HOST", "127.0.0.1")
    REDIS_PORT = int(os.getenv("REDIS_PORT", 6379))

    # ğŸ”¥ 4. MinIO é…ç½® (æ–°å¢)
    # æ³¨æ„ï¼šæœ¬åœ°è¿è¡Œæ—¶å¦‚æœè¿ Docker é‡Œçš„ MinIOï¼Œhost åº”è¯¥æ˜¯ localhost:9000
    MINIO_ENDPOINT = os.getenv("MINIO_ENDPOINT", "localhost:9000")
    MINIO_ACCESS_KEY = os.getenv("MINIO_ACCESS_KEY", "chimera_minio")
    MINIO_SECRET_KEY = os.getenv("MINIO_SECRET_KEY", "chimera_minio_secret")
    # æ¡¶åç§°è¦å’Œ Go ç«¯ä¿æŒä¸€è‡´
    MINIO_BUCKET = os.getenv("MINIO_BUCKET", "chimera-docs")

    # --- ä¸šåŠ¡å‚æ•° ---
    CHUNK_SIZE = int(os.getenv("CHUNK_SIZE", 500))
    CHUNK_OVERLAP = int(os.getenv("CHUNK_OVERLAP", 50))

    @staticmethod
    def validate():
        required_keys = {
            "DEEPSEEK_API_KEY": Config.DEEPSEEK_API_KEY,
            # "NEBULA_HOST": Config.NEBULA_HOST
            # æš‚æ—¶æ³¨é‡Šæ‰ NEBULA æ£€æŸ¥ï¼Œå¦‚æœè¿˜æ²¡é…å¥½å¯ä»¥å…ˆè·‘é€š MinIO
        }
        for name, value in required_keys.items():
            if not value:
                raise ValueError(f"âŒ å…³é”®é…ç½®ç¼ºå¤±: {name}ã€‚è¯·æ£€æŸ¥ .env æ–‡ä»¶ã€‚")
        print(f"âœ… é…ç½®æ–‡ä»¶æ ¡éªŒé€šè¿‡ï¼Œå‡†å¤‡å¯åŠ¨ {Config.SERVICE_NAME}...")

# æ‰§è¡Œæ ¡éªŒ
Config.validate()
</file>

<file path="runtime/Dockerfile">
# runtime/Dockerfile (Core)
FROM python:3.10-slim

WORKDIR /app
COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt -i https://pypi.tuna.tsinghua.edu.cn/simple

# ğŸ”¥ åªå¤åˆ¶ Core ä»£ç  (åˆ©ç”¨ .dockerignore æ’é™¤ enterprise ç›®å½•)
COPY . .

ENV PYTHONPATH=/app
EXPOSE 50051
CMD ["python", "main.py"]
</file>

<file path="runtime/Dockerfile.ee">
# runtime/Dockerfile.ee (Enterprise)
# åŸºäºå¼€æºç‰ˆé•œåƒæ„å»º (å‡è®¾å¼€æºç‰ˆ tag ä¸º chimera-runtime:core)
# å¦‚æœæ˜¯åœ¨ CI/CD ä¸­ï¼Œå¯ä»¥ç›´æ¥åŸºäº python:3.10-slim é‡æ–°æ„å»ºï¼Œè¿™é‡Œä¸ºäº†æ¼”ç¤ºåˆ†å±‚
FROM python:3.10-slim

WORKDIR /app
# ... (é‡å¤å®‰è£…ä¾èµ–æ­¥éª¤ï¼Œæˆ–è€…ç›´æ¥ COPY ä¹‹å‰çš„) ...
COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt -i https://pypi.tuna.tsinghua.edu.cn/simple

# 1. å…ˆå¤åˆ¶ Core
COPY . .

# 2. ğŸ”¥ æ˜¾å¼å¤åˆ¶ Enterprise ç›®å½• (è¦†ç›– .dockerignore çš„è§„åˆ™)
# æ³¨æ„ï¼šDocker build context éœ€è¦åŒ…å« enterprise ç›®å½•
COPY enterprise ./enterprise

ENV PYTHONPATH=/app
EXPOSE 50051
CMD ["python", "main.py"]
</file>

<file path="runtime/loader.py">
import os
import logging
import importlib
import pkgutil

logger = logging.getLogger(__name__)

def load_enterprise_plugins():
    """
    è‡ªåŠ¨æ‰«æå¹¶åŠ è½½ enterprise ç›®å½•ä¸‹çš„æ‰©å±•æ¨¡å—ã€‚
    è¿”å›: bool (æ˜¯å¦åŠ è½½äº†ä¼ä¸šç‰ˆç»„ä»¶)
    """
    # è·å–å½“å‰æ–‡ä»¶æ‰€åœ¨ç›®å½• (runtime/)
    base_dir = os.path.dirname(os.path.abspath(__file__))
    enterprise_dir = os.path.join(base_dir, "enterprise")

    # 1. æ£€æŸ¥ç›®å½•æ˜¯å¦å­˜åœ¨
    if not os.path.exists(enterprise_dir):
        logger.info("â„¹ï¸ [Loader] No 'enterprise' directory found. Running in Community Edition.")
        return False

    # ç¡®ä¿ runtime ç›®å½•åœ¨ sys.path ä¸­ï¼Œä»¥ä¾¿å¯ä»¥ import enterprise...
    # (é€šå¸¸è¿è¡Œ main.py æ—¶å·²ç»åœ¨è·¯å¾„ä¸­äº†ï¼Œè¿™é‡Œæ˜¯åŒé‡ä¿é™©)

    loaded_any = False

    # 2. æ‰«æå¹¶åŠ è½½è¿æ¥å™¨ (Connectors)
    # ç›®æ ‡è·¯å¾„: runtime/enterprise/core/connectors/
    connectors_path = os.path.join(enterprise_dir, "core", "connectors")
    if os.path.exists(connectors_path):
        # ä½¿ç”¨ pkgutil éå†ç›®å½•ä¸‹çš„æ‰€æœ‰ .py æ–‡ä»¶
        for _, name, _ in pkgutil.iter_modules([connectors_path]):
            if name == "__init__": continue

            module_name = f"enterprise.core.connectors.{name}"
            try:
                importlib.import_module(module_name)
                logger.info(f"ğŸ”“ [Loader] Activated Enterprise Connector: {name}")
                loaded_any = True
            except Exception as e:
                logger.warning(f"âš ï¸ [Loader] Failed to load connector '{name}': {e}")

    # 3. è¿™é‡Œå¯ä»¥æ‰©å±•åŠ è½½å…¶ä»–ç»„ä»¶ (å¦‚ Workflows, Tools)

    if loaded_any:
        logger.info("âœ… Enterprise environment initialized.")
    else:
        logger.info("â„¹ï¸ Enterprise directory exists but no plugins loaded.")

    return True
</file>

<file path="runtime/main.py">
import logging
import grpc
import os
import sys
from concurrent import futures
from config import Config

# OpenTelemetry
from opentelemetry.instrumentation.grpc import GrpcInstrumentorServer
from core.telemetry.tracing import setup_otel

# Core Stores
from core.stores.qdrant_store import QdrantStore

# Service & Loader
from service.runtime_service import ChimeraRuntimeService
from loader import load_enterprise_plugins # ğŸ‘ˆ å¼•å…¥åˆšæ‰å†™çš„åŠ è½½å™¨

# Generated RPC Path Fix
rpc_path = os.path.join(os.path.dirname(__file__), 'rpc')
if rpc_path not in sys.path:
    sys.path.insert(0, rpc_path)
from rpc import runtime_pb2_grpc

def serve():
    # 1. åˆå§‹åŒ–æ—¥å¿—
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
    )
    logger = logging.getLogger(__name__)

    # 2. å°è¯•åŠ è½½ä¼ä¸šç‰ˆæ’ä»¶ (é£ä¹¦ã€é’‰é’‰ç­‰)
    # è¿™ä¼šè§¦å‘ ConnectorFactory.registerï¼Œä½¿å¾—åç»­é€»è¾‘èƒ½æ‰¾åˆ°è¿™äº›è¿æ¥å™¨
    has_enterprise = load_enterprise_plugins()

    # 3. åˆå§‹åŒ–é“¾è·¯è¿½è¸ª
    setup_otel(service_name=Config.SERVICE_NAME, endpoint=Config.OTEL_ENDPOINT)

    # 4. åˆå§‹åŒ–å­˜å‚¨å±‚
    logger.info("ğŸ“¦ Initializing Storage Engines...")

    # Qdrant (Core - å¿…é¡»)
    try:
        qdrant_store = QdrantStore()
    except Exception as e:
        logger.critical(f"âŒ Qdrant init failed: {e}")
        sys.exit(1)

    # Nebula (Enterprise - å¯é€‰)
    nebula_store = None
    # åªæœ‰å½“æ£€æµ‹åˆ°ä¼ä¸šç‰ˆç¯å¢ƒï¼Œä¸”é…ç½®æ–‡ä»¶é‡Œæœ‰ Nebula åœ°å€æ—¶ï¼Œæ‰å°è¯•è¿æ¥
    if has_enterprise and getattr(Config, "NEBULA_HOST", None):
        try:
            # åŠ¨æ€ Importï¼Œé¿å… Core ç‰ˆå› ç¼ºå°‘åº“è€ŒæŠ¥é”™
            # æ³¨æ„ï¼šç‰©ç†æ‹†åˆ†åï¼Œè¿™ä¸ªè·¯å¾„å¯èƒ½æ˜¯ enterprise.core.stores.graph_store
            # ä¸ºäº†å…¼å®¹å½“å‰è·¯å¾„ï¼Œæˆ‘ä»¬å…ˆå°è¯•æ ‡å‡†è·¯å¾„ï¼Œå¦‚æœæŠ¥é”™å†å°è¯• enterprise è·¯å¾„
            try:
                from core.stores.graph_store import NebulaStore
            except ImportError:
                from enterprise.core.stores.graph_store import NebulaStore

            nebula_store = NebulaStore(Config)
            logger.info("âœ… NebulaGraph Connected (GraphRAG Enabled)")
        except ImportError:
            logger.warning("âš ï¸ NebulaStore module not found in Enterprise package.")
        except Exception as e:
            logger.warning(f"âš ï¸ NebulaGraph connection failed (Logic will degrade to Vector-Only): {e}")

    # 5. åˆå§‹åŒ– gRPC Server
    instrumentor = GrpcInstrumentorServer()
    if not instrumentor.is_instrumented_by_opentelemetry:
        instrumentor.instrument()

    server = grpc.server(
        futures.ThreadPoolExecutor(max_workers=getattr(Config, 'MAX_WORKERS', 10)),
        options=[
            ('grpc.max_send_message_length', Config.MAX_MESSAGE_LENGTH),
            ('grpc.max_receive_message_length', Config.MAX_MESSAGE_LENGTH),
        ]
    )

    # 6. æ³¨å†ŒæœåŠ¡ (æ³¨å…¥ Store ä¾èµ–)
    # RuntimeService ç°åœ¨æ˜¯ä¸€ä¸ªçº¯ Controllerï¼Œå®ƒä¼šå°† Store ä¼ ç»™ Managers
    runtime_pb2_grpc.add_RuntimeServiceServicer_to_server(
        ChimeraRuntimeService(qdrant_store, nebula_store),
        server
    )

    # 7. å¯åŠ¨
    server.add_insecure_port(f'[::]:{Config.PORT}')
    logger.info(f"ğŸ§  Chimera Runtime v0.6.0 running on port {Config.PORT}...")
    server.start()
    server.wait_for_termination()

if __name__ == '__main__':
    serve()
</file>

<file path="runtime/requirements.txt">
grpcio>=1.60.0
grpcio-tools>=1.60.0
qdrant-client>=1.7.3
langchain-text-splitters
openai>=1.0.0
python-dotenv
opentelemetry-api
opentelemetry-sdk
opentelemetry-exporter-otlp
opentelemetry-instrumentation-grpc
docling>=1.0.0
minio
nebula3-python>=3.0.0
sentence-transformers
langgraph>=0.0.10
langchain>=0.1.0
PyYAML>=6.0.1
</file>

<file path="scripts/dev_infra.sh">
#!/bin/bash

# ========================================================
# Chimera æœ¬åœ°å¼€å‘åŸºç¡€è®¾æ–½å¯åŠ¨è„šæœ¬
# ç”¨é€”: ä»…å¯åŠ¨æ•°æ®åº“ã€ç¼“å­˜ç­‰ä¾èµ–æœåŠ¡ï¼Œä¸å¯åŠ¨ Server/Runtime åº”ç”¨
# ========================================================

# å®šä¹‰é¢œè‰²
GREEN='\033[0;32m'
BLUE='\033[0;34m'
YELLOW='\033[1;33m'
NC='\033[0m' # No Color

# åŸºç¡€æœåŠ¡åˆ—è¡¨ (OSS & EE é€šç”¨)
# æ³¨æ„ï¼šè¿™é‡Œä½¿ç”¨çš„æ˜¯ docker-compose.yml ä¸­çš„ service name
BASE_SERVICES="postgres redis minio qdrant otel-collector"

# ä¼ä¸šç‰ˆä¸“å±æœåŠ¡ (NebulaGraph é›†ç¾¤)
EE_SERVICES="nebula-metad nebula-graphd nebula-storaged"

# å¸®åŠ©ä¿¡æ¯
usage() {
    echo -e "ç”¨æ³•: $0 [command] [mode]"
    echo ""
    echo "Commands:"
    echo "  up      å¯åŠ¨åŸºç¡€è®¾æ–½"
    echo "  down    åœæ­¢å¹¶ç§»é™¤åŸºç¡€è®¾æ–½"
    echo ""
    echo "Modes:"
    echo "  oss     (é»˜è®¤) å¯åŠ¨å¼€æºç‰ˆåŸºç¡€æœåŠ¡ (PG, Redis, MinIO, Qdrant)"
    echo "  ee      å¯åŠ¨ä¼ä¸šç‰ˆå…¨é‡æœåŠ¡ (åŒ…å« NebulaGraph)"
    echo ""
    echo "ç¤ºä¾‹:"
    echo "  $0 up oss    # å¯åŠ¨å¼€æºç‰ˆèµ„æº"
    echo "  $0 up ee     # å¯åŠ¨ä¼ä¸šç‰ˆèµ„æº"
    echo "  $0 down      # å…³é—­æ‰€æœ‰èµ„æº"
    exit 1
}

# æ£€æŸ¥å‚æ•°
COMMAND=$1
MODE=${2:-oss} # é»˜è®¤ä¸º oss

if [ -z "$COMMAND" ]; then
    usage
fi

# è¿›å…¥ deploy ç›®å½• (ç¡®ä¿ docker-compose ä¸Šä¸‹æ–‡æ­£ç¡®)
cd deploy || { echo "âŒ æ‰¾ä¸åˆ° deploy ç›®å½•ï¼Œè¯·åœ¨é¡¹ç›®æ ¹ç›®å½•è¿è¡Œæ­¤è„šæœ¬"; exit 1; }

# =======================
# å¯åŠ¨é€»è¾‘ (UP)
# =======================
if [ "$COMMAND" == "up" ]; then
    if [ "$MODE" == "ee" ]; then
        echo -e "${BLUE}ğŸš€ æ­£åœ¨å¯åŠ¨ [ä¼ä¸šç‰ˆ] åŸºç¡€è®¾æ–½...${NC}"
        echo -e "${YELLOW}åŒ…å«æœåŠ¡: $BASE_SERVICES $EE_SERVICES${NC}"

        # ä½¿ç”¨ EE é…ç½®æ–‡ä»¶ï¼ŒæŒ‡å®šå¯åŠ¨å…·ä½“çš„ Serviceï¼Œå¿½ç•¥ server/runtime/web
        docker-compose -f docker-compose-ee.yml up -d $BASE_SERVICES $EE_SERVICES

    else
        echo -e "${GREEN}ğŸŒ± æ­£åœ¨å¯åŠ¨ [å¼€æºç‰ˆ] åŸºç¡€è®¾æ–½...${NC}"
        echo -e "${YELLOW}åŒ…å«æœåŠ¡: $BASE_SERVICES${NC}"

        # ä½¿ç”¨ OSS é…ç½®æ–‡ä»¶
        docker-compose -f docker-compose.yml up -d $BASE_SERVICES
    fi

    echo ""
    echo -e "âœ… åŸºç¡€è®¾æ–½å¯åŠ¨å®Œæ¯•ï¼"
    echo -e "ğŸ‘‰ Postgres: :5432"
    echo -e "ğŸ‘‰ Redis:    :6379"
    echo -e "ğŸ‘‰ MinIO:    :9000 (Console :9001)"
    echo -e "ğŸ‘‰ Qdrant:   :6333"
    if [ "$MODE" == "ee" ]; then
        echo -e "ğŸ‘‰ Nebula:   :9669"
    fi

# =======================
# åœæ­¢é€»è¾‘ (DOWN)
# =======================
elif [ "$COMMAND" == "down" ]; then
    echo -e "${YELLOW}ğŸ›‘ æ­£åœ¨åœæ­¢æ‰€æœ‰åŸºç¡€è®¾æ–½...${NC}"

    # å°è¯•åœæ­¢ä¸¤ä¸ªé…ç½®æ–‡ä»¶å®šä¹‰çš„æ‰€æœ‰å®¹å™¨
    docker-compose -f docker-compose-ee.yml down 2>/dev/null
    docker-compose -f docker-compose.yml down 2>/dev/null

    echo -e "âœ… æ‰€æœ‰æœåŠ¡å·²åœæ­¢ã€‚"

else
    usage
fi

# å›åˆ°åŸç›®å½•
cd ..
</file>

<file path="scripts/dev_setup.sh">
#!/bin/bash

# å®šä¹‰è·¯å¾„
CORE_ROOT=$(pwd)
ENT_REPO="../chimera-enterprise"

echo "ğŸ”§ åˆå§‹åŒ–æœ¬åœ°å¼€å‘ç¯å¢ƒ..."

# 1. æ£€æŸ¥ç§æœ‰ä»“åº“æ˜¯å¦å­˜åœ¨
if [ ! -d "$ENT_REPO" ]; then
    echo "âŒ æœªæ‰¾åˆ°å…„å¼Ÿç›®å½• ../chimera-enterpriseï¼Œä»…é…ç½®å¼€æºç¯å¢ƒã€‚"
else
    echo "âœ… å‘ç°ä¼ä¸šç‰ˆä»“åº“ï¼Œæ­£åœ¨å»ºç«‹è½¯é“¾æ¥..."

    # Python Runtime é“¾æ¥
    rm -rf runtime/enterprise # å…ˆæ¸…ç†å¯èƒ½çš„ç©ºç›®å½•
    ln -s "$CORE_ROOT/$ENT_REPO/runtime/enterprise" "$CORE_ROOT/runtime/enterprise"
    echo "ğŸ”— Python Enterprise Linked."

    # Go Server é“¾æ¥
    rm -rf server/enterprise
    ln -s "$CORE_ROOT/$ENT_REPO/server/enterprise" "$CORE_ROOT/server/enterprise"
    echo "ğŸ”— Go Enterprise Linked."
fi

echo "ğŸ‰ å¼€å‘ç¯å¢ƒå°±ç»ªï¼"
echo "ğŸ‘‰ æ ¸å¿ƒä»£ç ä¿®æ”¹ -> æäº¤åˆ° Chimera"
echo "ğŸ‘‰ ä¼ä¸šç›®å½•ä¿®æ”¹ -> æäº¤åˆ° chimera-enterprise"
</file>

<file path="scripts/install_plugins.sh">
#!/bin/bash

# å®šä¹‰ä¼ä¸šç‰ˆä»“åº“çš„æœ¬åœ°è·¯å¾„ (æ ¹æ®ä½ çš„å®é™…ä½ç½®ä¿®æ”¹)
ENT_REPO="../chimera-enterprise"

echo "ğŸ”Œ æ­£åœ¨å®‰è£…ä¼ä¸šçº§æ’ä»¶..."

if [ -d "$ENT_REPO" ]; then
    # 1. å¤åˆ¶ Python æ’ä»¶
    # -r é€’å½’, -u æ›´æ–°(ä»…å¤åˆ¶è¾ƒæ–°çš„æ–‡ä»¶), -v æ˜¾ç¤ºè¿‡ç¨‹
    cp -r "$ENT_REPO/runtime/enterprise/" ./runtime/enterprise/

    # 2. å¤åˆ¶ Go æ’ä»¶
    cp -r "$ENT_REPO/server/enterprise/" ./server/enterprise/

    echo "âœ… ä¼ä¸šç‰ˆæ’ä»¶å·²æ³¨å…¥ï¼ç°åœ¨å¯ä»¥è¿è¡Œ Enterprise æ¨¡å¼ã€‚"
else
    echo "âŒ æœªæ‰¾åˆ°ä¼ä¸šç‰ˆä»“åº“: $ENT_REPO"
    echo "   è¯·æ£€æŸ¥è·¯å¾„ï¼Œæˆ–ä»…è¿è¡Œå¼€æºç‰ˆæœ¬ã€‚"
fi
</file>

<file path="server/api/runtime/v1/runtime_grpc.pb.go">
// Code generated by protoc-gen-go-grpc. DO NOT EDIT.
// versions:
// - protoc-gen-go-grpc v1.6.0
// - protoc             v6.32.0
// source: api/runtime/v1/runtime.proto

package v1

import (
	context "context"
	grpc "google.golang.org/grpc"
	codes "google.golang.org/grpc/codes"
	status "google.golang.org/grpc/status"
)

// This is a compile-time assertion to ensure that this generated file
// is compatible with the grpc package it is being compiled against.
// Requires gRPC-Go v1.64.0 or later.
const _ = grpc.SupportPackageIsVersion9

const (
	RuntimeService_RunAgent_FullMethodName       = "/chimera.v1.RuntimeService/RunAgent"
	RuntimeService_SyncDataSource_FullMethodName = "/chimera.v1.RuntimeService/SyncDataSource"
)

// RuntimeServiceClient is the client API for RuntimeService service.
//
// For semantics around ctx use and closing/ending streaming RPCs, please refer to https://pkg.go.dev/google.golang.org/grpc/?tab=doc#ClientConn.NewStream.
type RuntimeServiceClient interface {
	RunAgent(ctx context.Context, in *RunAgentRequest, opts ...grpc.CallOption) (grpc.ServerStreamingClient[RunAgentResponse], error)
	SyncDataSource(ctx context.Context, in *SyncRequest, opts ...grpc.CallOption) (*SyncResponse, error)
}

type runtimeServiceClient struct {
	cc grpc.ClientConnInterface
}

func NewRuntimeServiceClient(cc grpc.ClientConnInterface) RuntimeServiceClient {
	return &runtimeServiceClient{cc}
}

func (c *runtimeServiceClient) RunAgent(ctx context.Context, in *RunAgentRequest, opts ...grpc.CallOption) (grpc.ServerStreamingClient[RunAgentResponse], error) {
	cOpts := append([]grpc.CallOption{grpc.StaticMethod()}, opts...)
	stream, err := c.cc.NewStream(ctx, &RuntimeService_ServiceDesc.Streams[0], RuntimeService_RunAgent_FullMethodName, cOpts...)
	if err != nil {
		return nil, err
	}
	x := &grpc.GenericClientStream[RunAgentRequest, RunAgentResponse]{ClientStream: stream}
	if err := x.ClientStream.SendMsg(in); err != nil {
		return nil, err
	}
	if err := x.ClientStream.CloseSend(); err != nil {
		return nil, err
	}
	return x, nil
}

// This type alias is provided for backwards compatibility with existing code that references the prior non-generic stream type by name.
type RuntimeService_RunAgentClient = grpc.ServerStreamingClient[RunAgentResponse]

func (c *runtimeServiceClient) SyncDataSource(ctx context.Context, in *SyncRequest, opts ...grpc.CallOption) (*SyncResponse, error) {
	cOpts := append([]grpc.CallOption{grpc.StaticMethod()}, opts...)
	out := new(SyncResponse)
	err := c.cc.Invoke(ctx, RuntimeService_SyncDataSource_FullMethodName, in, out, cOpts...)
	if err != nil {
		return nil, err
	}
	return out, nil
}

// RuntimeServiceServer is the server API for RuntimeService service.
// All implementations must embed UnimplementedRuntimeServiceServer
// for forward compatibility.
type RuntimeServiceServer interface {
	RunAgent(*RunAgentRequest, grpc.ServerStreamingServer[RunAgentResponse]) error
	SyncDataSource(context.Context, *SyncRequest) (*SyncResponse, error)
	mustEmbedUnimplementedRuntimeServiceServer()
}

// UnimplementedRuntimeServiceServer must be embedded to have
// forward compatible implementations.
//
// NOTE: this should be embedded by value instead of pointer to avoid a nil
// pointer dereference when methods are called.
type UnimplementedRuntimeServiceServer struct{}

func (UnimplementedRuntimeServiceServer) RunAgent(*RunAgentRequest, grpc.ServerStreamingServer[RunAgentResponse]) error {
	return status.Error(codes.Unimplemented, "method RunAgent not implemented")
}
func (UnimplementedRuntimeServiceServer) SyncDataSource(context.Context, *SyncRequest) (*SyncResponse, error) {
	return nil, status.Error(codes.Unimplemented, "method SyncDataSource not implemented")
}
func (UnimplementedRuntimeServiceServer) mustEmbedUnimplementedRuntimeServiceServer() {}
func (UnimplementedRuntimeServiceServer) testEmbeddedByValue()                        {}

// UnsafeRuntimeServiceServer may be embedded to opt out of forward compatibility for this service.
// Use of this interface is not recommended, as added methods to RuntimeServiceServer will
// result in compilation errors.
type UnsafeRuntimeServiceServer interface {
	mustEmbedUnimplementedRuntimeServiceServer()
}

func RegisterRuntimeServiceServer(s grpc.ServiceRegistrar, srv RuntimeServiceServer) {
	// If the following call panics, it indicates UnimplementedRuntimeServiceServer was
	// embedded by pointer and is nil.  This will cause panics if an
	// unimplemented method is ever invoked, so we test this at initialization
	// time to prevent it from happening at runtime later due to I/O.
	if t, ok := srv.(interface{ testEmbeddedByValue() }); ok {
		t.testEmbeddedByValue()
	}
	s.RegisterService(&RuntimeService_ServiceDesc, srv)
}

func _RuntimeService_RunAgent_Handler(srv interface{}, stream grpc.ServerStream) error {
	m := new(RunAgentRequest)
	if err := stream.RecvMsg(m); err != nil {
		return err
	}
	return srv.(RuntimeServiceServer).RunAgent(m, &grpc.GenericServerStream[RunAgentRequest, RunAgentResponse]{ServerStream: stream})
}

// This type alias is provided for backwards compatibility with existing code that references the prior non-generic stream type by name.
type RuntimeService_RunAgentServer = grpc.ServerStreamingServer[RunAgentResponse]

func _RuntimeService_SyncDataSource_Handler(srv interface{}, ctx context.Context, dec func(interface{}) error, interceptor grpc.UnaryServerInterceptor) (interface{}, error) {
	in := new(SyncRequest)
	if err := dec(in); err != nil {
		return nil, err
	}
	if interceptor == nil {
		return srv.(RuntimeServiceServer).SyncDataSource(ctx, in)
	}
	info := &grpc.UnaryServerInfo{
		Server:     srv,
		FullMethod: RuntimeService_SyncDataSource_FullMethodName,
	}
	handler := func(ctx context.Context, req interface{}) (interface{}, error) {
		return srv.(RuntimeServiceServer).SyncDataSource(ctx, req.(*SyncRequest))
	}
	return interceptor(ctx, in, info, handler)
}

// RuntimeService_ServiceDesc is the grpc.ServiceDesc for RuntimeService service.
// It's only intended for direct use with grpc.RegisterService,
// and not to be introspected or modified (even as a copy)
var RuntimeService_ServiceDesc = grpc.ServiceDesc{
	ServiceName: "chimera.v1.RuntimeService",
	HandlerType: (*RuntimeServiceServer)(nil),
	Methods: []grpc.MethodDesc{
		{
			MethodName: "SyncDataSource",
			Handler:    _RuntimeService_SyncDataSource_Handler,
		},
	},
	Streams: []grpc.StreamDesc{
		{
			StreamName:    "RunAgent",
			Handler:       _RuntimeService_RunAgent_Handler,
			ServerStreams: true,
		},
	},
	Metadata: "api/runtime/v1/runtime.proto",
}
</file>

<file path="server/api/runtime/v1/runtime.pb.go">
// Code generated by protoc-gen-go. DO NOT EDIT.
// versions:
// 	protoc-gen-go v1.36.11
// 	protoc        v6.32.0
// source: api/runtime/v1/runtime.proto

package v1

import (
	protoreflect "google.golang.org/protobuf/reflect/protoreflect"
	protoimpl "google.golang.org/protobuf/runtime/protoimpl"
	reflect "reflect"
	sync "sync"
	unsafe "unsafe"
)

const (
	// Verify that this generated code is sufficiently up-to-date.
	_ = protoimpl.EnforceVersion(20 - protoimpl.MinVersion)
	// Verify that runtime/protoimpl is sufficiently up-to-date.
	_ = protoimpl.EnforceVersion(protoimpl.MaxVersion - 20)
)

type RunAgentRequest struct {
	state         protoimpl.MessageState `protogen:"open.v1"`
	AppId         string                 `protobuf:"bytes,1,opt,name=app_id,json=appId,proto3" json:"app_id,omitempty"`
	Query         string                 `protobuf:"bytes,2,opt,name=query,proto3" json:"query,omitempty"`
	SessionId     string                 `protobuf:"bytes,3,opt,name=session_id,json=sessionId,proto3" json:"session_id,omitempty"`
	AppConfigJson string                 `protobuf:"bytes,4,opt,name=app_config_json,json=appConfigJson,proto3" json:"app_config_json,omitempty"`
	History       []*Message             `protobuf:"bytes,5,rep,name=history,proto3" json:"history,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *RunAgentRequest) Reset() {
	*x = RunAgentRequest{}
	mi := &file_api_runtime_v1_runtime_proto_msgTypes[0]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *RunAgentRequest) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*RunAgentRequest) ProtoMessage() {}

func (x *RunAgentRequest) ProtoReflect() protoreflect.Message {
	mi := &file_api_runtime_v1_runtime_proto_msgTypes[0]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use RunAgentRequest.ProtoReflect.Descriptor instead.
func (*RunAgentRequest) Descriptor() ([]byte, []int) {
	return file_api_runtime_v1_runtime_proto_rawDescGZIP(), []int{0}
}

func (x *RunAgentRequest) GetAppId() string {
	if x != nil {
		return x.AppId
	}
	return ""
}

func (x *RunAgentRequest) GetQuery() string {
	if x != nil {
		return x.Query
	}
	return ""
}

func (x *RunAgentRequest) GetSessionId() string {
	if x != nil {
		return x.SessionId
	}
	return ""
}

func (x *RunAgentRequest) GetAppConfigJson() string {
	if x != nil {
		return x.AppConfigJson
	}
	return ""
}

func (x *RunAgentRequest) GetHistory() []*Message {
	if x != nil {
		return x.History
	}
	return nil
}

type Message struct {
	state         protoimpl.MessageState `protogen:"open.v1"`
	Role          string                 `protobuf:"bytes,1,opt,name=role,proto3" json:"role,omitempty"`
	Content       string                 `protobuf:"bytes,2,opt,name=content,proto3" json:"content,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *Message) Reset() {
	*x = Message{}
	mi := &file_api_runtime_v1_runtime_proto_msgTypes[1]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *Message) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*Message) ProtoMessage() {}

func (x *Message) ProtoReflect() protoreflect.Message {
	mi := &file_api_runtime_v1_runtime_proto_msgTypes[1]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use Message.ProtoReflect.Descriptor instead.
func (*Message) Descriptor() ([]byte, []int) {
	return file_api_runtime_v1_runtime_proto_rawDescGZIP(), []int{1}
}

func (x *Message) GetRole() string {
	if x != nil {
		return x.Role
	}
	return ""
}

func (x *Message) GetContent() string {
	if x != nil {
		return x.Content
	}
	return ""
}

type RunAgentResponse struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	// type: "thought" | "delta" | "reference" | "error" | "summary"
	Type    string     `protobuf:"bytes,1,opt,name=type,proto3" json:"type,omitempty"`
	Payload string     `protobuf:"bytes,2,opt,name=payload,proto3" json:"payload,omitempty"`
	Meta    *AgentMeta `protobuf:"bytes,3,opt,name=meta,proto3" json:"meta,omitempty"`
	// ğŸ”¥ æ–°å¢ï¼šæ‰§è¡Œæ‘˜è¦ (ä»…åœ¨ type="summary" æ—¶å­˜åœ¨ï¼Œä¸”ä½œä¸ºæµçš„æœ€åä¸€å¸§)
	Summary       *RunSummary `protobuf:"bytes,4,opt,name=summary,proto3" json:"summary,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *RunAgentResponse) Reset() {
	*x = RunAgentResponse{}
	mi := &file_api_runtime_v1_runtime_proto_msgTypes[2]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *RunAgentResponse) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*RunAgentResponse) ProtoMessage() {}

func (x *RunAgentResponse) ProtoReflect() protoreflect.Message {
	mi := &file_api_runtime_v1_runtime_proto_msgTypes[2]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use RunAgentResponse.ProtoReflect.Descriptor instead.
func (*RunAgentResponse) Descriptor() ([]byte, []int) {
	return file_api_runtime_v1_runtime_proto_rawDescGZIP(), []int{2}
}

func (x *RunAgentResponse) GetType() string {
	if x != nil {
		return x.Type
	}
	return ""
}

func (x *RunAgentResponse) GetPayload() string {
	if x != nil {
		return x.Payload
	}
	return ""
}

func (x *RunAgentResponse) GetMeta() *AgentMeta {
	if x != nil {
		return x.Meta
	}
	return nil
}

func (x *RunAgentResponse) GetSummary() *RunSummary {
	if x != nil {
		return x.Summary
	}
	return nil
}

type AgentMeta struct {
	state         protoimpl.MessageState `protogen:"open.v1"`
	NodeName      string                 `protobuf:"bytes,1,opt,name=node_name,json=nodeName,proto3" json:"node_name,omitempty"`
	TraceId       string                 `protobuf:"bytes,2,opt,name=trace_id,json=traceId,proto3" json:"trace_id,omitempty"`
	DurationMs    int64                  `protobuf:"varint,3,opt,name=duration_ms,json=durationMs,proto3" json:"duration_ms,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *AgentMeta) Reset() {
	*x = AgentMeta{}
	mi := &file_api_runtime_v1_runtime_proto_msgTypes[3]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *AgentMeta) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*AgentMeta) ProtoMessage() {}

func (x *AgentMeta) ProtoReflect() protoreflect.Message {
	mi := &file_api_runtime_v1_runtime_proto_msgTypes[3]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use AgentMeta.ProtoReflect.Descriptor instead.
func (*AgentMeta) Descriptor() ([]byte, []int) {
	return file_api_runtime_v1_runtime_proto_rawDescGZIP(), []int{3}
}

func (x *AgentMeta) GetNodeName() string {
	if x != nil {
		return x.NodeName
	}
	return ""
}

func (x *AgentMeta) GetTraceId() string {
	if x != nil {
		return x.TraceId
	}
	return ""
}

func (x *AgentMeta) GetDurationMs() int64 {
	if x != nil {
		return x.DurationMs
	}
	return 0
}

// ğŸ”¥ æ–°å¢ï¼šç»Ÿè®¡æ•°æ®ç»“æ„
type RunSummary struct {
	state            protoimpl.MessageState `protogen:"open.v1"`
	TotalTokens      int32                  `protobuf:"varint,1,opt,name=total_tokens,json=totalTokens,proto3" json:"total_tokens,omitempty"`
	PromptTokens     int32                  `protobuf:"varint,2,opt,name=prompt_tokens,json=promptTokens,proto3" json:"prompt_tokens,omitempty"`
	CompletionTokens int32                  `protobuf:"varint,3,opt,name=completion_tokens,json=completionTokens,proto3" json:"completion_tokens,omitempty"`
	TotalDurationMs  int64                  `protobuf:"varint,4,opt,name=total_duration_ms,json=totalDurationMs,proto3" json:"total_duration_ms,omitempty"` // Python ä¾§è®¡ç®—çš„æ€»è€—æ—¶
	FinalStatus      string                 `protobuf:"bytes,5,opt,name=final_status,json=finalStatus,proto3" json:"final_status,omitempty"`                // "success" | "failed"
	unknownFields    protoimpl.UnknownFields
	sizeCache        protoimpl.SizeCache
}

func (x *RunSummary) Reset() {
	*x = RunSummary{}
	mi := &file_api_runtime_v1_runtime_proto_msgTypes[4]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *RunSummary) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*RunSummary) ProtoMessage() {}

func (x *RunSummary) ProtoReflect() protoreflect.Message {
	mi := &file_api_runtime_v1_runtime_proto_msgTypes[4]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use RunSummary.ProtoReflect.Descriptor instead.
func (*RunSummary) Descriptor() ([]byte, []int) {
	return file_api_runtime_v1_runtime_proto_rawDescGZIP(), []int{4}
}

func (x *RunSummary) GetTotalTokens() int32 {
	if x != nil {
		return x.TotalTokens
	}
	return 0
}

func (x *RunSummary) GetPromptTokens() int32 {
	if x != nil {
		return x.PromptTokens
	}
	return 0
}

func (x *RunSummary) GetCompletionTokens() int32 {
	if x != nil {
		return x.CompletionTokens
	}
	return 0
}

func (x *RunSummary) GetTotalDurationMs() int64 {
	if x != nil {
		return x.TotalDurationMs
	}
	return 0
}

func (x *RunSummary) GetFinalStatus() string {
	if x != nil {
		return x.FinalStatus
	}
	return ""
}

// --- ETL ç›¸å…³ (ä¿æŒä¸å˜) ---
type SyncRequest struct {
	state         protoimpl.MessageState `protogen:"open.v1"`
	KbId          int64                  `protobuf:"varint,1,opt,name=kb_id,json=kbId,proto3" json:"kb_id,omitempty"`
	DatasourceId  int64                  `protobuf:"varint,2,opt,name=datasource_id,json=datasourceId,proto3" json:"datasource_id,omitempty"`
	Type          string                 `protobuf:"bytes,3,opt,name=type,proto3" json:"type,omitempty"`
	ConfigJson    string                 `protobuf:"bytes,4,opt,name=config_json,json=configJson,proto3" json:"config_json,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *SyncRequest) Reset() {
	*x = SyncRequest{}
	mi := &file_api_runtime_v1_runtime_proto_msgTypes[5]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *SyncRequest) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*SyncRequest) ProtoMessage() {}

func (x *SyncRequest) ProtoReflect() protoreflect.Message {
	mi := &file_api_runtime_v1_runtime_proto_msgTypes[5]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use SyncRequest.ProtoReflect.Descriptor instead.
func (*SyncRequest) Descriptor() ([]byte, []int) {
	return file_api_runtime_v1_runtime_proto_rawDescGZIP(), []int{5}
}

func (x *SyncRequest) GetKbId() int64 {
	if x != nil {
		return x.KbId
	}
	return 0
}

func (x *SyncRequest) GetDatasourceId() int64 {
	if x != nil {
		return x.DatasourceId
	}
	return 0
}

func (x *SyncRequest) GetType() string {
	if x != nil {
		return x.Type
	}
	return ""
}

func (x *SyncRequest) GetConfigJson() string {
	if x != nil {
		return x.ConfigJson
	}
	return ""
}

type SyncResponse struct {
	state         protoimpl.MessageState `protogen:"open.v1"`
	Success       bool                   `protobuf:"varint,1,opt,name=success,proto3" json:"success,omitempty"`
	ErrorMsg      string                 `protobuf:"bytes,2,opt,name=error_msg,json=errorMsg,proto3" json:"error_msg,omitempty"`
	ChunksCount   int32                  `protobuf:"varint,3,opt,name=chunks_count,json=chunksCount,proto3" json:"chunks_count,omitempty"`
	PageCount     int32                  `protobuf:"varint,4,opt,name=page_count,json=pageCount,proto3" json:"page_count,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *SyncResponse) Reset() {
	*x = SyncResponse{}
	mi := &file_api_runtime_v1_runtime_proto_msgTypes[6]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *SyncResponse) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*SyncResponse) ProtoMessage() {}

func (x *SyncResponse) ProtoReflect() protoreflect.Message {
	mi := &file_api_runtime_v1_runtime_proto_msgTypes[6]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use SyncResponse.ProtoReflect.Descriptor instead.
func (*SyncResponse) Descriptor() ([]byte, []int) {
	return file_api_runtime_v1_runtime_proto_rawDescGZIP(), []int{6}
}

func (x *SyncResponse) GetSuccess() bool {
	if x != nil {
		return x.Success
	}
	return false
}

func (x *SyncResponse) GetErrorMsg() string {
	if x != nil {
		return x.ErrorMsg
	}
	return ""
}

func (x *SyncResponse) GetChunksCount() int32 {
	if x != nil {
		return x.ChunksCount
	}
	return 0
}

func (x *SyncResponse) GetPageCount() int32 {
	if x != nil {
		return x.PageCount
	}
	return 0
}

var File_api_runtime_v1_runtime_proto protoreflect.FileDescriptor

const file_api_runtime_v1_runtime_proto_rawDesc = "" +
	"\n" +
	"\x1capi/runtime/v1/runtime.proto\x12\n" +
	"chimera.v1\"\xb4\x01\n" +
	"\x0fRunAgentRequest\x12\x15\n" +
	"\x06app_id\x18\x01 \x01(\tR\x05appId\x12\x14\n" +
	"\x05query\x18\x02 \x01(\tR\x05query\x12\x1d\n" +
	"\n" +
	"session_id\x18\x03 \x01(\tR\tsessionId\x12&\n" +
	"\x0fapp_config_json\x18\x04 \x01(\tR\rappConfigJson\x12-\n" +
	"\ahistory\x18\x05 \x03(\v2\x13.chimera.v1.MessageR\ahistory\"7\n" +
	"\aMessage\x12\x12\n" +
	"\x04role\x18\x01 \x01(\tR\x04role\x12\x18\n" +
	"\acontent\x18\x02 \x01(\tR\acontent\"\x9d\x01\n" +
	"\x10RunAgentResponse\x12\x12\n" +
	"\x04type\x18\x01 \x01(\tR\x04type\x12\x18\n" +
	"\apayload\x18\x02 \x01(\tR\apayload\x12)\n" +
	"\x04meta\x18\x03 \x01(\v2\x15.chimera.v1.AgentMetaR\x04meta\x120\n" +
	"\asummary\x18\x04 \x01(\v2\x16.chimera.v1.RunSummaryR\asummary\"d\n" +
	"\tAgentMeta\x12\x1b\n" +
	"\tnode_name\x18\x01 \x01(\tR\bnodeName\x12\x19\n" +
	"\btrace_id\x18\x02 \x01(\tR\atraceId\x12\x1f\n" +
	"\vduration_ms\x18\x03 \x01(\x03R\n" +
	"durationMs\"\xd0\x01\n" +
	"\n" +
	"RunSummary\x12!\n" +
	"\ftotal_tokens\x18\x01 \x01(\x05R\vtotalTokens\x12#\n" +
	"\rprompt_tokens\x18\x02 \x01(\x05R\fpromptTokens\x12+\n" +
	"\x11completion_tokens\x18\x03 \x01(\x05R\x10completionTokens\x12*\n" +
	"\x11total_duration_ms\x18\x04 \x01(\x03R\x0ftotalDurationMs\x12!\n" +
	"\ffinal_status\x18\x05 \x01(\tR\vfinalStatus\"|\n" +
	"\vSyncRequest\x12\x13\n" +
	"\x05kb_id\x18\x01 \x01(\x03R\x04kbId\x12#\n" +
	"\rdatasource_id\x18\x02 \x01(\x03R\fdatasourceId\x12\x12\n" +
	"\x04type\x18\x03 \x01(\tR\x04type\x12\x1f\n" +
	"\vconfig_json\x18\x04 \x01(\tR\n" +
	"configJson\"\x87\x01\n" +
	"\fSyncResponse\x12\x18\n" +
	"\asuccess\x18\x01 \x01(\bR\asuccess\x12\x1b\n" +
	"\terror_msg\x18\x02 \x01(\tR\berrorMsg\x12!\n" +
	"\fchunks_count\x18\x03 \x01(\x05R\vchunksCount\x12\x1d\n" +
	"\n" +
	"page_count\x18\x04 \x01(\x05R\tpageCount2\xa2\x01\n" +
	"\x0eRuntimeService\x12I\n" +
	"\bRunAgent\x12\x1b.chimera.v1.RunAgentRequest\x1a\x1c.chimera.v1.RunAgentResponse\"\x000\x01\x12E\n" +
	"\x0eSyncDataSource\x12\x17.chimera.v1.SyncRequest\x1a\x18.chimera.v1.SyncResponse\"\x00B\"Z Chimera/server/api/runtime/v1;v1b\x06proto3"

var (
	file_api_runtime_v1_runtime_proto_rawDescOnce sync.Once
	file_api_runtime_v1_runtime_proto_rawDescData []byte
)

func file_api_runtime_v1_runtime_proto_rawDescGZIP() []byte {
	file_api_runtime_v1_runtime_proto_rawDescOnce.Do(func() {
		file_api_runtime_v1_runtime_proto_rawDescData = protoimpl.X.CompressGZIP(unsafe.Slice(unsafe.StringData(file_api_runtime_v1_runtime_proto_rawDesc), len(file_api_runtime_v1_runtime_proto_rawDesc)))
	})
	return file_api_runtime_v1_runtime_proto_rawDescData
}

var file_api_runtime_v1_runtime_proto_msgTypes = make([]protoimpl.MessageInfo, 7)
var file_api_runtime_v1_runtime_proto_goTypes = []any{
	(*RunAgentRequest)(nil),  // 0: chimera.v1.RunAgentRequest
	(*Message)(nil),          // 1: chimera.v1.Message
	(*RunAgentResponse)(nil), // 2: chimera.v1.RunAgentResponse
	(*AgentMeta)(nil),        // 3: chimera.v1.AgentMeta
	(*RunSummary)(nil),       // 4: chimera.v1.RunSummary
	(*SyncRequest)(nil),      // 5: chimera.v1.SyncRequest
	(*SyncResponse)(nil),     // 6: chimera.v1.SyncResponse
}
var file_api_runtime_v1_runtime_proto_depIdxs = []int32{
	1, // 0: chimera.v1.RunAgentRequest.history:type_name -> chimera.v1.Message
	3, // 1: chimera.v1.RunAgentResponse.meta:type_name -> chimera.v1.AgentMeta
	4, // 2: chimera.v1.RunAgentResponse.summary:type_name -> chimera.v1.RunSummary
	0, // 3: chimera.v1.RuntimeService.RunAgent:input_type -> chimera.v1.RunAgentRequest
	5, // 4: chimera.v1.RuntimeService.SyncDataSource:input_type -> chimera.v1.SyncRequest
	2, // 5: chimera.v1.RuntimeService.RunAgent:output_type -> chimera.v1.RunAgentResponse
	6, // 6: chimera.v1.RuntimeService.SyncDataSource:output_type -> chimera.v1.SyncResponse
	5, // [5:7] is the sub-list for method output_type
	3, // [3:5] is the sub-list for method input_type
	3, // [3:3] is the sub-list for extension type_name
	3, // [3:3] is the sub-list for extension extendee
	0, // [0:3] is the sub-list for field type_name
}

func init() { file_api_runtime_v1_runtime_proto_init() }
func file_api_runtime_v1_runtime_proto_init() {
	if File_api_runtime_v1_runtime_proto != nil {
		return
	}
	type x struct{}
	out := protoimpl.TypeBuilder{
		File: protoimpl.DescBuilder{
			GoPackagePath: reflect.TypeOf(x{}).PkgPath(),
			RawDescriptor: unsafe.Slice(unsafe.StringData(file_api_runtime_v1_runtime_proto_rawDesc), len(file_api_runtime_v1_runtime_proto_rawDesc)),
			NumEnums:      0,
			NumMessages:   7,
			NumExtensions: 0,
			NumServices:   1,
		},
		GoTypes:           file_api_runtime_v1_runtime_proto_goTypes,
		DependencyIndexes: file_api_runtime_v1_runtime_proto_depIdxs,
		MessageInfos:      file_api_runtime_v1_runtime_proto_msgTypes,
	}.Build()
	File_api_runtime_v1_runtime_proto = out.File
	file_api_runtime_v1_runtime_proto_goTypes = nil
	file_api_runtime_v1_runtime_proto_depIdxs = nil
}
</file>

<file path="server/cmd/server/main.go">
package main

import (
	"Chimera/server/internal/bootstrap"
)

func main() {
	// ç›´æ¥è°ƒç”¨å¯åŠ¨å¼•å¯¼
	bootstrap.Run()
}
</file>

<file path="server/cmd/test_client/main.go">
package main

import (
	"context"
	"fmt"
	"io"
	"log"
	"time"

	pb "Chimera/api/runtime/v1"

	"google.golang.org/grpc"
	"google.golang.org/grpc/credentials/insecure"
)

func main() {
	// 1. è¿æ¥ Python æœåŠ¡ (localhost:50051)
	// ä½¿ç”¨ insecure (éåŠ å¯†) æ¨¡å¼ï¼Œå› ä¸ºæ˜¯å†…éƒ¨é€šä¿¡
	conn, err := grpc.Dial("localhost:50051", grpc.WithTransportCredentials(insecure.NewCredentials()))
	if err != nil {
		log.Fatalf("æ— æ³•è¿æ¥ Chimera å¤§è„‘: %v", err)
	}
	defer conn.Close()

	// 2. åˆ›å»ºå®¢æˆ·ç«¯
	client := pb.NewLLMServiceClient(conn)

	// 3. æ„é€ è¯·æ±‚
	req := &pb.AskRequest{
		Query:     "ä»€ä¹ˆæ˜¯ä¸‰æ°¯ç¡…çƒ·ï¼Ÿ",
		SessionId: "test-session-001",
		UseGraph:  true, // å¼€å¯å›¾è°±å¢å¼ºï¼Œæµ‹è¯• Python ç«¯çš„ mock é€»è¾‘
	}

	fmt.Printf("æ­£åœ¨å‘é€è¯·æ±‚: %s\n", req.Query)

	// 4. è°ƒç”¨æµå¼æ¥å£
	ctx, cancel := context.WithTimeout(context.Background(), 10*time.Second)
	defer cancel()

	stream, err := client.AskStream(ctx, req)
	if err != nil {
		log.Fatalf("è°ƒç”¨å¤±è´¥: %v", err)
	}

	// 5. å¾ªç¯è¯»å–æµå¼å“åº”
	for {
		resp, err := stream.Recv()
		if err == io.EOF {
			break // æµç»“æŸ
		}
		if err != nil {
			log.Fatalf("è¯»å–æµå¤±è´¥: %v", err)
		}

		// æ‰“å°æ¥æ”¶åˆ°çš„å†…å®¹
		if resp.ThinkingLog != "" {
			fmt.Printf("\n[ğŸ§  æ€è€ƒ]: %s", resp.ThinkingLog)
		}
		if resp.AnswerDelta != "" {
			fmt.Printf("%s", resp.AnswerDelta) // ä¸æ¢è¡Œï¼Œæ¨¡æ‹Ÿæ‰“å­—æœº
		}
		if len(resp.SourceDocs) > 0 {
			fmt.Printf("\n\n[ğŸ“š å¼•ç”¨]: %s (é¡µç : %s)", resp.SourceDocs[0].DocName, resp.SourceDocs[0].PageNum)
		}
	}
	fmt.Println("\n\n--- å¯¹è¯ç»“æŸ ---")
}
</file>

<file path="server/internal/biz/dto.go">
package biz

// ChatRequest æ˜¯å‰ç«¯å‘æ¥çš„ JSON
type ChatRequest struct {
	Query     string `json:"query" binding:"required"`
	SessionID string `json:"session_id"`
	UseGraph  bool   `json:"use_graph"`
	UseSearch bool   `json:"use_search"`
}

// è¿™é‡Œçš„ç»“æ„ä½“åªç”¨äºç»‘å®šè¯·æ±‚ï¼Œå“åº”æˆ‘ä»¬ç›´æ¥å†™æµï¼Œä¸éœ€è¦å®šä¹‰ç»“æ„ä½“
</file>

<file path="server/internal/bootstrap/boot.go">
package bootstrap

import (
	"log"
	"time"

	"github.com/gin-contrib/cors"
	"github.com/gin-gonic/gin"
	"google.golang.org/grpc"
	"google.golang.org/grpc/credentials/insecure"

	// å¼•å…¥ PB å’Œ Internal æ¨¡å—
	pb "Chimera/server/api/runtime/v1"
	"Chimera/server/internal/conf"
	"Chimera/server/internal/data"
	"Chimera/server/internal/handler"
	"Chimera/server/internal/middleware"
	"Chimera/server/internal/repository"
	"Chimera/server/internal/service"
)

// Run å¯åŠ¨æœåŠ¡å™¨
func Run() {
	// 1. åŠ è½½é…ç½®
	cfg := conf.LoadConfig()

	// 2. åˆå§‹åŒ– gRPC è¿æ¥ (Python AI Service)
	maxMsgSize := 100 * 1024 * 1024
	conn, err := grpc.NewClient(
		cfg.AI.GRPCHost,
		grpc.WithTransportCredentials(insecure.NewCredentials()),
		grpc.WithDefaultCallOptions(
			grpc.MaxCallRecvMsgSize(maxMsgSize),
			grpc.MaxCallSendMsgSize(maxMsgSize),
		),
	)
	if err != nil {
		log.Fatalf("âŒ æ— æ³•è¿æ¥ AI Service: %v", err)
	}
	defer conn.Close()

	// 3. åˆå§‹åŒ–æ•°æ®å±‚
	d, cleanup, err := data.NewData(cfg)
	if err != nil {
		log.Fatalf("âŒ æ•°æ®å±‚åˆå§‹åŒ–å¤±è´¥: %v", err)
	}
	defer cleanup()

	userRepo := repository.NewUserRepository(d.DB)

	// 4. åˆå§‹åŒ–æœåŠ¡å±‚ (Service & Adapter)
	grpcClient := pb.NewRuntimeServiceClient(conn)
	adapter := service.NewRuntimeAdapter(grpcClient)

	// ChatService (åŸ RuntimeService)
	chatSvc := service.NewChatService(d, adapter)
	// DataSourceService (æ–°æ‹†åˆ†)
	dsSvc := service.NewDataSourceService(d, adapter)

	// å…¶ä»–åŸºç¡€æœåŠ¡
	orgSvc := service.NewOrgService(d)
	kbSvc := service.NewKBService(d)
	authSvc := service.NewAuthService(userRepo)
	logSvc := service.NewLogService(d)

	// 5. åˆå§‹åŒ– Handler
	orgH := handler.NewOrgHandler(orgSvc)
	kbH := handler.NewKBHandler(kbSvc)
	authH := handler.NewAuthHandler(authSvc)
	logH := handler.NewLogHandler(logSvc)
	chatH := handler.NewChatHandler(chatSvc) // åªè´Ÿè´£å¯¹è¯

	dsH := handler.NewDataSourceHandler(dsSvc) // è´Ÿè´£æ•°æ®æº
	fileH := handler.NewFileHandler(dsSvc)     // è´Ÿè´£æ–‡ä»¶

	// 6. åˆå§‹åŒ– Gin Server
	r := gin.Default()

	// CORS é…ç½®
	r.Use(cors.New(cors.Config{
		AllowOrigins:     []string{"*"},
		AllowMethods:     []string{"GET", "POST", "PUT", "DELETE", "OPTIONS"},
		AllowHeaders:     []string{"Origin", "Content-Type", "Content-Length", "Accept-Encoding", "X-CSRF-Token", "Authorization"},
		ExposeHeaders:    []string{"Content-Length"},
		AllowCredentials: true,
		MaxAge:           12 * time.Hour,
	}))

	// 7. æ³¨å†Œè·¯ç”±
	api := r.Group("/api/v1")
	{
		// å…¬å¼€æ¥å£
		auth := api.Group("/auth")
		{
			auth.POST("/register", authH.Register)
			auth.POST("/login", authH.Login)
		}

		// é‰´æƒæ¥å£
		protected := api.Group("/")
		protected.Use(middleware.JWTAuth())
		{
			// æ–‡ä»¶ä¸Šä¼  (è°ƒç”¨ FileHandler)
			protected.POST("/files/upload", fileH.Upload)
			// å¯¹è¯æµ (è°ƒç”¨ ChatHandler)
			protected.POST("/chat/stream", chatH.HandleChatSSE)
			// æ•°æ®æºåˆ›å»º (è°ƒç”¨ DataSourceHandler)
			protected.POST("/datasources", dsH.Create)

			// ç»„ç»‡ä¸çŸ¥è¯†åº“
			protected.POST("/orgs", orgH.Create)
			protected.GET("/orgs", orgH.List)
			protected.POST("/kbs", kbH.Create)
			protected.GET("/kbs", kbH.List)

			// ç›‘æ§
			protected.GET("/logs", logH.List)
			protected.GET("/stats", logH.Stats)
		}

		// æ–‡ä»¶ä¸‹è½½
		protected.GET("/file/:filename", fileH.HandleGetFile)
	}

	log.Println("ğŸš€ Chimera åç«¯å·²å¯åŠ¨ï¼Œç›‘å¬ç«¯å£ :8080")
	if err := r.Run(":8080"); err != nil {
		log.Fatalf("âŒ Server å¯åŠ¨å¤±è´¥: %v", err)
	}
}
</file>

<file path="server/internal/core/datasource.go">
package core

// DataSourceHandler å®šä¹‰ç‰¹å®šæ•°æ®æºï¼ˆå¦‚é£ä¹¦ã€é’‰é’‰ï¼‰éœ€è¦å®ç°çš„é€»è¾‘æ¥å£
type DataSourceHandler interface {
	// ValidateConfig æ ¡éªŒå‰ç«¯ä¼ æ¥çš„ Config JSON/Map æ˜¯å¦åˆæ³•
	ValidateConfig(config map[string]interface{}) error
}

// DataSourceRegistry æ•°æ®æºå¤„ç†å™¨æ³¨å†Œè¡¨
type DataSourceRegistry struct {
	handlers map[string]DataSourceHandler
}

// å…¨å±€å•ä¾‹ï¼Œæ–¹ä¾¿ init() æ³¨å†Œ
var GlobalRegistry = &DataSourceRegistry{
	handlers: make(map[string]DataSourceHandler),
}

func (r *DataSourceRegistry) Register(sourceType string, handler DataSourceHandler) {
	r.handlers[sourceType] = handler
}

func (r *DataSourceRegistry) Get(sourceType string) (DataSourceHandler, bool) {
	h, ok := r.handlers[sourceType]
	return h, ok
}

// Validate è¾…åŠ©å‡½æ•°ï¼šå¦‚æœæ³¨å†Œäº†æ ¡éªŒå™¨åˆ™æ ¡éªŒï¼Œæ²¡æ³¨å†Œï¼ˆå¦‚ fileï¼‰åˆ™é»˜è®¤é€šè¿‡
func (r *DataSourceRegistry) Validate(sourceType string, config map[string]interface{}) error {
	if handler, ok := r.Get(sourceType); ok {
		return handler.ValidateConfig(config)
	}
	// å¦‚æœæ²¡æœ‰æ³¨å†Œç‰¹å®šçš„ Handler (æ¯”å¦‚ file ç±»å‹æš‚ä¸éœ€è¦å¤æ‚æ ¡éªŒ)ï¼Œé»˜è®¤æ”¾è¡Œ
	// æˆ–è€…ä½ å¯ä»¥é…ç½®æˆ return errors.New("æœªçŸ¥çš„æ•°æ®æºç±»å‹") æ¥å¼ºåˆ¶è¦æ±‚æ³¨å†Œ
	return nil
}
</file>

<file path="server/internal/data/queue.go">
package data

import (
	"context"
	"fmt"
)

// ---------------------------------------------------------
// Redis ç›¸å…³æ“ä½œ (Queue)
// ---------------------------------------------------------

// PushTask å°†ä»»åŠ¡æ¨é€åˆ° Redis é˜Ÿåˆ—
func (d *Data) PushTask(ctx context.Context, queueName string, payload string) error {
	// ä½¿ç”¨ RPush (å³è¿›) é…åˆ Worker çš„ BLPop (å·¦å‡º) å®ç° FIFO é˜Ÿåˆ—
	err := d.Redis.RPush(ctx, queueName, payload).Err()
	if err != nil {
		return fmt.Errorf("redis push error: %w", err)
	}
	return nil
}
</file>

<file path="server/internal/data/storage.go">
package data

import (
	"Chimera/server/internal/model"
	"context"
	"fmt"
	"io"
	"path/filepath"

	"github.com/google/uuid"
	"github.com/minio/minio-go/v7"
)

// ---------------------------------------------------------
// MinIO ç›¸å…³æ“ä½œ (Storage)
// ---------------------------------------------------------

// UploadFile å°†æ–‡ä»¶æµä¸Šä¼ åˆ° MinIO
// è¿”å›: å­˜å‚¨è·¯å¾„(objectName), é”™è¯¯
func (d *Data) UploadFile(ctx context.Context, file io.Reader, fileSize int64, originalFilename string) (string, error) {
	// 1. ç”Ÿæˆå®‰å…¨çš„æ–‡ä»¶å (UUID + åŸå§‹åç¼€)
	// ä¾‹å¦‚: "550e8400-e29b-41d4-a716-446655440000.pdf"
	ext := filepath.Ext(originalFilename)
	objectName := fmt.Sprintf("%s%s", uuid.New().String(), ext)

	// æ¡¶åç§°å»ºè®®ä» Config ä¸­è¯»å–ï¼Œè¿™é‡Œä¸ºæ¼”ç¤ºå…ˆå†™æ­»æˆ–ä½œä¸ºå‚æ•°
	bucketName := "chimera-docs"

	// 2. æ‰§è¡Œä¸Šä¼ 
	_, err := d.Minio.PutObject(ctx, bucketName, objectName, file, fileSize, minio.PutObjectOptions{
		ContentType: "application/octet-stream", // è‡ªåŠ¨æ£€æµ‹æˆ–ç”±ä¸Šå±‚ä¼ å…¥
	})
	if err != nil {
		return "", fmt.Errorf("minio put object error: %w", err)
	}

	// è¿”å›å­˜å‚¨è·¯å¾„ (bucket/objectName æˆ– çº¯ objectNameï¼Œçœ‹éœ€æ±‚)
	// è¿™é‡Œè¿”å› objectNameï¼Œæ–¹ä¾¿åç»­æ‹¼æ¥ URL
	return objectName, nil
}

// GetFileStream ä» MinIO è·å–æ–‡ä»¶æµ
// è¿”å›: æ–‡ä»¶å¯¹è±¡(éœ€ç”±è°ƒç”¨è€…Close), æ–‡ä»¶å¤§å°, é”™è¯¯
func (d *Data) GetFileStream(ctx context.Context, bucketName string, objectName string) (*minio.Object, int64, error) {
	// 1. è·å–å¯¹è±¡æµ
	object, err := d.Minio.GetObject(ctx, bucketName, objectName, minio.GetObjectOptions{})
	if err != nil {
		return nil, 0, fmt.Errorf("minio get object error: %w", err)
	}

	// 2. è·å–å¯¹è±¡ä¿¡æ¯ (ä¸»è¦ä¸ºäº†æ‹¿ Size)
	// Stat() ä¼šæ£€æŸ¥å¯¹è±¡æ˜¯å¦å­˜åœ¨ï¼Œå¦‚æœä¸å­˜åœ¨è¿™é‡Œä¼šæŠ¥é”™
	info, err := object.Stat()
	if err != nil {
		// å¦‚æœ Stat å¤±è´¥ï¼Œè¯´æ˜å¯¹è±¡å¯èƒ½ä¸å­˜åœ¨æˆ–è¿æ¥æ–­å¼€
		// è®°å¾—å…³é—­ objectï¼Œé˜²æ­¢æ³„æ¼
		object.Close()
		return nil, 0, fmt.Errorf("minio stat object error: %w", err)
	}

	return object, info.Size, nil
}

// ---------------------------------------------------------
// Postgres ç›¸å…³æ“ä½œ (DB) - v0.2.0 æ–°å¢
// ---------------------------------------------------------

// CreateDocument åœ¨æ•°æ®åº“åˆ›å»ºæ–‡æ¡£è®°å½•
func (d *Data) CreateDocument(ctx context.Context, doc *model.DataSource) error {
	return d.DB.WithContext(ctx).Create(doc).Error
}
</file>

<file path="server/internal/dto/auth_dto.go">
package dto

type RegisterReq struct {
	Username string `json:"username" binding:"required"`
	Password string `json:"password" binding:"required,min=6"`
	Email    string `json:"email"`
}

type LoginReq struct {
	Username string `json:"username" binding:"required"`
	Password string `json:"password" binding:"required"`
}

type LoginResp struct {
	Token    string `json:"token"`
	Username string `json:"username"`
	UserID   uint   `json:"user_id"`
}
</file>

<file path="server/internal/dto/chat_dto.go">
package dto

// ChatReq å®šä¹‰å‰ç«¯å‘é€çš„èŠå¤©è¯·æ±‚å‚æ•°
type ChatReq struct {
	Query     string `json:"query" binding:"required"` // ç”¨æˆ·çš„é—®é¢˜
	SessionID string `json:"session_id"`               // ä¼šè¯ID (å¯é€‰)

	// ğŸ”¥ v0.4.0 æ–°å¢å­—æ®µï¼šç”¨äºæŒ‡å®šæœç´¢èŒƒå›´
	KbID  uint `json:"kb_id"`  // æŒ‡å®šçŸ¥è¯†åº“ ID (0 è¡¨ç¤ºä¸æŒ‡å®š)
	OrgID uint `json:"org_id"` // æŒ‡å®šç»„ç»‡ ID (0 è¡¨ç¤ºä¸æŒ‡å®š)

	// é»˜è®¤ä¸º falseã€‚å‰ç«¯ Vue éœ€è¦ä¼  trueï¼ŒApifox æµ‹è¯•ä¼  false (æˆ–ä¸ä¼ )
	Stream bool `json:"stream"`

	// å¦‚æœéœ€è¦æ”¯æŒå†å²è®°å½•ï¼Œå¯ä»¥åœ¨è¿™é‡ŒåŠ 
	// History []Message `json:"history"`
}
</file>

<file path="server/internal/dto/datasource_dto.go">
package dto

// CreateDataSourceReq åˆ›å»ºæ•°æ®æºè¯·æ±‚
type CreateDataSourceReq struct {
	KbID uint   `json:"kb_id" binding:"required"`
	Type string `json:"type" binding:"required"`
	Name string `json:"name" binding:"required"`

	// å‰ç«¯ä¼ æ¥çš„ { "app_id": "...", "secret": "..." } ä¼šè¢«è‡ªåŠ¨è§£æè¿›è¿™ä¸ª map
	Config map[string]interface{} `json:"config"`
}
</file>

<file path="server/internal/dto/file_dto.go">
package dto

type FileResp struct {
	ID        uint   `json:"id"`
	Title     string `json:"title"`
	FileName  string `json:"file_name"`
	Size      int64  `json:"size"`
	Status    string `json:"status"` // pending, parsing, success
	CreatedAt string `json:"created_at"`
}
</file>

<file path="server/internal/dto/kb_dto.go">
package dto

import "time"

type CreateKBReq struct {
	Name        string `json:"name" binding:"required"`
	Description string `json:"description"`
	Type        string `json:"type" binding:"oneof=folder repo"` // æš‚æ—¶åªç”¨ folder

	// ğŸ”¥ æ ¸å¿ƒå­—æ®µï¼šå¦‚æœä¸ä¼ (0/null)ï¼Œåˆ™æ˜¯ä¸ªäººçŸ¥è¯†åº“
	OrgID uint `json:"org_id"`
}

type KBResp struct {
	ID          uint      `json:"id"`
	Name        string    `json:"name"`
	Description string    `json:"description"`
	Type        string    `json:"type"`
	CreatorID   uint      `json:"creator_id"`
	OrgID       *uint     `json:"org_id"` // æŒ‡é’ˆç±»å‹ï¼Œè¿”å› null è¡¨ç¤ºä¸ªäºº
	CreatedAt   time.Time `json:"created_at"`
}
</file>

<file path="server/internal/dto/log_dto.go">
package dto

import "time"

// LogListReq æŸ¥è¯¢æ—¥å¿—åˆ—è¡¨è¯·æ±‚
type LogListReq struct {
	Page     int    `form:"page,default=1"`
	PageSize int    `form:"page_size,default=20"`
	AppID    string `form:"app_id"` // é€‰å¡«ï¼Œç­›é€‰ç‰¹å®šåº”ç”¨
	Status   string `form:"status"` // success, failed
}

// LogListResp æ—¥å¿—åˆ—è¡¨å“åº”
type LogListResp struct {
	Total int64        `json:"total"`
	List  []LogSummary `json:"list"`
}

type LogSummary struct {
	ID          uint      `json:"id"`
	TraceID     string    `json:"trace_id"`
	AppID       string    `json:"app_id"`
	User        string    `json:"user"` // ç”¨æˆ·å
	Query       string    `json:"query"`
	Answer      string    `json:"answer"`
	TotalTokens int       `json:"total_tokens"`
	DurationMs  int64     `json:"duration_ms"`
	Status      string    `json:"status"`
	CreatedAt   time.Time `json:"created_at"`
}

// AppStatsReq ç»Ÿè®¡è¯·æ±‚
type AppStatsReq struct {
	AppID string `form:"app_id"`
	Days  int    `form:"days,default=7"` // æœ€è¿‘å‡ å¤©
}

// AppStatsResp ç»Ÿè®¡å“åº”
type AppStatsResp struct {
	TotalCalls    int64         `json:"total_calls"`
	TotalTokens   int64         `json:"total_tokens"`
	AvgDurationMs int64         `json:"avg_duration_ms"`
	DailyStats    []DailyMetric `json:"daily_stats"`
}

type DailyMetric struct {
	Date   string `json:"date"`
	Tokens int64  `json:"tokens"`
	Calls  int64  `json:"calls"`
}
</file>

<file path="server/internal/dto/org_dto.go">
package dto

import "time"

// CreateOrgReq åˆ›å»ºç»„ç»‡è¯·æ±‚å‚æ•°
type CreateOrgReq struct {
	Name        string `json:"name" binding:"required"`
	Description string `json:"description"`
	// ğŸ‘‡ æ”¹ä¸º omitemptyï¼Œå…è®¸ä¸ä¼ 
	Key string `json:"key" binding:"omitempty,alphanum,min=3,max=20"`
}

// OrgResp ç»„ç»‡å“åº”æ•°æ®
type OrgResp struct {
	ID          uint      `json:"id"`
	Name        string    `json:"name"`
	Description string    `json:"description"`
	Key         string    `json:"key"`
	OwnerID     uint      `json:"owner_id"`
	CreatedAt   time.Time `json:"created_at"`
}
</file>

<file path="server/internal/handler/auth_handler.go">
package handler

import (
	"Chimera/server/internal/dto"
	"Chimera/server/internal/service"
	"net/http"

	"github.com/gin-gonic/gin"
)

type AuthHandler struct {
	svc service.AuthService // ä¾èµ–æ¥å£ï¼Œè€Œä¸æ˜¯å…·ä½“çš„ç»“æ„ä½“
}

func NewAuthHandler(svc service.AuthService) *AuthHandler {
	return &AuthHandler{svc: svc}
}

// Register æ¥å£
func (h *AuthHandler) Register(c *gin.Context) {
	var req dto.RegisterReq
	if err := c.ShouldBindJSON(&req); err != nil {
		c.JSON(http.StatusBadRequest, gin.H{"error": "å‚æ•°é”™è¯¯: " + err.Error()})
		return
	}

	// è°ƒç”¨ Service
	userID, err := h.svc.Register(req)
	if err != nil {
		// è¿™é‡Œå¯ä»¥æ ¹æ® error ç±»å‹ç»†åˆ†çŠ¶æ€ç ï¼Œè¿™é‡Œç®€å•å¤„ç†
		c.JSON(http.StatusBadRequest, gin.H{"error": err.Error()})
		return
	}

	c.JSON(http.StatusOK, gin.H{"msg": "æ³¨å†ŒæˆåŠŸ", "user_id": userID})
}

// Login æ¥å£
func (h *AuthHandler) Login(c *gin.Context) {
	var req dto.LoginReq
	if err := c.ShouldBindJSON(&req); err != nil {
		c.JSON(http.StatusBadRequest, gin.H{"error": "å‚æ•°é”™è¯¯"})
		return
	}

	resp, err := h.svc.Login(req)
	if err != nil {
		c.JSON(http.StatusUnauthorized, gin.H{"error": err.Error()})
		return
	}

	// ç›´æ¥è¿”å› Service å±‚å¤„ç†å¥½çš„ DTO
	c.JSON(http.StatusOK, resp)
}
</file>

<file path="server/internal/handler/chat_handler.go">
package handler

import (
	"io"
	"net/http"
	"strings"

	"Chimera/server/internal/dto"
	"Chimera/server/internal/service"

	"github.com/gin-gonic/gin"
)

type ChatHandler struct {
	svc *service.ChatService
}

func NewChatHandler(svc *service.ChatService) *ChatHandler {
	return &ChatHandler{svc: svc}
}

// HandleChatSSE å¤„ç†å¯¹è¯æ¥å£ (å…¼å®¹æµå¼ä¸éæµå¼)
// POST /api/v1/chat/stream
func (h *ChatHandler) HandleChatSSE(c *gin.Context) {
	var req dto.ChatReq

	// 1. ç»‘å®šå‰ç«¯ JSON
	if err := c.ShouldBindJSON(&req); err != nil {
		c.JSON(http.StatusBadRequest, gin.H{"error": err.Error()})
		return
	}

	// 2. è·å–ç”¨æˆ·id
	userID, exists := c.Get("userID")
	if !exists {
		c.JSON(http.StatusUnauthorized, gin.H{"error": "æœªç™»å½•"})
		return
	}

	// 3. åˆ›å»ºé€šé“ç”¨äºæ¥æ”¶ Service çš„æµå¼è¿”å›
	respChan := make(chan string)

	// 4. å¼‚æ­¥è°ƒç”¨ Service
	// æ³¨æ„ï¼šä¼ å…¥ userID.(uint)
	go h.svc.StreamChat(c.Request.Context(), userID.(uint), req, respChan)

	// ==========================================
	// åˆ†æ”¯ A: éæµå¼æ¨¡å¼ (For Apifox æµ‹è¯• / ç¬¬ä¸‰æ–¹è°ƒç”¨)
	// ==========================================
	if !req.Stream {
		var fullAnswer string
		// å¾ªç¯è¯»å–é€šé“
		for msg := range respChan {
			// ç®€å•è¿‡æ»¤æ‰ THINKING æ ‡ç­¾ï¼Œåªè¿”å›å†…å®¹ (æˆ–è€…ä½ å¯ä»¥é€‰æ‹©éƒ½è¿”å›)
			if !strings.HasPrefix(msg, "THOUGHT:") {
				fullAnswer += msg
			}
		}

		if strings.Contains(fullAnswer, "ERR: â›”ï¸") {
			c.JSON(http.StatusForbidden, gin.H{
				"error": "Access Denied",
			})
			return
		}

		c.JSON(http.StatusOK, gin.H{
			"answer": fullAnswer,
		})
		return
	}

	// ==========================================
	// åˆ†æ”¯ B: æµå¼æ¨¡å¼ (SSE, For Vue å‰ç«¯)
	// ==========================================
	c.Writer.Header().Set("Content-Type", "text/event-stream")
	c.Writer.Header().Set("Cache-Control", "no-cache")
	c.Writer.Header().Set("Connection", "keep-alive")
	c.Writer.Header().Set("Transfer-Encoding", "chunked")

	c.Stream(func(w io.Writer) bool {
		if msg, ok := <-respChan; ok {
			// ç›´æ¥é€ä¼ ç»™å‰ç«¯ï¼Œå‰ç«¯å»è§£æ "THOUGHT:" å‰ç¼€
			c.SSEvent("message", msg)
			return true
		}
		return false
	})
}
</file>

<file path="server/internal/handler/datasource_handler.go">
package handler

import (
	"Chimera/server/internal/dto"
	"Chimera/server/internal/service"
	"github.com/gin-gonic/gin"
	"net/http"
)

type DataSourceHandler struct {
	svc *service.DataSourceService
}

func NewDataSourceHandler(svc *service.DataSourceService) *DataSourceHandler {
	return &DataSourceHandler{svc: svc}
}

func (h *DataSourceHandler) Create(c *gin.Context) {
	var req dto.CreateDataSourceReq
	// ç»‘å®š JSON
	if err := c.ShouldBindJSON(&req); err != nil {
		c.JSON(http.StatusBadRequest, gin.H{"error": err.Error()})
		return
	}
	userID := c.GetUint("userID")

	// ğŸ”¥ æ”¹é€ ç‚¹ï¼šç›´æ¥è°ƒç”¨é€šç”¨æ¥å£
	ds, err := h.svc.CreateDataSource(c.Request.Context(), userID, req)
	if err != nil {
		c.JSON(http.StatusInternalServerError, gin.H{"error": err.Error()})
		return
	}

	c.JSON(http.StatusOK, gin.H{"data": ds})
}
</file>

<file path="server/internal/handler/file_handler.go">
package handler

import (
	"fmt"
	"io"
	"net/http"
	"strconv"

	"Chimera/server/internal/service"
	"github.com/gin-gonic/gin"
)

type FileHandler struct {
	// ğŸ”¥ å…³é”®ä¿®æ”¹ï¼šä¾èµ– DataSourceService
	svc *service.DataSourceService
}

func NewFileHandler(svc *service.DataSourceService) *FileHandler {
	return &FileHandler{svc: svc}
}

// Upload ä¸Šä¼ 
func (h *FileHandler) Upload(c *gin.Context) {
	file, err := c.FormFile("file")
	if err != nil {
		c.JSON(http.StatusBadRequest, gin.H{"error": "è¯·ä¸Šä¼ æ–‡ä»¶"})
		return
	}

	kbIDStr := c.PostForm("kb_id")
	if kbIDStr == "" {
		c.JSON(http.StatusBadRequest, gin.H{"error": "ç¼ºå°‘ kb_id"})
		return
	}
	kbID, _ := strconv.Atoi(kbIDStr)
	userID := c.GetUint("userID")

	// è°ƒç”¨ DataSourceService çš„ UploadFile
	ds, err := h.svc.UploadFile(c.Request.Context(), file, userID, uint(kbID))
	if err != nil {
		c.JSON(http.StatusInternalServerError, gin.H{"error": err.Error()})
		return
	}

	c.JSON(http.StatusOK, gin.H{"code": 200, "data": ds})
}

func (h *FileHandler) HandleGetFile(c *gin.Context) {
	filename := c.Param("filename")

	// è°ƒç”¨ dsSvc çš„ GetFile
	obj, size, err := h.svc.GetFile(c.Request.Context(), filename)
	if err != nil {
		c.JSON(http.StatusNotFound, gin.H{"error": "æ–‡ä»¶ä¸å­˜åœ¨"})
		return
	}
	defer obj.Close()

	c.Header("Content-Disposition", "inline; filename="+filename)
	c.Header("Content-Length", fmt.Sprintf("%d", size))
	c.Header("Content-Type", "application/pdf") // ç®€æ˜“å¤„ç†

	io.Copy(c.Writer, obj)
}
</file>

<file path="server/internal/handler/kb_handler.go">
package handler

import (
	"Chimera/server/internal/dto"
	"Chimera/server/internal/service"
	"github.com/gin-gonic/gin"
	"net/http"
	"strconv"
)

type KBHandler struct {
	svc *service.KBService
}

func NewKBHandler(svc *service.KBService) *KBHandler {
	return &KBHandler{svc: svc}
}

// Create åˆ›å»ºçŸ¥è¯†åº“
// POST /api/v1/kbs
func (h *KBHandler) Create(c *gin.Context) {
	var req dto.CreateKBReq
	if err := c.ShouldBindJSON(&req); err != nil {
		c.JSON(http.StatusBadRequest, gin.H{"error": err.Error()})
		return
	}

	userID, exists := c.Get("userID")
	if !exists {
		c.JSON(http.StatusUnauthorized, gin.H{"error": "æœªç™»å½•"})
		return
	}

	resp, err := h.svc.CreateKnowledgeBase(c.Request.Context(), userID.(uint), req)
	if err != nil {
		// åŒºåˆ†ä¸€ä¸‹æ˜¯æƒé™é”™è¯¯è¿˜æ˜¯æœåŠ¡å™¨é”™è¯¯ä¼šæ›´å¥½ï¼Œè¿™é‡Œæš‚æ—¶ç®€åŒ–
		c.JSON(http.StatusInternalServerError, gin.H{"error": err.Error()})
		return
	}

	c.JSON(http.StatusOK, gin.H{"data": resp})
}

// List è·å–çŸ¥è¯†åº“åˆ—è¡¨
// GET /api/v1/kbs?org_id=1
func (h *KBHandler) List(c *gin.Context) {
	userID, exists := c.Get("userID")
	if !exists {
		c.JSON(http.StatusUnauthorized, gin.H{"error": "æœªç™»å½•"})
		return
	}

	// è·å– Query å‚æ•°ï¼Œé»˜è®¤ä¸ºç©ºå­—ç¬¦ä¸²
	orgIDStr := c.Query("org_id")
	var orgID uint = 0

	// å¦‚æœä¼ äº†å‚æ•°ï¼Œå°è¯•è½¬ä¸º uint
	if orgIDStr != "" {
		// è¿™é‡Œå·æ‡’ç”¨äº†ç®€å•çš„è½¬æ¢ï¼Œç”Ÿäº§ç¯å¢ƒå¯ä»¥ç”¨ cast åº“
		// æˆ–è€…ç›´æ¥å®šä¹‰ä¸€ä¸ª Form ç»“æ„ä½“ç”¨ ShouldBindQuery
		if id, err := strconv.Atoi(orgIDStr); err == nil {
			orgID = uint(id)
		}
	}

	list, err := h.svc.ListKnowledgeBases(c.Request.Context(), userID.(uint), orgID)
	if err != nil {
		c.JSON(http.StatusInternalServerError, gin.H{"error": err.Error()})
		return
	}

	c.JSON(http.StatusOK, gin.H{"data": list})
}
</file>

<file path="server/internal/handler/log_handler.go">
package handler

import (
	"Chimera/server/internal/dto"
	"Chimera/server/internal/service"
	"github.com/gin-gonic/gin"
	"net/http"
)

type LogHandler struct {
	svc *service.LogService
}

func NewLogHandler(svc *service.LogService) *LogHandler {
	return &LogHandler{svc: svc}
}

// List è·å–æ—¥å¿—åˆ—è¡¨
// GET /api/v1/logs
func (h *LogHandler) List(c *gin.Context) {
	var req dto.LogListReq
	if err := c.ShouldBindQuery(&req); err != nil {
		c.JSON(http.StatusBadRequest, gin.H{"error": err.Error()})
		return
	}

	userID := c.GetUint("userID")
	resp, err := h.svc.GetLogList(c.Request.Context(), userID, req)
	if err != nil {
		c.JSON(http.StatusInternalServerError, gin.H{"error": err.Error()})
		return
	}

	c.JSON(http.StatusOK, gin.H{"data": resp})
}

// Stats è·å–ç»Ÿè®¡æ•°æ®
// GET /api/v1/stats
func (h *LogHandler) Stats(c *gin.Context) {
	var req dto.AppStatsReq
	if err := c.ShouldBindQuery(&req); err != nil {
		c.JSON(http.StatusBadRequest, gin.H{"error": err.Error()})
		return
	}

	resp, err := h.svc.GetAppStats(c.Request.Context(), req)
	if err != nil {
		c.JSON(http.StatusInternalServerError, gin.H{"error": err.Error()})
		return
	}

	c.JSON(http.StatusOK, gin.H{"data": resp})
}
</file>

<file path="server/internal/handler/org_handler.go">
package handler

import (
	"Chimera/server/internal/dto"
	"Chimera/server/internal/service"
	"github.com/gin-gonic/gin"
	"net/http"
)

type OrgHandler struct {
	svc *service.OrgService
}

func NewOrgHandler(svc *service.OrgService) *OrgHandler {
	return &OrgHandler{svc: svc}
}

// Create åˆ›å»ºç»„ç»‡
// POST /api/v1/orgs
func (h *OrgHandler) Create(c *gin.Context) {
	var req dto.CreateOrgReq
	if err := c.ShouldBindJSON(&req); err != nil {
		c.JSON(http.StatusBadRequest, gin.H{"error": err.Error()})
		return
	}

	// ä»ä¸­é—´ä»¶è·å–å½“å‰ç™»å½•ç”¨æˆ· ID
	userID, exists := c.Get("userID")
	if !exists {
		c.JSON(http.StatusUnauthorized, gin.H{"error": "æœªç™»å½•"})
		return
	}

	// è°ƒç”¨ Service
	// æ³¨æ„ï¼šuserID.(uint) æ˜¯ç±»å‹æ–­è¨€ï¼Œç¡®ä¿ä¸­é—´ä»¶é‡Œå­˜çš„æ˜¯ uint ç±»å‹
	resp, err := h.svc.CreateOrganization(c.Request.Context(), userID.(uint), req)
	if err != nil {
		c.JSON(http.StatusInternalServerError, gin.H{"error": err.Error()})
		return
	}

	c.JSON(http.StatusOK, gin.H{"data": resp})
}

// List è·å–æˆ‘çš„ç»„ç»‡åˆ—è¡¨
// GET /api/v1/orgs
func (h *OrgHandler) List(c *gin.Context) {
	userID, exists := c.Get("userID")
	if !exists {
		c.JSON(http.StatusUnauthorized, gin.H{"error": "æœªç™»å½•"})
		return
	}

	orgs, err := h.svc.ListUserOrganizations(c.Request.Context(), userID.(uint))
	if err != nil {
		c.JSON(http.StatusInternalServerError, gin.H{"error": "è·å–ç»„ç»‡åˆ—è¡¨å¤±è´¥"})
		return
	}

	c.JSON(http.StatusOK, gin.H{"data": orgs})
}
</file>

<file path="server/internal/middleware/jwt.go">
package middleware

import (
	"Chimera/server/internal/utils"
	"net/http"
	"strings"

	"github.com/gin-gonic/gin"
)

// JWTAuth é‰´æƒä¸­é—´ä»¶
func JWTAuth() gin.HandlerFunc {
	return func(c *gin.Context) {
		// 1. è·å– Header ä¸­çš„ Authorization
		authHeader := c.Request.Header.Get("Authorization")
		if authHeader == "" {
			c.JSON(http.StatusUnauthorized, gin.H{"error": "éœ€è¦ç™»å½•æ‰èƒ½è®¿é—®"})
			c.Abort()
			return
		}

		// 2. æ ¼å¼é€šå¸¸æ˜¯ "Bearer eyJ..."ï¼Œæˆ‘ä»¬è¦å»æ‰ "Bearer "
		parts := strings.SplitN(authHeader, " ", 2)
		if len(parts) != 2 || parts[0] != "Bearer" {
			c.JSON(http.StatusUnauthorized, gin.H{"error": "Tokenæ ¼å¼é”™è¯¯"})
			c.Abort()
			return
		}

		// 3. è§£æ Token
		claims, err := utils.ParseToken(parts[1])
		if err != nil {
			c.JSON(http.StatusUnauthorized, gin.H{"error": "Tokenæ— æ•ˆæˆ–å·²è¿‡æœŸ"})
			c.Abort()
			return
		}

		// 4. ğŸ”¥ å…³é”®ï¼šæŠŠ UserID å­˜å…¥ä¸Šä¸‹æ–‡ï¼Œä¾›åç»­ Handler ä½¿ç”¨
		c.Set("userID", claims.UserID)
		c.Set("username", claims.Username)

		c.Next()
	}
}
</file>

<file path="server/internal/model/application.go">
package model

import (
	"gorm.io/datatypes" // éœ€è¦ go get gorm.io/datatypes
)

type Application struct {
	BaseModel
	Name        string `gorm:"size:100;not null" json:"name"`
	Description string `gorm:"size:255" json:"description"`
	Avatar      string `json:"avatar"`

	// å½’å±
	OrgID     *uint `gorm:"index" json:"org_id"`
	CreatorID uint  `gorm:"index;not null" json:"creator_id"`

	// ğŸ¤– æ™ºèƒ½ä½“é…ç½® (JSON)
	// åŒ…å«: {"model": "deepseek-v3", "prompts": "ä½ æ˜¯ä¸€ä¸ª...", "temperature": 0.7}
	AgentConfig datatypes.JSON `json:"agent_config"`

	// ğŸ”— å…³è”çŸ¥è¯†åº“ (å¤šå¯¹å¤š)
	// GORM ä¼šè‡ªåŠ¨åˆ›å»º application_knowledge_bases ä¸­é—´è¡¨
	KnowledgeBases []*KnowledgeBase `gorm:"many2many:app_kb_relations;" json:"knowledge_bases"`

	Status string `gorm:"default:'active'" json:"status"` // active, disabled
}
</file>

<file path="server/internal/model/base.go">
package model

import (
	"gorm.io/gorm"
	"time"
)

// StandardModel æ›¿ä»£ gorm.Modelï¼Œæ–¹ä¾¿è‡ªå®šä¹‰ JSON tag
type BaseModel struct {
	ID        uint           `gorm:"primarykey" json:"id"`
	CreatedAt time.Time      `json:"created_at"`
	UpdatedAt time.Time      `json:"updated_at"`
	DeletedAt gorm.DeletedAt `gorm:"index" json:"-"`
}
</file>

<file path="server/internal/model/datasource.go">
package model

import (
	"gorm.io/datatypes"
	"time"
)

type DataSource struct {
	BaseModel
	KnowledgeBaseID uint `gorm:"index;not null" json:"knowledge_base_id"`

	// ç±»å‹åŒºåˆ†: "file", "feishu_wiki", "dingtalk", "web_crawl"
	Type string `gorm:"size:50;not null;index" json:"type"`

	// åç§°: æ–‡ä»¶å æˆ– é£ä¹¦çŸ¥è¯†åº“æ ‡é¢˜
	Name string `gorm:"size:255;not null" json:"name"`

	// ğŸ”¥ æ ¸å¿ƒé…ç½® (JSON) - æ‰€æœ‰çš„æºæ•°æ®éƒ½å­˜åœ¨è¿™
	// File:   {"storage_path": "minio://...", "size": 1024, "ext": ".pdf"}
	// Feishu: {"app_id": "...", "root_token": "..."}
	Config datatypes.JSON `json:"config"`

	// çŠ¶æ€æœº: pending -> syncing -> active / error
	Status   string `gorm:"default:'pending';index" json:"status"`
	ErrorMsg string `json:"error_msg"`

	// ç»Ÿè®¡æ•°æ®
	ChunkCount   int       `json:"chunk_count"`
	PageCount    int       `json:"page_count"`
	LastSyncTime time.Time `json:"last_sync_time"`
}
</file>

<file path="server/internal/model/knowledge_base.go">
package model

type KnowledgeBase struct {
	BaseModel
	Name        string `gorm:"size:100;not null" json:"name"`
	Description string `json:"description"`
	Avatar      string `json:"avatar"`

	// å½’å±
	OrgID     *uint `gorm:"index" json:"org_id"`
	CreatorID uint  `gorm:"index;not null" json:"creator_id"`

	// ğŸ”— å…³è”æ•°æ®æº (ä¸€å¯¹å¤š)
	DataSources []DataSource `gorm:"foreignKey:KnowledgeBaseID" json:"data_sources"`
}
</file>

<file path="server/internal/model/organization.go">
package model

import "time"

type Organization struct {
	BaseModel
	Name        string `gorm:"size:100;not null" json:"name"`
	Description string `gorm:"size:255" json:"description"`
	Key         string `gorm:"uniqueIndex;size:50" json:"key"`

	OwnerID uint `gorm:"index;not null" json:"owner_id"`

	// å…³è”
	Members        []OrganizationMember `gorm:"foreignKey:OrganizationID" json:"members"`
	KnowledgeBases []KnowledgeBase      `gorm:"foreignKey:OrgID" json:"knowledge_bases"`
}

// OrganizationMember ä¸­é—´è¡¨ï¼šè®°å½•ç”¨æˆ·åœ¨ç»„ç»‡é‡Œçš„è§’è‰²
type OrganizationMember struct {
	OrganizationID uint `gorm:"primaryKey" json:"organization_id"`
	UserID         uint `gorm:"primaryKey" json:"user_id"`

	// è§’è‰²: owner, admin, member
	Role     string    `gorm:"size:20;default:'member'" json:"role"`
	JoinedAt time.Time `json:"joined_at"`

	// é¢„åŠ è½½å…³è”
	User         User         `json:"user"`
	Organization Organization `json:"organization"`
}
</file>

<file path="server/internal/model/run_log.go">
package model

import (
	"time"

	"gorm.io/datatypes"
)

// AppRunLog è®°å½•æ¯ä¸€æ¬¡æ™ºèƒ½ä½“è¿è¡Œçš„è¯¦ç»†ä¿¡æ¯
type AppRunLog struct {
	ID        uint      `gorm:"primarykey" json:"id"`
	CreatedAt time.Time `json:"created_at"`

	// ç´¢å¼•å­—æ®µ (ç”¨äºå¤šç§Ÿæˆ·æŸ¥è¯¢)
	OrgID     uint   `gorm:"index;not null" json:"org_id"`
	AppID     string `gorm:"index;not null" json:"app_id"`
	UserID    uint   `gorm:"index;not null" json:"user_id"`
	SessionID string `gorm:"index" json:"session_id"`
	TraceID   string `gorm:"index" json:"trace_id"` // å…³è” SigNoz

	// è¾“å…¥è¾“å‡ºå¿«ç…§
	Query  string `gorm:"type:text" json:"query"`
	Answer string `gorm:"type:text" json:"answer"` // æœ€ç»ˆå®Œæ•´å›ç­”

	// ç»Ÿè®¡æŒ‡æ ‡
	TotalTokens      int   `json:"total_tokens"`
	PromptTokens     int   `json:"prompt_tokens"`
	CompletionTokens int   `json:"completion_tokens"`
	DurationMs       int64 `json:"duration_ms"`

	Status string `gorm:"size:20" json:"status"` // success, failed

	// æ‰©å±•å­—æ®µ (ç•™ç»™æœªæ¥å­˜è¯¦ç»†æ­¥éª¤ JSON)
	MetaInfo datatypes.JSON `json:"meta_info"`
}
</file>

<file path="server/internal/model/user.go">
package model

type User struct {
	BaseModel
	Username     string `gorm:"uniqueIndex;size:50;not null" json:"username"`
	PasswordHash string `gorm:"not null" json:"-"`
	Email        string `gorm:"size:100" json:"email"`
	Avatar       string `gorm:"size:255" json:"avatar"`

	// ç³»ç»Ÿçº§è§’è‰² (sys_admin, user) - ç”¨äºç®¡ç†æ•´ä¸ªå¹³å°
	Role string `gorm:"default:'user'" json:"role"`

	// ğŸ”¥ æˆ‘åŠ å…¥çš„ç»„ç»‡ (é€šè¿‡ä¸­é—´è¡¨å…³è”)
	Memberships []OrganizationMember `gorm:"foreignKey:UserID" json:"memberships"`
}
</file>

<file path="server/internal/repository/user_repo.go">
package repository

import (
	"Chimera/server/internal/model"
	"gorm.io/gorm"
)

type UserRepository interface {
	Create(user *model.User) error
	GetByUsername(username string) (*model.User, error)
	IsUsernameExist(username string) bool
}

type userRepository struct {
	db *gorm.DB
}

func NewUserRepository(db *gorm.DB) UserRepository {
	return &userRepository{db: db}
}

func (r *userRepository) Create(user *model.User) error {
	return r.db.Create(user).Error
}

func (r *userRepository) GetByUsername(username string) (*model.User, error) {
	var user model.User
	if err := r.db.Where("username = ?", username).First(&user).Error; err != nil {
		return nil, err
	}
	return &user, nil
}

func (r *userRepository) IsUsernameExist(username string) bool {
	var count int64
	r.db.Model(&model.User{}).Where("username = ?", username).Count(&count)
	return count > 0
}
</file>

<file path="server/internal/service/adapter.go">
package service

import (
	pb "Chimera/server/api/runtime/v1"
	"context"
)

type RuntimeAdapter struct {
	client pb.RuntimeServiceClient
}

func NewRuntimeAdapter(client pb.RuntimeServiceClient) *RuntimeAdapter {
	return &RuntimeAdapter{client: client}
}

func (a *RuntimeAdapter) SyncDataSource(ctx context.Context, req *pb.SyncRequest) (*pb.SyncResponse, error) {
	return a.client.SyncDataSource(ctx, req)
}

// StreamChat æ–¹æ³•
func (a *RuntimeAdapter) StreamChat(ctx context.Context, req *pb.RunAgentRequest) (pb.RuntimeService_RunAgentClient, error) {
	return a.client.RunAgent(ctx, req)
}
</file>

<file path="server/internal/service/auth_service.go">
package service

import (
	"Chimera/server/internal/dto"
	"Chimera/server/internal/model"
	"Chimera/server/internal/repository"
	"Chimera/server/internal/utils" // å¼•ç”¨ä½ å†™çš„ utils
	"errors"
)

type AuthService interface {
	Register(req dto.RegisterReq) (uint, error)
	Login(req dto.LoginReq) (*dto.LoginResp, error)
}

type authService struct {
	repo repository.UserRepository
}

func NewAuthService(repo repository.UserRepository) AuthService {
	return &authService{repo: repo}
}

// Register æ³¨å†Œä¸šåŠ¡é€»è¾‘
func (s *authService) Register(req dto.RegisterReq) (uint, error) {
	// 1. ä¸šåŠ¡æ£€æŸ¥ï¼šç”¨æˆ·åæ˜¯å¦å­˜åœ¨
	if s.repo.IsUsernameExist(req.Username) {
		return 0, errors.New("ç”¨æˆ·åå·²å­˜åœ¨")
	}

	// 2. å¯†ç åŠ å¯†
	hash, err := utils.HashPassword(req.Password)
	if err != nil {
		return 0, errors.New("å¯†ç åŠ å¯†å¤±è´¥")
	}

	// 3. ç»„è£… Model
	user := &model.User{
		Username:     req.Username,
		PasswordHash: hash,
		Email:        req.Email,
		Role:         "user",
	}

	// 4. è½åº“
	if err := s.repo.Create(user); err != nil {
		return 0, err
	}

	return user.ID, nil
}

// Login ç™»å½•ä¸šåŠ¡é€»è¾‘
func (s *authService) Login(req dto.LoginReq) (*dto.LoginResp, error) {
	// 1. æŸ¥ç”¨æˆ·
	user, err := s.repo.GetByUsername(req.Username)
	if err != nil {
		return nil, errors.New("ç”¨æˆ·ä¸å­˜åœ¨")
	}

	// 2. æ¯”å¯¹å¯†ç 
	if !utils.CheckPasswordHash(req.Password, user.PasswordHash) {
		return nil, errors.New("å¯†ç é”™è¯¯")
	}

	// 3. ç­¾å‘ Token
	token, err := utils.GenerateToken(user.ID, user.Username, user.Role)
	if err != nil {
		return nil, errors.New("Token ç”Ÿæˆå¤±è´¥")
	}

	return &dto.LoginResp{
		Token:    token,
		Username: user.Username,
		UserID:   user.ID,
	}, nil
}
</file>

<file path="server/internal/service/chat_service.go">
package service

import (
	"context"
	"encoding/json"
	"errors"
	"fmt"
	"io"
	"log"
	"strings"
	"time"

	pb "Chimera/server/api/runtime/v1"
	"Chimera/server/internal/data"
	"Chimera/server/internal/dto"
	"Chimera/server/internal/model"
)

// ChatService
// èŒè´£ï¼šåªä¸“æ³¨äºå¯¹è¯æµã€å†å²è®°å½•ã€æ—¥å¿—å®¡è®¡
type ChatService struct {
	Data    *data.Data
	Adapter *RuntimeAdapter
}

// NewChatService æ„é€ å‡½æ•°
func NewChatService(data *data.Data, adapter *RuntimeAdapter) *ChatService {
	return &ChatService{
		Data:    data,
		Adapter: adapter,
	}
}

// StreamChat å¤„ç†å¯¹è¯è¯·æ±‚
func (s *ChatService) StreamChat(ctx context.Context, userID uint, req dto.ChatReq, respChan chan<- string) {
	defer close(respChan)

	// 1. é‰´æƒ
	if req.KbID > 0 {
		if err := s.checkKbPermission(req.KbID, userID); err != nil {
			respChan <- fmt.Sprintf("ERR: â›”ï¸ %s", err.Error())
			return
		}
	}

	// 2. æ„é€ é…ç½®ç»™ Python
	configData := map[string]interface{}{
		"kb_ids": []uint{req.KbID},
		"org_id": req.OrgID,
	}
	configBytes, _ := json.Marshal(configData)

	grpcReq := &pb.RunAgentRequest{
		AppId:         "default_chat_app",
		Query:         req.Query,
		SessionId:     req.SessionID,
		AppConfigJson: string(configBytes),
	}

	// 3. è°ƒç”¨ Adapter
	stream, err := s.Adapter.StreamChat(ctx, grpcReq)
	if err != nil {
		log.Printf("âŒ gRPC Link Error: %v", err)
		respChan <- "ERR: æœåŠ¡ç«¯è¿æ¥å¤±è´¥"
		return
	}

	// 4. å¤„ç†æµå“åº”
	var fullAnswerBuilder strings.Builder
	for {
		resp, err := stream.Recv()
		if err == io.EOF {
			break
		}
		if err != nil {
			log.Printf("âŒ gRPC Recv Error: %v", err)
			return
		}

		switch resp.Type {
		case "delta":
			respChan <- resp.Payload
			fullAnswerBuilder.WriteString(resp.Payload)
		case "thought":
			respChan <- "THOUGHT: " + resp.Payload
		case "reference":
			respChan <- "REF: " + resp.Payload
		case "summary":
			go s.saveRunLog(userID, req, resp.Summary, fullAnswerBuilder.String())
		case "error":
			respChan <- "\n[Error]: " + resp.Payload
		}
	}
}

// checkKbPermission ç§æœ‰é‰´æƒ (ChatService ç‹¬äº«)
func (s *ChatService) checkKbPermission(kbID uint, userID uint) error {
	var kb model.KnowledgeBase
	if err := s.Data.DB.First(&kb, kbID).Error; err != nil {
		return errors.New("çŸ¥è¯†åº“ä¸å­˜åœ¨")
	}
	if kb.OrgID != nil {
		var count int64
		s.Data.DB.Model(&model.OrganizationMember{}).
			Where("organization_id = ? AND user_id = ?", *kb.OrgID, userID).
			Count(&count)
		if count == 0 {
			return errors.New("æ— æƒè®¿é—®è¯¥ç»„ç»‡çŸ¥è¯†åº“")
		}
		return nil
	}
	if kb.CreatorID != userID {
		return errors.New("æ— æƒè®¿é—®è¯¥çŸ¥è¯†åº“")
	}
	return nil
}

// saveRunLog æ—¥å¿—è½åº“
func (s *ChatService) saveRunLog(userID uint, req dto.ChatReq, summary *pb.RunSummary, answer string) {
	ctx, cancel := context.WithTimeout(context.Background(), 5*time.Second)
	defer cancel()

	runLog := &model.AppRunLog{
		OrgID:            req.OrgID,
		AppID:            "default_chat_app",
		UserID:           userID,
		SessionID:        req.SessionID,
		Query:            req.Query,
		Answer:           answer,
		TotalTokens:      int(summary.TotalTokens),
		PromptTokens:     int(summary.PromptTokens),
		CompletionTokens: int(summary.CompletionTokens),
		DurationMs:       summary.TotalDurationMs,
		Status:           summary.FinalStatus,
	}

	if err := s.Data.DB.WithContext(ctx).Create(runLog).Error; err != nil {
		log.Printf("âŒ æ—¥å¿—å…¥åº“å¤±è´¥: %v", err)
	}
}
</file>

<file path="server/internal/service/datasource_service.go">
package service

import (
	"context"
	"encoding/json"
	"errors"
	"fmt"
	"mime/multipart"
	"path/filepath"
	"strings"
	"time"

	pb "Chimera/server/api/runtime/v1"
	"Chimera/server/internal/core"
	"Chimera/server/internal/data"
	"Chimera/server/internal/dto"
	"Chimera/server/internal/model"

	"github.com/minio/minio-go/v7"
	"gorm.io/datatypes"
)

type DataSourceService struct {
	Data    *data.Data
	Adapter *RuntimeAdapter
}

func NewDataSourceService(data *data.Data, adapter *RuntimeAdapter) *DataSourceService {
	return &DataSourceService{
		Data:    data,
		Adapter: adapter,
	}
}

// CreateDataSource é€šç”¨åˆ›å»ºæ¥å£ (API/SaaSæº)
func (s *DataSourceService) CreateDataSource(ctx context.Context, userID uint, req dto.CreateDataSourceReq) (*model.DataSource, error) {
	// 1. é‰´æƒ
	if err := s.checkKbPermission(req.KbID, userID); err != nil {
		return nil, err
	}

	// 2. æ ¡éªŒé…ç½® (ä¼ä¸šç‰ˆæ³¨å…¥ç‚¹)
	if err := core.GlobalRegistry.Validate(req.Type, req.Config); err != nil {
		return nil, fmt.Errorf("é…ç½®æ ¡éªŒå¤±è´¥: %v", err)
	}

	// 3. åºåˆ—åŒ–
	configBytes, err := json.Marshal(req.Config)
	if err != nil {
		return nil, errors.New("é…ç½®æ ¼å¼é”™è¯¯")
	}

	// 4. è½åº“
	ds := &model.DataSource{
		KnowledgeBaseID: req.KbID,
		Type:            req.Type,
		Name:            req.Name,
		Config:          datatypes.JSON(configBytes),
		Status:          "pending",
	}
	if err := s.Data.DB.WithContext(ctx).Create(ds).Error; err != nil {
		return nil, err
	}

	// 5. è§¦å‘ ETL
	s.triggerAsyncETL(ds.ID, req.KbID, req.Type, configBytes)

	return ds, nil
}

// UploadFile ä¸Šä¼ æ–‡ä»¶æ¥å£ (æ–‡ä»¶æº)
func (s *DataSourceService) UploadFile(ctx context.Context, fileHeader *multipart.FileHeader, userID uint, kbID uint) (*model.DataSource, error) {
	// 1. é‰´æƒ
	if err := s.checkKbPermission(kbID, userID); err != nil {
		return nil, err
	}

	// 2. MinIO ä¸Šä¼ 
	src, err := fileHeader.Open()
	if err != nil {
		return nil, err
	}
	defer src.Close()

	storagePath, err := s.Data.UploadFile(ctx, src, fileHeader.Size, fileHeader.Filename)
	if err != nil {
		return nil, err
	}

	// 3. æ„é€ é…ç½®
	configMap := map[string]interface{}{
		"storage_path": storagePath,
		"file_size":    fileHeader.Size,
		"file_ext":     strings.ToLower(filepath.Ext(fileHeader.Filename)),
		"file_name":    fileHeader.Filename,
	}
	configBytes, _ := json.Marshal(configMap)

	// 4. è½åº“
	ds := &model.DataSource{
		KnowledgeBaseID: kbID,
		Type:            "file",
		Name:            fileHeader.Filename,
		Config:          datatypes.JSON(configBytes),
		Status:          "pending",
	}
	if err := s.Data.DB.WithContext(ctx).Create(ds).Error; err != nil {
		return nil, err
	}

	// 5. è§¦å‘ ETL
	s.triggerAsyncETL(ds.ID, kbID, "file", configBytes)

	return ds, nil
}

// GetFile è·å–æ–‡ä»¶æµ (ç”¨äºé¢„è§ˆ/ä¸‹è½½)
func (s *DataSourceService) GetFile(ctx context.Context, fileName string) (*minio.Object, int64, error) {
	// æ¡¶åç¡¬ç¼–ç æˆ–ä»é…ç½®è¯»å–
	bucketName := "chimera-docs"
	return s.Data.GetFileStream(ctx, bucketName, fileName)
}

// --- ç§æœ‰è¾…åŠ©æ–¹æ³• ---

// checkKbPermission é‰´æƒ
func (s *DataSourceService) checkKbPermission(kbID uint, userID uint) error {
	var kb model.KnowledgeBase
	if err := s.Data.DB.First(&kb, kbID).Error; err != nil {
		return errors.New("çŸ¥è¯†åº“ä¸å­˜åœ¨")
	}
	// ç»„ç»‡åº“é‰´æƒ
	if kb.OrgID != nil {
		var count int64
		s.Data.DB.Model(&model.OrganizationMember{}).
			Where("organization_id = ? AND user_id = ?", *kb.OrgID, userID).
			Count(&count)
		if count == 0 {
			return errors.New("æƒé™ä¸è¶³ï¼šä½ ä¸æ˜¯è¯¥ç»„ç»‡æˆå‘˜")
		}
		return nil
	}
	// ä¸ªäººåº“é‰´æƒ
	if kb.CreatorID != userID {
		return errors.New("æƒé™ä¸è¶³")
	}
	return nil
}

// triggerAsyncETL å¼‚æ­¥è§¦å‘
func (s *DataSourceService) triggerAsyncETL(dsID uint, kbID uint, sourceType string, configBytes []byte) {
	go func() {
		// 30åˆ†é’Ÿè¶…æ—¶
		bgCtx, cancel := context.WithTimeout(context.Background(), 30*time.Minute)
		defer cancel()

		s.updateDataSourceStatus(dsID, "syncing", "", 0, 0)

		// è°ƒç”¨ Adapter (gRPC)
		resp, err := s.Adapter.SyncDataSource(bgCtx, &pb.SyncRequest{
			KbId:         int64(kbID),
			DatasourceId: int64(dsID),
			Type:         sourceType,
			ConfigJson:   string(configBytes),
		})

		if err != nil {
			s.updateDataSourceStatus(dsID, "failed", fmt.Sprintf("RPC Error: %v", err), 0, 0)
			return
		}

		if !resp.Success {
			s.updateDataSourceStatus(dsID, "failed", resp.ErrorMsg, 0, 0)
			return
		}

		s.updateDataSourceStatus(dsID, "active", "", int(resp.ChunksCount), int(resp.PageCount))
	}()
}

// updateDataSourceStatus æ›´æ–°çŠ¶æ€
func (s *DataSourceService) updateDataSourceStatus(id uint, status string, errMsg string, chunks, pages int) {
	updates := map[string]interface{}{
		"status":         status,
		"error_msg":      errMsg,
		"last_sync_time": time.Now(),
	}
	if chunks > 0 {
		updates["chunk_count"] = chunks
	}
	if pages > 0 {
		updates["page_count"] = pages
	}
	s.Data.DB.Model(&model.DataSource{}).Where("id = ?", id).Updates(updates)
}
</file>

<file path="server/internal/service/kb_service.go">
package service

import (
	"Chimera/server/internal/data"
	"Chimera/server/internal/dto"
	"Chimera/server/internal/model"
	"context"
	"errors"
)

type KBService struct {
	Data *data.Data
}

func NewKBService(data *data.Data) *KBService {
	return &KBService{Data: data}
}

// CreateKnowledgeBase åˆ›å»ºçŸ¥è¯†åº“
func (s *KBService) CreateKnowledgeBase(ctx context.Context, userID uint, req dto.CreateKBReq) (*dto.KBResp, error) {
	var orgIDPtr *uint
	if req.OrgID > 0 {
		val := req.OrgID
		orgIDPtr = &val
	}

	// 1. æ„é€ æ¨¡å‹
	kb := &model.KnowledgeBase{
		Name:        req.Name,
		Description: req.Description,
		CreatorID:   userID,
		OrgID:       orgIDPtr, // ä¼ å…¥æŒ‡é’ˆ (nil æˆ– &id)
	}

	// 2. æƒé™/å½’å±æ£€æŸ¥
	if req.OrgID > 0 {
		// --- ç»„ç»‡æ¨¡å¼ ---
		var count int64
		err := s.Data.DB.Model(&model.OrganizationMember{}).
			Where("organization_id = ? AND user_id = ?", req.OrgID, userID).
			Count(&count).Error
		if err != nil {
			return nil, err
		}
		if count == 0 {
			return nil, errors.New("æƒé™ä¸è¶³ï¼šä½ ä¸æ˜¯è¯¥ç»„ç»‡çš„æˆå‘˜")
		}
	} else {
		// --- ä¸ªäººæ¨¡å¼ ---
		// é€»è¾‘ä¿æŒç®€å•ï¼ŒOrgID=0 å³ä¸ºä¸ªäºº
	}

	// 3. è½åº“
	if err := s.Data.DB.Create(kb).Error; err != nil {
		return nil, err
	}

	// 4. è¿”å›ç»“æœ
	return &dto.KBResp{
		ID:          kb.ID,
		Name:        kb.Name,
		Description: kb.Description,
		Type:        "folder", // æš‚æ—¶ç¡¬ç¼–ç æˆ–ä» req è·å–ï¼ˆå¦‚æœ DTO è¿˜æœ‰çš„è¯ï¼‰
		CreatorID:   kb.CreatorID,
		OrgID:       orgIDPtr,
		CreatedAt:   kb.CreatedAt,
	}, nil
}

// ListKnowledgeBases è·å–åˆ—è¡¨
func (s *KBService) ListKnowledgeBases(ctx context.Context, userID uint, orgID uint) ([]dto.KBResp, error) {
	var kbs []model.KnowledgeBase
	db := s.Data.DB.Model(&model.KnowledgeBase{})

	if orgID > 0 {
		// æŸ¥ç»„ç»‡åº“
		// 1. æ£€æŸ¥æˆå‘˜èµ„æ ¼
		var isMember int64
		s.Data.DB.Model(&model.OrganizationMember{}).
			Where("organization_id = ? AND user_id = ?", orgID, userID).
			Count(&isMember)
		if isMember == 0 {
			return nil, errors.New("æƒé™ä¸è¶³")
		}
		// 2. è¿‡æ»¤
		db = db.Where("org_id = ?", orgID)
	} else {
		// æŸ¥ä¸ªäººåº“ (OrgID is NULL)
		db = db.Where("creator_id = ? AND org_id IS NULL", userID)
	}

	if err := db.Order("created_at desc").Find(&kbs).Error; err != nil {
		return nil, err
	}

	var result []dto.KBResp
	for _, k := range kbs {
		result = append(result, dto.KBResp{
			ID:          k.ID,
			Name:        k.Name,
			Description: k.Description,
			Type:        "folder",
			CreatorID:   k.CreatorID,
			OrgID:       k.OrgID,
			CreatedAt:   k.CreatedAt,
		})
	}
	return result, nil
}
</file>

<file path="server/internal/service/log_service.go">
package service

import (
	"Chimera/server/internal/data"
	"Chimera/server/internal/dto"
	"Chimera/server/internal/model"
	"context"
	"fmt"
	"time"
)

type LogService struct {
	Data *data.Data
}

func NewLogService(data *data.Data) *LogService {
	return &LogService{Data: data}
}

// GetLogList è·å–æ—¥å¿—åˆ—è¡¨ (æ”¯æŒåˆ†é¡µå’Œç­›é€‰)
func (s *LogService) GetLogList(ctx context.Context, userID uint, req dto.LogListReq) (*dto.LogListResp, error) {
	var logs []model.AppRunLog
	var total int64

	db := s.Data.DB.Model(&model.AppRunLog{})

	// 1. æƒé™æ§åˆ¶: æš‚æ—¶åªçœ‹è‡ªå·±æ‰€å±ç»„ç»‡çš„æ—¥å¿— (æˆ–è€…ç”±ä¸Šå±‚ Handler æ§åˆ¶ OrgID)
	// è¿™é‡Œç®€åŒ–ï¼šæŸ¥è¯¢ç”¨æˆ·æœ‰æƒé™çš„ App (å¦‚æœè¦åšä¸¥æ ¼é‰´æƒï¼Œéœ€è¦å…³è” OrganizationMember)
	// ç›®å‰ v0.6.0 alpha é˜¶æ®µï¼Œå‡è®¾ä¼ å…¥äº† AppIDï¼Œæˆ‘ä»¬å°±ä¸åšå¤ªå¤æ‚çš„è·¨è¡¨é‰´æƒäº†ï¼Œå…ˆè·‘é€šæ•°æ®ã€‚

	if req.AppID != "" {
		db = db.Where("app_id = ?", req.AppID)
	}
	if req.Status != "" {
		db = db.Where("status = ?", req.Status)
	}

	// è®¡ç®—æ€»æ•°
	db.Count(&total)

	// åˆ†é¡µæŸ¥è¯¢
	offset := (req.Page - 1) * req.PageSize
	// é¢„åŠ è½½ User ä¿¡æ¯ï¼Ÿæ—¥å¿—è¡¨é‡Œåªå­˜äº† UserID
	// è¿™é‡Œç”¨ Preload éœ€è¦åœ¨ Model é‡Œå®šä¹‰å…³è”ï¼Œæˆ–è€…æ‰‹åŠ¨æŸ¥ã€‚
	// ä¸ºäº†æ€§èƒ½ï¼Œåˆ—è¡¨é¡µé€šå¸¸ä¸æŸ¥ User è¯¦æƒ…ï¼Œæˆ–è€… Join æŸ¥è¯¢ã€‚
	if err := db.Order("created_at desc").Limit(req.PageSize).Offset(offset).Find(&logs).Error; err != nil {
		return nil, err
	}

	// è½¬æ¢ä¸º DTO
	var list []dto.LogSummary
	for _, l := range logs {
		// æˆªå– Queryï¼Œé˜²æ­¢åˆ—è¡¨é¡µå¤ªé•¿
		shortQuery := l.Query
		if len(shortQuery) > 50 {
			shortQuery = shortQuery[:50] + "..."
		}

		list = append(list, dto.LogSummary{
			ID:          l.ID,
			TraceID:     l.TraceID,
			AppID:       l.AppID,
			User:        fmt.Sprintf("User-%d", l.UserID), // æš‚æ—¶æ˜¾ç¤º IDï¼Œåç»­ä¼˜åŒ–
			Query:       shortQuery,
			Answer:      l.Answer,
			TotalTokens: l.TotalTokens,
			DurationMs:  l.DurationMs,
			Status:      l.Status,
			CreatedAt:   l.CreatedAt,
		})
	}

	return &dto.LogListResp{
		Total: total,
		List:  list,
	}, nil
}

// GetAppStats è·å–åº”ç”¨ç»Ÿè®¡æ•°æ® (å›¾è¡¨ç”¨)
func (s *LogService) GetAppStats(ctx context.Context, req dto.AppStatsReq) (*dto.AppStatsResp, error) {
	// 1. æ€»ä½“ç»Ÿè®¡
	var totalStats struct {
		SumTokens   int64
		CountCalls  int64
		SumDuration int64
	}

	// è®¡ç®—æ—¶é—´èŒƒå›´
	startTime := time.Now().AddDate(0, 0, -req.Days)

	db := s.Data.DB.Model(&model.AppRunLog{}).Where("created_at >= ?", startTime)
	if req.AppID != "" {
		db = db.Where("app_id = ?", req.AppID)
	}

	err := db.Select("sum(total_tokens) as sum_tokens, count(id) as count_calls, sum(duration_ms) as sum_duration").
		Scan(&totalStats).Error
	if err != nil {
		return nil, err
	}

	avgDuration := int64(0)
	if totalStats.CountCalls > 0 {
		avgDuration = totalStats.SumDuration / totalStats.CountCalls
	}

	// 2. æ¯æ—¥è¶‹åŠ¿ (èšåˆæŸ¥è¯¢)
	// Postgres ä½¿ç”¨ TO_CHAR(created_at, 'YYYY-MM-DD')
	type DailyRow struct {
		Date        string
		TotalTokens int64
		CallCount   int64
	}
	var dailyRows []DailyRow

	err = db.Select("TO_CHAR(created_at, 'YYYY-MM-DD') as date, sum(total_tokens) as total_tokens, count(id) as call_count").
		Group("date").
		Order("date").
		Scan(&dailyRows).Error
	if err != nil {
		return nil, err
	}

	// è½¬æ¢
	var dailyMetrics []dto.DailyMetric
	for _, row := range dailyRows {
		dailyMetrics = append(dailyMetrics, dto.DailyMetric{
			Date:   row.Date,
			Tokens: row.TotalTokens,
			Calls:  row.CallCount,
		})
	}

	return &dto.AppStatsResp{
		TotalCalls:    totalStats.CountCalls,
		TotalTokens:   totalStats.SumTokens,
		AvgDurationMs: avgDuration,
		DailyStats:    dailyMetrics,
	}, nil
}
</file>

<file path="server/internal/service/org_service.go">
package service

import (
	"Chimera/server/internal/data"
	"Chimera/server/internal/dto"
	"Chimera/server/internal/model"
	"context"
	"errors"
	"gorm.io/gorm"
	"math/rand"
)

type OrgService struct {
	Data *data.Data
}

func NewOrgService(data *data.Data) *OrgService {
	return &OrgService{Data: data}
}

// CreateOrganization åˆ›å»ºç»„ç»‡
func (s *OrgService) CreateOrganization(ctx context.Context, userID uint, req dto.CreateOrgReq) (*dto.OrgResp, error) {
	// ğŸ‘‡ è‡ªåŠ¨è¡¥å…¨é€»è¾‘
	if req.Key == "" {
		// ç”Ÿæˆä¸€ä¸ª 8 ä½çš„éšæœº Keyï¼Œä¾‹å¦‚ "xk9d2m1a"
		req.Key = generateRandomKey(8)
	}
	// 1. æ£€æŸ¥ Key æ˜¯å¦å·²å­˜åœ¨ (Key å¿…é¡»å”¯ä¸€)
	var count int64
	s.Data.DB.Model(&model.Organization{}).Where("key = ?", req.Key).Count(&count)
	if count > 0 {
		return nil, errors.New("ç»„ç»‡æ ‡è¯†(Key)å·²å­˜åœ¨ï¼Œè¯·æ¢ä¸€ä¸ª")
	}

	org := &model.Organization{
		Name:        req.Name,
		Description: req.Description,
		Key:         req.Key,
		OwnerID:     userID,
	}

	// 2. å¼€å¯äº‹åŠ¡ï¼šåˆ›å»ºç»„ç»‡ + æ·»åŠ æˆå‘˜
	err := s.Data.DB.Transaction(func(tx *gorm.DB) error {
		// A. åˆ›å»ºç»„ç»‡è®°å½•
		if err := tx.Create(org).Error; err != nil {
			return err
		}

		// B. å°†åˆ›å»ºè€…åŠ å…¥æˆå‘˜è¡¨ï¼Œå¹¶è®¾ä¸º Owner
		member := &model.OrganizationMember{
			OrganizationID: org.ID,
			UserID:         userID,
			Role:           "owner",
		}
		if err := tx.Create(member).Error; err != nil {
			return err // è¿”å›é”™è¯¯ä¼šè§¦å‘å›æ»š
		}

		return nil
	})

	if err != nil {
		return nil, err
	}

	// 3. è¿”å›ç»“æœ
	return &dto.OrgResp{
		ID:          org.ID,
		Name:        org.Name,
		Description: org.Description,
		Key:         org.Key,
		OwnerID:     org.OwnerID,
		CreatedAt:   org.CreatedAt,
	}, nil
}

// ListUserOrganizations è·å–ç”¨æˆ·åŠ å…¥çš„æ‰€æœ‰ç»„ç»‡
func (s *OrgService) ListUserOrganizations(ctx context.Context, userID uint) ([]dto.OrgResp, error) {
	var memberships []model.OrganizationMember

	// 1. æŸ¥è¯¢ä¸­é—´è¡¨ï¼Œå¹¶é¢„åŠ è½½ Organization å®ä½“
	// SELECT * FROM organization_members WHERE user_id = ?
	if err := s.Data.DB.
		Preload("Organization").
		Where("user_id = ?", userID).
		Find(&memberships).Error; err != nil {
		return nil, err
	}

	// 2. è½¬æ¢ä¸º DTO
	var result []dto.OrgResp
	for _, m := range memberships {
		// ç¨å¾®é˜²å¾¡ä¸€ä¸‹ï¼Œä¸‡ä¸€ç»„ç»‡è¢«åˆ äº†ä½†ä¸­é—´è¡¨è¿˜åœ¨
		if m.Organization.ID == 0 {
			continue
		}

		result = append(result, dto.OrgResp{
			ID:          m.Organization.ID,
			Name:        m.Organization.Name,
			Description: m.Organization.Description,
			Key:         m.Organization.Key,
			OwnerID:     m.Organization.OwnerID, // æ³¨æ„ï¼šè¿™é‡Œçš„ OwnerID æ˜¯ç»„ç»‡çš„æ‹¥æœ‰è€…ï¼Œä¸æ˜¯å½“å‰ç”¨æˆ·
			CreatedAt:   m.Organization.CreatedAt,
			// ğŸ’¡ å¯ä»¥åœ¨è¿™é‡ŒåŠ ä¸€ä¸ª UserRole: m.Role è¿”å›ç»™å‰ç«¯ï¼Œå‘Šè¯‰å‰ç«¯æˆ‘åœ¨è¿™ä¸ªç»„é‡Œæ˜¯ä»€ä¹ˆè§’è‰²
		})
	}

	return result, nil
}

func generateRandomKey(n int) string {
	const letters = "abcdefghijklmnopqrstuvwxyz0123456789"
	b := make([]byte, n)
	for i := range b {
		b[i] = letters[rand.Intn(len(letters))]
	}
	return string(b)
}
</file>

<file path="server/internal/utils/jwt.go">
package utils

import (
	"time"

	"github.com/golang-jwt/jwt/v5"
)

// JWT ç§˜é’¥ (ç”Ÿäº§ç¯å¢ƒåº”è¯¥ä»é…ç½®æ–‡ä»¶è¯»)
var jwtSecret = []byte("chimera-secret-key-2025")

// Claims è‡ªå®šä¹‰è½½è·
type Claims struct {
	UserID   uint   `json:"user_id"`
	Username string `json:"username"`
	Role     string `json:"role"`
	jwt.RegisteredClaims
}

// GenerateToken ç”Ÿæˆ JWT
func GenerateToken(userID uint, username, role string) (string, error) {
	expirationTime := time.Now().Add(24 * time.Hour) // 1å¤©è¿‡æœŸ
	claims := &Claims{
		UserID:   userID,
		Username: username,
		Role:     role,
		RegisteredClaims: jwt.RegisteredClaims{
			ExpiresAt: jwt.NewNumericDate(expirationTime),
			Issuer:    "Chimera",
		},
	}

	token := jwt.NewWithClaims(jwt.SigningMethodHS256, claims)
	return token.SignedString(jwtSecret)
}

// ParseToken è§£æ Token
func ParseToken(tokenString string) (*Claims, error) {
	tokenClaims, err := jwt.ParseWithClaims(tokenString, &Claims{}, func(token *jwt.Token) (interface{}, error) {
		return jwtSecret, nil
	})

	if tokenClaims != nil {
		if claims, ok := tokenClaims.Claims.(*Claims); ok && tokenClaims.Valid {
			return claims, nil
		}
	}
	return nil, err
}
</file>

<file path="server/internal/utils/password.go">
package utils

import (
	"golang.org/x/crypto/bcrypt"
)

// HashPassword å°†æ˜æ–‡å¯†ç åŠ å¯†ä¸º Hash å­—ç¬¦ä¸²
// ç”¨äºï¼šç”¨æˆ·æ³¨å†Œ (Register)
func HashPassword(password string) (string, error) {
	// GenerateFromPassword ä¼šè‡ªåŠ¨åŠ ç› (Salt)ï¼Œå³ä½¿ä¸¤ä¸ªç”¨æˆ·å¯†ç ç›¸åŒï¼Œç”Ÿæˆçš„ Hash ä¹Ÿä¸åŒ
	// DefaultCost ç›®å‰æ˜¯ 10ï¼Œæ˜¯ä¸€ä¸ªåœ¨æ€§èƒ½å’Œå®‰å…¨æ€§ä¹‹é—´å¹³è¡¡çš„å€¼
	bytes, err := bcrypt.GenerateFromPassword([]byte(password), bcrypt.DefaultCost)
	return string(bytes), err
}

// CheckPasswordHash æ ¡éªŒæ˜æ–‡å¯†ç æ˜¯å¦ä¸ Hash åŒ¹é…
// ç”¨äºï¼šç”¨æˆ·ç™»å½• (Login)
// è¿”å› true è¡¨ç¤ºå¯†ç æ­£ç¡®ï¼Œfalse è¡¨ç¤ºé”™è¯¯
func CheckPasswordHash(password, hash string) bool {
	err := bcrypt.CompareHashAndPassword([]byte(hash), []byte(password))
	return err == nil
}
</file>

<file path="server/Dockerfile">
# server/Dockerfile (Core)
FROM golang:1.24-alpine AS builder

WORKDIR /app
COPY go.mod go.sum ./
ENV GOPROXY=https://goproxy.cn,direct
RUN go mod download

COPY . .
# ğŸ”¥ ç¼–è¯‘å¼€æºå…¥å£
RUN go build -o server cmd/server/main.go

FROM alpine:latest
WORKDIR /app
RUN apk --no-cache add ca-certificates tzdata
COPY --from=builder /app/server .
EXPOSE 8080
CMD ["./server"]
</file>

<file path="server/Dockerfile.ee">
# server/Dockerfile.ee (Enterprise)
FROM golang:1.24-alpine AS builder

WORKDIR /app
COPY go.mod go.sum ./
ENV GOPROXY=https://goproxy.cn,direct
RUN go mod download

COPY . .
# ğŸ”¥ ç¼–è¯‘ä¼ä¸šç‰ˆå…¥å£ (server-ee)
RUN go build -o server-ee cmd/server-ee/main.go

FROM alpine:latest
WORKDIR /app
RUN apk --no-cache add ca-certificates tzdata
COPY --from=builder /app/server-ee .
EXPOSE 8080
# å¯åŠ¨ä¼ä¸šç‰ˆäºŒè¿›åˆ¶
CMD ["./server-ee"]
</file>

<file path="server/main.go">
package server
</file>

<file path="test/test_pb2.py">
# -*- coding: utf-8 -*-
# Generated by the protocol buffer compiler.  DO NOT EDIT!
# source: test.proto
"""Generated protocol buffer code."""
from google.protobuf.internal import builder as _builder
from google.protobuf import descriptor as _descriptor
from google.protobuf import descriptor_pool as _descriptor_pool
from google.protobuf import symbol_database as _symbol_database
# @@protoc_insertion_point(imports)

_sym_db = _symbol_database.Default()




DESCRIPTOR = _descriptor_pool.Default().AddSerializedFile(b'\n\ntest.proto\x12\x04test\"!\n\x05Hello\x12\x0c\n\x04name\x18\x01 \x01(\t\x12\n\n\x02id\x18\x02 \x01(\x05\x42\tZ\x07test/pbb\x06proto3')

_builder.BuildMessageAndEnumDescriptors(DESCRIPTOR, globals())
_builder.BuildTopDescriptorsAndMessages(DESCRIPTOR, 'test_pb2', globals())
if _descriptor._USE_C_DESCRIPTORS == False:

  DESCRIPTOR._options = None
  DESCRIPTOR._serialized_options = b'Z\007test/pb'
  _HELLO._serialized_start=20
  _HELLO._serialized_end=53
# @@protoc_insertion_point(module_scope)
</file>

<file path="test/test.pb.go">
// Code generated by protoc-gen-go. DO NOT EDIT.
// versions:
// 	protoc-gen-go v1.36.11
// 	protoc        v3.20.3
// source: test.proto

package pb

import (
	protoreflect "google.golang.org/protobuf/reflect/protoreflect"
	protoimpl "google.golang.org/protobuf/runtime/protoimpl"
	reflect "reflect"
	sync "sync"
	unsafe "unsafe"
)

const (
	// Verify that this generated code is sufficiently up-to-date.
	_ = protoimpl.EnforceVersion(20 - protoimpl.MinVersion)
	// Verify that runtime/protoimpl is sufficiently up-to-date.
	_ = protoimpl.EnforceVersion(protoimpl.MaxVersion - 20)
)

type Hello struct {
	state         protoimpl.MessageState `protogen:"open.v1"`
	Name          string                 `protobuf:"bytes,1,opt,name=name,proto3" json:"name,omitempty"`
	Id            int32                  `protobuf:"varint,2,opt,name=id,proto3" json:"id,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *Hello) Reset() {
	*x = Hello{}
	mi := &file_test_proto_msgTypes[0]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *Hello) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*Hello) ProtoMessage() {}

func (x *Hello) ProtoReflect() protoreflect.Message {
	mi := &file_test_proto_msgTypes[0]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use Hello.ProtoReflect.Descriptor instead.
func (*Hello) Descriptor() ([]byte, []int) {
	return file_test_proto_rawDescGZIP(), []int{0}
}

func (x *Hello) GetName() string {
	if x != nil {
		return x.Name
	}
	return ""
}

func (x *Hello) GetId() int32 {
	if x != nil {
		return x.Id
	}
	return 0
}

var File_test_proto protoreflect.FileDescriptor

const file_test_proto_rawDesc = "" +
	"\n" +
	"\n" +
	"test.proto\x12\x04test\"+\n" +
	"\x05Hello\x12\x12\n" +
	"\x04name\x18\x01 \x01(\tR\x04name\x12\x0e\n" +
	"\x02id\x18\x02 \x01(\x05R\x02idB\tZ\atest/pbb\x06proto3"

var (
	file_test_proto_rawDescOnce sync.Once
	file_test_proto_rawDescData []byte
)

func file_test_proto_rawDescGZIP() []byte {
	file_test_proto_rawDescOnce.Do(func() {
		file_test_proto_rawDescData = protoimpl.X.CompressGZIP(unsafe.Slice(unsafe.StringData(file_test_proto_rawDesc), len(file_test_proto_rawDesc)))
	})
	return file_test_proto_rawDescData
}

var file_test_proto_msgTypes = make([]protoimpl.MessageInfo, 1)
var file_test_proto_goTypes = []any{
	(*Hello)(nil), // 0: test.Hello
}
var file_test_proto_depIdxs = []int32{
	0, // [0:0] is the sub-list for method output_type
	0, // [0:0] is the sub-list for method input_type
	0, // [0:0] is the sub-list for extension type_name
	0, // [0:0] is the sub-list for extension extendee
	0, // [0:0] is the sub-list for field type_name
}

func init() { file_test_proto_init() }
func file_test_proto_init() {
	if File_test_proto != nil {
		return
	}
	type x struct{}
	out := protoimpl.TypeBuilder{
		File: protoimpl.DescBuilder{
			GoPackagePath: reflect.TypeOf(x{}).PkgPath(),
			RawDescriptor: unsafe.Slice(unsafe.StringData(file_test_proto_rawDesc), len(file_test_proto_rawDesc)),
			NumEnums:      0,
			NumMessages:   1,
			NumExtensions: 0,
			NumServices:   0,
		},
		GoTypes:           file_test_proto_goTypes,
		DependencyIndexes: file_test_proto_depIdxs,
		MessageInfos:      file_test_proto_msgTypes,
	}.Build()
	File_test_proto = out.File
	file_test_proto_goTypes = nil
	file_test_proto_depIdxs = nil
}
</file>

<file path="test/test.proto">
syntax = "proto3";

package test;

option go_package = "test/pb";

message Hello {
  string name = 1;
  int32 id = 2;
}
</file>

<file path="web/public/vite.svg">
<svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" role="img" class="iconify iconify--logos" width="31.88" height="32" preserveAspectRatio="xMidYMid meet" viewBox="0 0 256 257"><defs><linearGradient id="IconifyId1813088fe1fbc01fb466" x1="-.828%" x2="57.636%" y1="7.652%" y2="78.411%"><stop offset="0%" stop-color="#41D1FF"></stop><stop offset="100%" stop-color="#BD34FE"></stop></linearGradient><linearGradient id="IconifyId1813088fe1fbc01fb467" x1="43.376%" x2="50.316%" y1="2.242%" y2="89.03%"><stop offset="0%" stop-color="#FFEA83"></stop><stop offset="8.333%" stop-color="#FFDD35"></stop><stop offset="100%" stop-color="#FFA800"></stop></linearGradient></defs><path fill="url(#IconifyId1813088fe1fbc01fb466)" d="M255.153 37.938L134.897 252.976c-2.483 4.44-8.862 4.466-11.382.048L.875 37.958c-2.746-4.814 1.371-10.646 6.827-9.67l120.385 21.517a6.537 6.537 0 0 0 2.322-.004l117.867-21.483c5.438-.991 9.574 4.796 6.877 9.62Z"></path><path fill="url(#IconifyId1813088fe1fbc01fb467)" d="M185.432.063L96.44 17.501a3.268 3.268 0 0 0-2.634 3.014l-5.474 92.456a3.268 3.268 0 0 0 3.997 3.378l24.777-5.718c2.318-.535 4.413 1.507 3.936 3.838l-7.361 36.047c-.495 2.426 1.782 4.5 4.151 3.78l15.304-4.649c2.372-.72 4.652 1.36 4.15 3.788l-11.698 56.621c-.732 3.542 3.979 5.473 5.943 2.437l1.313-2.028l72.516-144.72c1.215-2.423-.88-5.186-3.54-4.672l-25.505 4.922c-2.396.462-4.435-1.77-3.759-4.114l16.646-57.705c.677-2.35-1.37-4.583-3.769-4.113Z"></path></svg>
</file>

<file path="web/src/api/insight.js">
import request from './request'

export function getAppStats(params) {
    return request({
        url: '/stats',
        method: 'get',
        params // { app_id, days }
    })
}

export function getLogList(params) {
    return request({
        url: '/logs',
        method: 'get',
        params // { page, page_size, app_id, status }
    })
}
</file>

<file path="web/src/api/request.js">
// src/api/request.js
import axios from 'axios'
import { useUserStore } from '../store/user'
import { Message } from '@arco-design/web-vue'

// åˆ›å»º axios å®ä¾‹
const service = axios.create({
    baseURL: 'http://localhost:8080/api/v1', // åç«¯åœ°å€
    timeout: 60000,
})

// request æ‹¦æˆªå™¨
service.interceptors.request.use(
    config => {
        // ä» localStorage è·å– token
        const token = localStorage.getItem('token')
        if (token) {
            // Go åç«¯é€šå¸¸æœŸæœ› Authorization: Bearer <token>
            config.headers['Authorization'] = `Bearer ${token}`
        }
        return config
    },
    error => {
        console.log(error)
        return Promise.reject(error)
    }
)

// response æ‹¦æˆªå™¨
service.interceptors.response.use(
    response => {
        const res = response.data
        // å‡è®¾ Go åç«¯è¿”å› { code: 200, data: ..., message: ... }
        // å¦‚æœ code ä¸æ˜¯ 200ï¼Œè§†ä¸ºé”™è¯¯ (æ ¹æ®ä½ çš„ Go é€»è¾‘è°ƒæ•´)
        return res
    },
    error => {
        console.log('err' + error)
        return Promise.reject(error)
    }
)

export default service
</file>

<file path="web/src/assets/vue.svg">
<svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" role="img" class="iconify iconify--logos" width="37.07" height="36" preserveAspectRatio="xMidYMid meet" viewBox="0 0 256 198"><path fill="#41B883" d="M204.8 0H256L128 220.8L0 0h97.92L128 51.2L157.44 0h47.36Z"></path><path fill="#41B883" d="m0 0l128 220.8L256 0h-51.2L128 132.48L50.56 0H0Z"></path><path fill="#35495E" d="M50.56 0L128 133.12L204.8 0h-47.36L128 51.2L97.92 0H50.56Z"></path></svg>
</file>

<file path="web/src/router/index.js">
import { createRouter, createWebHistory } from 'vue-router'
import Login from '../views/Login.vue'
import ChatHome from '../views/Home.vue' // åŸæ¥çš„ Home æ”¹åä¸º ChatHome
import AdminDashboard from '../views/AdminDashboard.vue' // æ–°å»ºç®¡ç†å‘˜é¡µé¢
import Register from '../views/Register.vue'
import Insights from '../views/Insights.vue'

const routes = [
    { path: '/login', component: Login },
    { path: '/register', component: Register },
    {
        path: '/',
        redirect: '/chat' // é»˜è®¤è·³å¯¹è¯
    },
    {
        path: '/chat',
        component: ChatHome,
        meta: { requiresAuth: true }
    },
    {
        path: '/admin',
        component: AdminDashboard,
        meta: { requiresAuth: true, requiresAdmin: true } // æ ‡è®°éœ€è¦ç®¡ç†å‘˜æƒé™
    },
    {
        path: '/admin/insights',
        component: Insights,
        meta: { requiresAuth: true } // å¦‚æœä½ çš„åå°æœ‰é‰´æƒ
    }
]

const router = createRouter({
    history: createWebHistory(),
    routes
})

// ç®€å•çš„è·¯ç”±å®ˆå«
router.beforeEach((to, from, next) => {
    const token = localStorage.getItem('token')
    if (to.meta.requiresAuth && !token) {
        next('/login')
    } else {
        next()
    }
})

export default router
</file>

<file path="web/src/store/user.js">
// src/store/user.js
import { defineStore } from 'pinia'
import { ref, computed } from 'vue'

export const useUserStore = defineStore('user', () => {
    // ===========================
    // 1. åŸºç¡€è®¤è¯æ•°æ® (Auth)
    // ===========================
    const token = ref(localStorage.getItem('token') || '')
    // ç”¨æˆ·ä¿¡æ¯ä¸­å¢åŠ  role å­—æ®µï¼š 'user' | 'admin'
    const userInfo = ref(JSON.parse(localStorage.getItem('userInfo') || '{}'))

    // ===========================
    // 2. ä¸šåŠ¡ä¸Šä¸‹æ–‡æ•°æ® (Context)
    // ===========================
    // é»˜è®¤è¿›å…¥ä¸ªäººç©ºé—´ (Org=0, KB=1)
    const currentOrgId = ref(parseInt(localStorage.getItem('current_org_id') || 0))
    const currentKbId = ref(parseInt(localStorage.getItem('current_kb_id') || 1))
    const currentOrgName = ref(localStorage.getItem('current_org_name') || 'ä¸ªäººç©ºé—´')

    // æ¨¡æ‹Ÿï¼šç”¨æˆ·å¯è®¿é—®çš„ç»„ç»‡åˆ—è¡¨ (å®é™…é¡¹ç›®åº”ä» userInfo æˆ– API è·å–)
    // è¿™é‡Œçš„æƒé™é€»è¾‘ï¼šAdmin å¯ä»¥ç®¡ç†æ‰€æœ‰ï¼ŒUser åªèƒ½çœ‹è‡ªå·±åŠ å…¥çš„
    const userOrgs = ref([
        { name: 'ğŸ‘¤ ä¸ªäººç©ºé—´', org_id: 0, kb_id: 1, role: 'owner' },
        { name: 'ğŸ¢ ç ”å‘éƒ¨', org_id: 101, kb_id: 2, role: 'member' },
        { name: 'ğŸ’° è´¢åŠ¡éƒ¨', org_id: 102, kb_id: 3, role: 'admin' } // å‡è®¾ç”¨æˆ·åœ¨è´¢åŠ¡éƒ¨æ˜¯ç®¡ç†å‘˜
    ])

    // ===========================
    // 3. åŠ¨ä½œ (Actions)
    // ===========================

    // A. ç™»å½•åŠ¨ä½œ (æ›´æ–° Auth + é‡ç½® Context)
    function login(newToken, newUser) {
        token.value = newToken
        userInfo.value = newUser

        // æŒä¹…åŒ–
        localStorage.setItem('token', newToken)
        localStorage.setItem('userInfo', JSON.stringify(newUser))
    }

    // B. ç™»å‡ºåŠ¨ä½œ
    function logout() {
        token.value = ''
        userInfo.value = {}
        currentOrgId.value = 0

        localStorage.clear() // ç®€å•ç²—æš´æ¸…ç©ºæ‰€æœ‰
        // æˆ–è€…é€ä¸ªç§»é™¤
        // localStorage.removeItem('token') ...
    }

    // C. åˆ‡æ¢ç»„ç»‡ä¸Šä¸‹æ–‡
    function setContext(org) {
        currentOrgId.value = org.org_id
        currentKbId.value = org.kb_id
        currentOrgName.value = org.name

        localStorage.setItem('current_org_id', org.org_id)
        localStorage.setItem('current_kb_id', org.kb_id)
        localStorage.setItem('current_org_name', org.name)
    }

    // ===========================
    // 4. è®¡ç®—å±æ€§ (Getters)
    // ===========================
    // åˆ¤æ–­å½“å‰æ˜¯å¦æ˜¯å¹³å°è¶…çº§ç®¡ç†å‘˜ (ä¸¾ä¾‹)
    const isPlatformAdmin = computed(() => userInfo.value.role === 'admin')

    return {
        token,
        userInfo,
        currentOrgId,
        currentKbId,
        currentOrgName,
        userOrgs,
        isPlatformAdmin,
        login,
        logout,
        setContext
    }
})
</file>

<file path="web/src/views/AdminDashboard.vue">
<template>
  <div class="admin-container">
    <div class="header">
      <h1>âš™ï¸ ç»„ç»‡ç®¡ç†åå°</h1>
      <div class="user-info">
        <span>å½“å‰èº«ä»½: {{ userStore.userInfo.role }}</span>
        <button @click="handleLogout" class="logout-btn">é€€å‡ºç™»å½•</button>
      </div>
    </div>

    <div class="content">
      <div class="card">
        <h3>ğŸ‘¥ æˆå‘˜ç®¡ç†</h3>
        <p>ç®¡ç†ç»„ç»‡ä¸‹çš„æˆå‘˜åŠæƒé™ (å¼€å‘ä¸­...)</p>
      </div>
      <div class="card">
        <h3>ğŸ“š çŸ¥è¯†åº“é…ç½®</h3>
        <p>å½“å‰ç»„ç»‡ KB ID: {{ userStore.currentKbId }}</p>
        <p>åœ¨è¿™é‡Œé…ç½® MinIO å­˜å‚¨ç­–ç•¥å’Œ Qdrant ç´¢å¼• (å¼€å‘ä¸­...)</p>
      </div>
      <div class="card">
        <h3>ğŸ“Š ç”¨é‡ç»Ÿè®¡</h3>
        <p>Token æ¶ˆè€—ä¸ API è°ƒç”¨æ¬¡æ•° (å¼€å‘ä¸­...)</p>
      </div>
    </div>
  </div>
</template>

<script setup>
import { useUserStore } from '../store/user'
import { useRouter } from 'vue-router'

const userStore = useUserStore()
const router = useRouter()

const handleLogout = () => {
  userStore.logout()
  router.push('/login')
}
</script>

<style scoped>
.admin-container { padding: 20px; background: #f0f2f5; min-height: 100vh; }
.header { display: flex; justify-content: space-between; align-items: center; margin-bottom: 30px; background: white; padding: 15px 20px; border-radius: 8px; }
.logout-btn { background: #ff4d4f; color: white; border: none; padding: 5px 15px; border-radius: 4px; margin-left: 10px; cursor: pointer; }
.content { display: grid; grid-template-columns: repeat(auto-fit, minmax(250px, 1fr)); gap: 20px; }
.card { background: white; padding: 20px; border-radius: 8px; box-shadow: 0 2px 8px rgba(0,0,0,0.05); }
h3 { margin-top: 0; color: #1890ff; }
</style>
</file>

<file path="web/src/views/Home.vue">
<template>
  <div class="home-container">
    <div class="sidebar">
      <div class="brand-area">
        <h2>Chimera RAG</h2>
        <span class="version-tag">v0.4.0 SaaS</span>
      </div>

      <div class="context-section">
        <label class="section-label">å½“å‰å·¥ä½œåŒº (Org)</label>
        <select
            :value="userStore.currentOrgId"
            @change="handleOrgChange"
            class="org-selector"
        >
          <option
              v-for="org in userStore.userOrgs"
              :key="org.org_id"
              :value="org.org_id"
          >
            {{ org.name }}
          </option>
        </select>

        <div class="debug-info">
          <small>Org ID: {{ userStore.currentOrgId }}</small>
          <small>KB ID: {{ userStore.currentKbId }}</small>
        </div>
      </div>

      <div class="divider"></div>

      <div class="upload-section">
        <label class="section-label">çŸ¥è¯†åº“å½•å…¥</label>
        <div class="file-drop-zone">
          <input type="file" ref="fileInput" @change="resetUploadStatus" />
        </div>

        <button
            @click="triggerUpload"
            :disabled="uploading || !fileInput?.files?.length"
            class="action-btn upload-btn"
            :class="{ 'processing': uploading }"
        >
          {{ uploading ? 'æ­£åœ¨è§£æ ETL...' : 'ä¸Šä¼ å¹¶å…¥åº“' }}
        </button>

        <div v-if="uploadStatus" :class="['status-msg', uploadStatusType]">
          {{ uploadStatus }}
        </div>
      </div>

      <div class="spacer"></div>

      <div class="user-profile">
        <div class="avatar">{{ userStore.userInfo.name?.[0]?.toUpperCase() || 'U' }}</div>
        <div class="info">
          <div class="username">{{ userStore.userInfo.name || 'User' }}</div>
          <button @click="handleLogout" class="logout-link">é€€å‡ºç™»å½•</button>
        </div>
      </div>
    </div>

    <div class="main-area">
      <header class="chat-header">
        <div class="header-content">
          <h3>{{ userStore.currentOrgName }} æ™ºèƒ½åŠ©æ‰‹</h3>
          <span class="status-badge online">åœ¨çº¿</span>
        </div>
        <button @click="clearHistory" class="clear-btn" title="æ¸…ç©ºå¯¹è¯">
          ğŸ—‘ï¸ æ¸…ç©ºè®°å½•
        </button>
      </header>

      <div class="messages-container" ref="chatContainer">
        <div v-if="messages.length === 0" class="empty-state">
          <p>ğŸ‘‹ æ¬¢è¿æ¥åˆ° <b>{{ userStore.currentOrgName }}</b></p>
          <p>è¯·ä¸Šä¼ æ–‡æ¡£ï¼Œæˆ–ç›´æ¥æé—®ã€‚</p>
        </div>

        <div
            v-for="(msg, index) in messages"
            :key="index"
            :class="['message-row', msg.role]"
        >
          <div class="avatar">
            {{ msg.role === 'user' ? 'ğŸ‘¤' : 'ğŸ¤–' }}
          </div>
          <div class="message-bubble">
            <div class="message-text">{{ msg.content }}</div>
            <span v-if="msg.role === 'ai' && msg.loading" class="typing-cursor">|</span>
          </div>
        </div>
      </div>

      <div class="input-section">
        <div class="input-wrapper">
          <input
              v-model="query"
              @keyup.enter="sendMessage"
              :placeholder="`å‘ ${userStore.currentOrgName} æé—®...`"
              :disabled="loading"
          />
          <button @click="sendMessage" :disabled="loading || !query.trim()">
            {{ loading ? '...' : 'å‘é€' }}
          </button>
        </div>
        <div class="footer-note">Chimera ç”Ÿæˆçš„å†…å®¹å¯èƒ½åŒ…å«å¹»è§‰ï¼Œè¯·ä»¥åŸæ–‡ä¸ºå‡†ã€‚</div>
      </div>
    </div>
  </div>
</template>

<script setup>
import { ref, reactive, nextTick, onMounted } from 'vue'
import { useRouter } from 'vue-router'
import { useUserStore } from '../store/user'
import request from '../api/request' // ç”¨äºä¸Šä¼  (Axios)

// 1. åˆå§‹åŒ–
const router = useRouter()
const userStore = useUserStore()
const chatContainer = ref(null)
const fileInput = ref(null)

// 2. å“åº”å¼çŠ¶æ€
const query = ref('')
const messages = reactive([])
const loading = ref(false)
const uploading = ref(false)
const uploadStatus = ref('')
const uploadStatusType = ref('info') // info, success, error

// 3. æ ¸å¿ƒåŠŸèƒ½ï¼šæ»šåŠ¨åˆ°åº•éƒ¨
const scrollToBottom = async () => {
  await nextTick()
  if (chatContainer.value) {
    chatContainer.value.scrollTop = chatContainer.value.scrollHeight
  }
}

// 4. æ ¸å¿ƒåŠŸèƒ½ï¼šåˆ‡æ¢ç»„ç»‡ (Context Switch)
const handleOrgChange = (e) => {
  const newOrgId = parseInt(e.target.value)
  const targetOrg = userStore.userOrgs.find(o => o.org_id === newOrgId)

  if (targetOrg) {
    // å…³é”®ï¼šæ›´æ–° Pinia çŠ¶æ€
    userStore.setContext(targetOrg)
    // å…³é”®ï¼šæ¸…ç©ºå½“å‰å¯¹è¯ï¼Œé˜²æ­¢æ•°æ®ä¸²å°
    clearHistory()
    resetUploadStatus()
  }
}

const clearHistory = () => {
  messages.splice(0, messages.length)
}

const handleLogout = () => {
  userStore.logout()
  router.push('/login')
}

// 5. æ ¸å¿ƒåŠŸèƒ½ï¼šä¸Šä¼ æ–‡ä»¶ (è°ƒç”¨ Go æ¥å£)
const resetUploadStatus = () => {
  uploadStatus.value = ''
  uploadStatusType.value = 'info'
}

const triggerUpload = async () => {
  const file = fileInput.value?.files[0]
  if (!file) return

  uploading.value = true
  uploadStatus.value = 'ğŸ“¤ æ­£åœ¨ä¸Šä¼ å¹¶è§¦å‘ ETL è§£æ...'
  uploadStatusType.value = 'info'

  const formData = new FormData()
  formData.append('file', file)
  // ğŸ”¥ å…³é”®ï¼šå¸¦ä¸Šå½“å‰çš„ KB IDï¼Œä¿è¯ä¼ åˆ°æ­£ç¡®çš„åº“
  formData.append('kb_id', userStore.currentKbId)

  try {
    // ä½¿ç”¨ axios å®ä¾‹ (src/api/request.js)
    const res = await request.post('/files/upload', formData, {
      headers: { 'Content-Type': 'multipart/form-data' }
    })

    uploadStatus.value = `âœ… ä¸Šä¼ æˆåŠŸ! æ–‡æ¡£ID: ${res.data.doc_id}ã€‚åå°æ­£åœ¨åˆ‡ç‰‡å…¥åº“...`
    uploadStatusType.value = 'success'
    fileInput.value.value = '' // æ¸…ç©º input
  } catch (e) {
    console.error(e)
    uploadStatus.value = `âŒ ä¸Šä¼ å¤±è´¥: ${e.response?.data?.msg || e.message}`
    uploadStatusType.value = 'error'
  } finally {
    uploading.value = false
  }
}

// 6. æ ¸å¿ƒåŠŸèƒ½ï¼šæµå¼å¯¹è¯ (è°ƒç”¨ Go -> Python)
// âš ï¸ è¿™é‡Œä½¿ç”¨åŸç”Ÿ fetchï¼Œå› ä¸º axios å¤„ç†æµæ¯”è¾ƒéº»çƒ¦
const sendMessage = async () => {
  if (!query.value.trim() || loading.value) return

  const userQ = query.value
  query.value = '' // æ¸…ç©ºè¾“å…¥æ¡†

  // æ·»åŠ ç”¨æˆ·æ¶ˆæ¯
  messages.push({ role: 'user', content: userQ })
  scrollToBottom()

  // æ·»åŠ  AI å ä½æ¶ˆæ¯
  const aiMsg = reactive({ role: 'ai', content: '', loading: true })
  messages.push(aiMsg)
  loading.value = true

  try {
    const response = await fetch('/api/v1/chat/completions', {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
        // ğŸ”¥ å…³é”®ï¼šæ‰‹åŠ¨æ·»åŠ  Tokenï¼Œå› ä¸ºåŸç”Ÿ fetch ä¸èµ° axios æ‹¦æˆªå™¨
        'Authorization': `Bearer ${userStore.token}`
      },
      body: JSON.stringify({
        query: userQ,
        kb_id: userStore.currentKbId,  // å¿…ä¼ ï¼šå½“å‰çŸ¥è¯†åº“ ID
        org_id: userStore.currentOrgId, // å¿…ä¼ ï¼šå½“å‰ç»„ç»‡ ID
        stream: true
      })
    })

    if (!response.ok) {
      throw new Error(`è¯·æ±‚å¤±è´¥: ${response.statusText}`)
    }

    // å¤„ç†æµå¼å“åº”
    const reader = response.body.getReader()
    const decoder = new TextDecoder('utf-8')

    while (true) {
      const { done, value } = await reader.read()
      if (done) break

      const chunk = decoder.decode(value, { stream: true })
      // ç®€å•æ‹¼æ¥ (å¦‚æœåç«¯è¿”å›çš„æ˜¯çº¯æ–‡æœ¬æµ)
      aiMsg.content += chunk
      scrollToBottom()
    }

  } catch (e) {
    aiMsg.content += `\n[ç³»ç»Ÿé”™è¯¯: ${e.message}]`
  } finally {
    aiMsg.loading = false
    loading.value = false
    scrollToBottom()
  }
}
</script>

<style scoped>
/* ================= å¸ƒå±€æ ·å¼ ================= */
.home-container {
  display: flex;
  height: 100vh;
  background-color: #f5f7fa;
  font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, "Helvetica Neue", Arial, sans-serif;
}

/* --- ä¾§è¾¹æ  --- */
.sidebar {
  width: 280px;
  background: #ffffff;
  border-right: 1px solid #e1e4e8;
  display: flex;
  flex-direction: column;
  padding: 20px;
  box-shadow: 2px 0 5px rgba(0,0,0,0.02);
}

.brand-area {
  margin-bottom: 25px;
  display: flex;
  align-items: center;
  gap: 10px;
}
.brand-area h2 { margin: 0; font-size: 20px; color: #1f2d3d; }
.version-tag { background: #e6f7ff; color: #1890ff; font-size: 10px; padding: 2px 6px; border-radius: 4px; }

.section-label {
  display: block;
  font-size: 12px;
  color: #8492a6;
  margin-bottom: 8px;
  font-weight: 600;
  text-transform: uppercase;
}

.org-selector {
  width: 100%;
  padding: 10px;
  border: 1px solid #dcdfe6;
  border-radius: 6px;
  background-color: #fff;
  font-size: 14px;
  margin-bottom: 5px;
  cursor: pointer;
}
.org-selector:focus { border-color: #1890ff; outline: none; }

.debug-info { font-size: 10px; color: #c0c4cc; display: flex; gap: 10px; margin-bottom: 20px; }

.divider { height: 1px; background: #ebeef5; margin: 10px 0 20px 0; }

.file-drop-zone input { width: 100%; font-size: 12px; }

.action-btn {
  width: 100%;
  padding: 10px;
  border: none;
  border-radius: 6px;
  font-weight: 500;
  cursor: pointer;
  transition: all 0.3s;
  margin-top: 10px;
}
.upload-btn { background: #1890ff; color: white; }
.upload-btn:hover { background: #40a9ff; }
.upload-btn:disabled { background: #a0cfff; cursor: not-allowed; }
.upload-btn.processing { cursor: wait; opacity: 0.8; }

.status-msg { font-size: 12px; margin-top: 10px; line-height: 1.4; padding: 8px; border-radius: 4px; }
.status-msg.info { color: #606266; background: #f4f4f5; }
.status-msg.success { color: #67c23a; background: #f0f9eb; }
.status-msg.error { color: #f56c6c; background: #fef0f0; }

.spacer { flex: 1; }

.user-profile {
  display: flex;
  align-items: center;
  gap: 10px;
  padding-top: 15px;
  border-top: 1px solid #ebeef5;
}
.user-profile .avatar {
  width: 36px; height: 36px;
  background: #7265e6; color: white;
  border-radius: 50%;
  display: flex; align-items: center; justify-content: center;
  font-weight: bold;
}
.user-profile .info { display: flex; flex-direction: column; }
.user-profile .username { font-weight: 600; font-size: 14px; color: #303133; }
.logout-link { border: none; background: none; color: #909399; font-size: 12px; cursor: pointer; padding: 0; text-align: left; }
.logout-link:hover { color: #f56c6c; }

/* --- ä¸»åŒºåŸŸ --- */
.main-area {
  flex: 1;
  display: flex;
  flex-direction: column;
  background: white;
}

.chat-header {
  height: 60px;
  border-bottom: 1px solid #e1e4e8;
  display: flex;
  justify-content: space-between;
  align-items: center;
  padding: 0 20px;
}
.chat-header h3 { margin: 0; font-size: 16px; font-weight: 600; }
.status-badge { font-size: 12px; margin-left: 8px; padding: 2px 6px; border-radius: 10px; }
.status-badge.online { background: #e1f3d8; color: #67c23a; }
.clear-btn { background: none; border: 1px solid #dcdfe6; padding: 5px 10px; border-radius: 4px; color: #606266; cursor: pointer; font-size: 12px; }
.clear-btn:hover { border-color: #f56c6c; color: #f56c6c; }

.messages-container {
  flex: 1;
  overflow-y: auto;
  padding: 20px;
  display: flex;
  flex-direction: column;
  gap: 20px;
  background: #f9fafc;
}

.empty-state { text-align: center; color: #909399; margin-top: 100px; }

.message-row { display: flex; gap: 12px; max-width: 80%; }
.message-row.user { align-self: flex-end; flex-direction: row-reverse; }
.message-row.ai { align-self: flex-start; }

.message-row .avatar {
  width: 32px; height: 32px;
  background: #fff; border: 1px solid #dcdfe6;
  border-radius: 50%;
  display: flex; align-items: center; justify-content: center;
  font-size: 18px;
  flex-shrink: 0;
}
.message-row.user .avatar { background: #d9ecff; border: none; }

.message-bubble {
  padding: 12px 16px;
  border-radius: 8px;
  font-size: 14px;
  line-height: 1.6;
  position: relative;
  box-shadow: 0 1px 2px rgba(0,0,0,0.05);
}
.message-row.user .message-bubble { background: #1890ff; color: white; border-top-right-radius: 2px; }
.message-row.ai .message-bubble { background: white; color: #303133; border: 1px solid #ebeef5; border-top-left-radius: 2px; }

.message-text { white-space: pre-wrap; /* å…³é”®ï¼šä¿ç•™æ¢è¡Œ */ word-break: break-word; }

.typing-cursor { display: inline-block; animation: blink 1s infinite; margin-left: 5px; font-weight: bold; }
@keyframes blink { 50% { opacity: 0; } }

.input-section { padding: 20px; border-top: 1px solid #e1e4e8; background: white; }
.input-wrapper { display: flex; gap: 10px; }
.input-wrapper input {
  flex: 1;
  padding: 12px;
  border: 1px solid #dcdfe6;
  border-radius: 6px;
  outline: none;
  font-size: 14px;
}
.input-wrapper input:focus { border-color: #1890ff; }
.input-wrapper button {
  padding: 0 25px;
  background: #1890ff;
  color: white;
  border: none;
  border-radius: 6px;
  font-weight: 600;
  cursor: pointer;
}
.input-wrapper button:disabled { background: #a0cfff; }

.footer-note { text-align: center; font-size: 11px; color: #c0c4cc; margin-top: 10px; }
</style>
</file>

<file path="web/src/views/Insights.vue">
<template>
  <div class="insight-container">
    <!-- 1. é¡¶éƒ¨æ  -->
    <div class="header-actions">
      <h2>ğŸ“Š ç›‘æ§ä¸­å° (Chimera Insight)</h2>
      <div class="filters">
        <a-select
            v-model="currentApp"
            style="width: 200px"
            placeholder="é€‰æ‹©åº”ç”¨"
            @change="handleAppChange"
        >
          <a-option
              v-for="opt in appOptions"
              :key="opt.value"
              :value="opt.value"
          >
            {{ opt.label }}
          </a-option>
        </a-select>
        <a-range-picker style="width: 250px" disabled /> <!-- é¢„ç•™ -->
        <a-button type="primary" @click="fetchData">åˆ·æ–°</a-button>
      </div>
    </div>

    <!-- 2. æ ¸å¿ƒæŒ‡æ ‡å¡ç‰‡ -->
    <a-grid :cols="4" :col-gap="16" class="stat-cards">
      <a-grid-item>
        <a-card hoverable>
          <a-statistic title="æ€» Token æ¶ˆè€—" :value="stats.total_tokens" show-group-separator>
            <template #prefix>ğŸª™</template>
          </a-statistic>
        </a-card>
      </a-grid-item>
      <a-grid-item>
        <a-card hoverable>
          <a-statistic title="æ€»è°ƒç”¨æ¬¡æ•°" :value="stats.total_calls" show-group-separator>
            <template #prefix>ğŸ¤–</template>
          </a-statistic>
        </a-card>
      </a-grid-item>
      <a-grid-item>
        <a-card hoverable>
          <a-statistic title="å¹³å‡è€—æ—¶ (ms)" :value="stats.avg_duration_ms" :precision="0">
            <template #prefix>â±ï¸</template>
            <template #suffix>ms</template>
          </a-statistic>
        </a-card>
      </a-grid-item>
      <a-grid-item>
        <a-card hoverable>
          <a-statistic title="æˆåŠŸç‡" :value="stats.success_rate" :precision="1">
            <template #prefix>âœ…</template>
            <template #suffix>%</template>
          </a-statistic>
        </a-card>
      </a-grid-item>
    </a-grid>

    <!-- 3. è¶‹åŠ¿å›¾è¡¨ -->
    <a-card class="chart-card" title="è¿‘ 7 å¤© Token æ¶ˆè€—è¶‹åŠ¿">
      <div style="height: 300px">
        <v-chart :option="chartOption" autoresize />
      </div>
    </a-card>

    <!-- 4. è¯¦ç»†æ—¥å¿—è¡¨æ ¼ -->
    <a-card class="table-card" title="è¿è¡Œæ—¥å¿— (Run History)">
      <a-table
          :data="logs"
          :pagination="pagination"
          @page-change="handlePageChange"
          :loading="loading"
      >
        <template #columns>
          <a-table-column title="æ—¶é—´" data-index="created_at">
            <template #cell="{ record }">
              {{ new Date(record.created_at).toLocaleString() }}
            </template>
          </a-table-column>
          <a-table-column title="ç”¨æˆ·" data-index="user" />
          <a-table-column title="Query" data-index="query" ellipsis tooltip />
          <a-table-column title="Tokens" data-index="total_tokens" />
          <a-table-column title="è€—æ—¶" data-index="duration_ms">
            <template #cell="{ record }">
              <a-tag :color="record.duration_ms > 5000 ? 'orange' : 'green'">
                {{ (record.duration_ms / 1000).toFixed(2) }}s
              </a-tag>
            </template>
          </a-table-column>
          <a-table-column title="çŠ¶æ€" data-index="status">
            <template #cell="{ record }">
              <a-badge :status="record.status === 'success' ? 'success' : 'danger'" :text="record.status" />
            </template>
          </a-table-column>
          <a-table-column title="æ“ä½œ">
            <template #cell="{ record }">
              <a-button size="mini" @click="viewDetail(record)">è¯¦æƒ…</a-button>
            </template>
          </a-table-column>
        </template>
      </a-table>
    </a-card>
    <!-- ğŸ”¥ æ–°å¢ï¼šè¯¦æƒ…æŠ½å±‰ -->
    <a-drawer
        :visible="drawerVisible"
        @ok="drawerVisible = false"
        @cancel="drawerVisible = false"
        width="600px"
        :footer="false"
    >
      <template #title>
        ğŸ” é“¾è·¯è¯¦æƒ… (Trace: {{ currentLog.trace_id || 'N/A' }})
      </template>

      <div v-if="currentLog" class="detail-content">
        <!-- 1. æ¦‚è§ˆä¿¡æ¯ -->
        <a-descriptions :column="2" bordered title="åŸºç¡€æŒ‡æ ‡">
          <a-descriptions-item label="ç”¨æˆ·">{{ currentLog.user }}</a-descriptions-item>
          <a-descriptions-item label="çŠ¶æ€">
            <a-tag :color="currentLog.status === 'success' ? 'green' : 'red'">
              {{ currentLog.status }}
            </a-tag>
          </a-descriptions-item>
          <a-descriptions-item label="æ€»è€—æ—¶">{{ currentLog.duration_ms }} ms</a-descriptions-item>
          <a-descriptions-item label="Token æ¶ˆè€—">{{ currentLog.total_tokens }}</a-descriptions-item>
        </a-descriptions>

        <a-divider />

        <!-- 2. å¯¹è¯è¿˜åŸ -->
        <h3>ğŸ—£ï¸ å¯¹è¯å¿«ç…§</h3>
        <div class="chat-snapshot">
          <div class="chat-bubble user">
            <div class="role-label">User</div>
            <div class="bubble-content">{{ currentLog.query }}</div>
          </div>
          <div class="chat-bubble ai">
            <div class="role-label">AI Agent</div>
            <div class="bubble-content">{{ currentLog.answer || '(æ— å›ç­”å†…å®¹)' }}</div>
          </div>
        </div>

        <a-divider />

        <!-- 3. æŠ€æœ¯ç»†èŠ‚ (JSON) -->
        <a-collapse>
          <a-collapse-item header="ğŸ› ï¸ åŸå§‹å…ƒæ•°æ® (Meta Info)" key="1">
            <pre class="json-box">{{ currentLog }}</pre>
          </a-collapse-item>
        </a-collapse>
      </div>
    </a-drawer>
  </div> <!-- ç»“æŸ div -->
</template>


<script setup>
import { ref, reactive, onMounted, computed } from 'vue'
import { getAppStats, getLogList } from '../api/insight'
// ECharts å¼•ç”¨ä¿æŒä¸å˜...
import VChart from 'vue-echarts'
import { use } from 'echarts/core'
import { CanvasRenderer } from 'echarts/renderers'
import { LineChart } from 'echarts/charts'
import { GridComponent, TooltipComponent, TitleComponent } from 'echarts/components'

use([CanvasRenderer, LineChart, GridComponent, TooltipComponent, TitleComponent])

// --- çŠ¶æ€å®šä¹‰ ---
const loading = ref(false)
const drawerVisible = ref(false)
const currentLog = ref({})

// 1. åº”ç”¨åˆ—è¡¨ (åŠ¨æ€åŒ–)
const currentApp = ref('default_chat_app')
const appOptions = ref([
  { label: 'é»˜è®¤å¯¹è¯åº”ç”¨', value: 'default_chat_app' },
  // å¯ä»¥åœ¨è¿™é‡Œæ‰©å±•ï¼Œæˆ–è€…ä»åç«¯ /api/v1/apps æ¥å£æ‹‰å–
])

// 2. æ ¸å¿ƒæŒ‡æ ‡ (åŠ¨æ€åŒ–)
const stats = reactive({
  total_tokens: 0,
  total_calls: 0,
  avg_duration_ms: 0,
  success_rate: 100 // ğŸ”¥ æ–°å¢
})

const logs = ref([])
const pagination = reactive({
  current: 1,
  pageSize: 10,
  total: 0
})

const chartOption = ref({})

// --- æ–¹æ³•å®šä¹‰ ---

// è·å–ç»¼åˆæ•°æ®
const fetchData = async () => {
  loading.value = true
  try {
    // A. è·å–ç»Ÿè®¡æ•°æ® (åç«¯è®¡ç®—)
    const statsRes = await getAppStats({ app_id: currentApp.value, days: 7 })
    const sData = statsRes.data || {} // é˜²ç©º

    stats.total_tokens = sData.total_tokens || 0
    stats.total_calls = sData.total_calls || 0
    stats.avg_duration_ms = sData.avg_duration_ms || 0

    // æ¸²æŸ“å›¾è¡¨
    renderChart(sData.daily_stats || [])

    // B. è·å–æ—¥å¿—åˆ—è¡¨
    const logRes = await getLogList({
      page: pagination.current,
      page_size: pagination.pageSize,
      app_id: currentApp.value
    })

    logs.value = logRes.data.list || []
    pagination.total = logRes.data.total || 0

    // ğŸ”¥ C. å‰ç«¯è®¡ç®—æˆåŠŸç‡ (åŸºäºå½“å‰åˆ—è¡¨æ ·æœ¬ï¼Œæ›´ç²¾ç¡®åšæ³•æ˜¯åç«¯æä¾›)
    if (logs.value.length > 0) {
      const successCount = logs.value.filter(l => l.status === 'success').length
      stats.success_rate = (successCount / logs.value.length) * 100
    } else {
      stats.success_rate = 100
    }

  } catch (e) {
    console.error("åŠ è½½æ•°æ®å¤±è´¥:", e)
  } finally {
    loading.value = false
  }
}

// æ¸²æŸ“å›¾è¡¨
const renderChart = (dailyData) => {
  const dates = dailyData.map(d => d.date)
  const tokens = dailyData.map(d => d.tokens)
  const calls = dailyData.map(d => d.calls) // ä¹Ÿå¯ä»¥ç”»è°ƒç”¨æ¬¡æ•°

  chartOption.value = {
    tooltip: {
      trigger: 'axis',
      formatter: '{b}<br/>Tokenæ¶ˆè€—: {c}'
    },
    grid: { left: '3%', right: '4%', bottom: '3%', containLabel: true },
    xAxis: { type: 'category', data: dates },
    yAxis: { type: 'value', name: 'Tokens' },
    series: [{
      name: 'Tokenæ¶ˆè€—',
      data: tokens,
      type: 'line',
      smooth: true,
      symbol: 'circle',
      symbolSize: 8,
      areaStyle: { opacity: 0.2 },
      itemStyle: { color: '#1890ff' },
      lineStyle: { width: 3 }
    }]
  }
}

const handlePageChange = (page) => {
  pagination.current = page
  fetchData()
}

// æŸ¥çœ‹è¯¦æƒ… (ä»è¡¨æ ¼è¡Œæ•°æ®ç›´æ¥è·å–ï¼Œåˆ©ç”¨ä¹‹å‰åç«¯è¡¥å…¨çš„ Answer å­—æ®µ)
const viewDetail = (record) => {
  currentLog.value = record
  drawerVisible.value = true
}

// æ ¼å¼åŒ–æ—¶é—´
const formatTime = (ts) => {
  if (!ts) return '-'
  return new Date(ts).toLocaleString()
}

// åˆ‡æ¢åº”ç”¨æ—¶åˆ·æ–°
const handleAppChange = () => {
  pagination.current = 1
  fetchData()
}

onMounted(() => {
  fetchData()
})
</script>

<style scoped>
.insight-container { padding: 20px; background: #f0f2f5; min-height: 100vh; }
.header-actions { display: flex; justify-content: space-between; align-items: center; margin-bottom: 20px; }
.filters { display: flex; gap: 10px; }
.stat-cards { margin-bottom: 20px; }
.chart-card { margin-bottom: 20px; }
.table-card { background: white; }
/* æ–°å¢è¯¦æƒ…é¡µæ ·å¼ */
.chat-snapshot {
  background: #f8f9fa;
  padding: 15px;
  border-radius: 8px;
}
.chat-bubble { margin-bottom: 15px; }
.role-label { font-size: 12px; color: #999; margin-bottom: 4px; }
.bubble-content {
  padding: 10px;
  border-radius: 6px;
  font-size: 14px;
  line-height: 1.5;
  white-space: pre-wrap;
}
.user .bubble-content { background: #e6f7ff; border: 1px solid #91d5ff; }
.ai .bubble-content { background: #fff; border: 1px solid #dcdfe6; }
.json-box { background: #2d2d2d; color: #ccc; padding: 10px; border-radius: 4px; overflow-x: auto; font-size: 12px; }
</style>
</file>

<file path="web/src/views/Login.vue">
<template>
  <div class="login-container">
    <div class="login-card">
      <h2>Chimera RAG</h2>
      <p class="subtitle">ä¼ä¸šçº§å¤šç§Ÿæˆ·çŸ¥è¯†åº“ç³»ç»Ÿ v0.4.0</p>

      <div class="form-item">
        <label>è´¦å·</label>
        <input v-model="form.username" placeholder="admin / user" />
      </div>

      <div class="form-item">
        <label>å¯†ç </label>
        <input v-model="form.password" type="password" />
      </div>

      <div class="role-selector">
        <label>ç™»å½•èº«ä»½ï¼š</label>
        <div class="radio-group">
          <label>
            <input type="radio" v-model="form.role" value="user" />
            æ™®é€šç”¨æˆ· (å¯¹è¯)
          </label>
          <label>
            <input type="radio" v-model="form.role" value="admin" />
            ç»„ç»‡ç®¡ç†å‘˜ (ç®¡ç†)
          </label>
        </div>
      </div>

      <button @click="handleLogin" :disabled="loading">
        {{ loading ? 'ç™»å½•ä¸­...' : 'ç™» å½•' }}
      </button>
      <div style="margin-top: 15px; text-align: center; font-size: 14px;">
        è¿˜æ²¡æœ‰è´¦å·ï¼Ÿ <router-link to="/register" style="color: #42b983;">ç«‹å³æ³¨å†Œ</router-link>
      </div>
    </div>
  </div>
</template>

<script setup>
import { reactive, ref } from 'vue'
import { useRouter } from 'vue-router'
import { useUserStore } from '../store/user'
import request from '../api/request' // ğŸ”¥ å¼•å…¥ axios å®ä¾‹

const router = useRouter()
const userStore = useUserStore()
const loading = ref(false)

const form = reactive({
  username: 'admin', // é»˜è®¤å¡«å¥½æ–¹ä¾¿æµ‹è¯•
  password: '123',
  role: 'user'
})

const handleLogin = async () => {
  if (!form.username || !form.password) {
    alert('è¯·è¾“å…¥è´¦å·å¯†ç ')
    return
  }

  loading.value = true

  try {
    // ğŸ”¥ 1. è°ƒç”¨çœŸå®åç«¯æ¥å£
    const res = await request.post('/auth/login', {
      username: form.username,
      password: form.password
    })

    // æ³¨æ„ï¼šæ ¹æ®ä½ çš„ Go AuthHandlerï¼Œè¿”å›ç»“æ„åº”è¯¥æ˜¯ { token: "...", username: "...", user_id: 1 }
    // å¦‚æœä½ çš„ request.js æ‹¦æˆªå™¨é‡Œæ²¡æœ‰å‰¥ç¦» data å±‚ï¼Œè¿™é‡Œå¯èƒ½éœ€è¦ res.data.token

    // å‡è®¾ request.js æ‹¦æˆªå™¨ç›´æ¥è¿”å›äº† response.data
    const token = res.token
    const user = {
      name: res.username,
      id: res.user_id,
      role: form.role // æš‚æ—¶å‰ç«¯é€ä¼ ï¼Œå®é™…ä¸Šåº”è¯¥è§£æ Token æˆ–ç”±åç«¯è¿”å›
    }

    // 2. å­˜å…¥ Pinia å’Œ LocalStorage
    userStore.login(token, user)

    // 3. è·³è½¬
    if (form.role === 'admin') {
      router.push('/admin/insights') // ç›´æ¥è·³åˆ°ç›‘æ§å°
    } else {
      router.push('/chat')
    }

  } catch (e) {
    console.error(e)
    alert('ç™»å½•å¤±è´¥: ' + (e.response?.data?.error || e.message))
  } finally {
    loading.value = false
  }
}
</script>

<style scoped>
.login-container { display: flex; justify-content: center; align-items: center; height: 100vh; background: #2c3e50; }
.login-card { width: 350px; background: white; padding: 30px; border-radius: 10px; box-shadow: 0 4px 20px rgba(0,0,0,0.2); }
h2 { text-align: center; margin-bottom: 5px; color: #333; }
.subtitle { text-align: center; color: #666; font-size: 0.9em; margin-bottom: 20px; }
.form-item { margin-bottom: 15px; }
.form-item label { display: block; margin-bottom: 5px; font-weight: bold; }
input[type="text"], input[type="password"] { width: 100%; padding: 10px; box-sizing: border-box; border: 1px solid #ddd; border-radius: 4px; }
.role-selector { margin-bottom: 20px; background: #f8f9fa; padding: 10px; border-radius: 4px; }
.radio-group { display: flex; gap: 15px; margin-top: 5px; }
button { width: 100%; padding: 12px; background: #42b983; color: white; border: none; border-radius: 4px; cursor: pointer; font-size: 16px; font-weight: bold; }
button:hover { background: #3aa876; }
</style>
</file>

<file path="web/src/views/Register.vue">
<template>
  <div class="register-container">
    <div class="register-card">
      <h2>ğŸ“ æ³¨å†Œæ–°è´¦å·</h2>
      <p class="subtitle">åŠ å…¥ Chimera RAG æ™ºèƒ½çŸ¥è¯†åº“</p>

      <div class="form-item">
        <label>ç”¨æˆ·å</label>
        <input v-model="form.username" placeholder="è¯·è¾“å…¥ç”¨æˆ·å" />
      </div>

      <div class="form-item">
        <label>é‚®ç®± (è´¦å·)</label>
        <input v-model="form.email" placeholder="user@example.com" />
      </div>

      <div class="form-item">
        <label>å¯†ç </label>
        <input v-model="form.password" type="password" placeholder="è®¾ç½®å¯†ç " />
      </div>

      <div class="form-item">
        <label>æ³¨å†Œè§’è‰²</label>
        <select v-model="form.role">
          <option value="user">æ™®é€šç”¨æˆ· (User)</option>
          <option value="admin">ç»„ç»‡ç®¡ç†å‘˜ (Admin)</option>
        </select>
      </div>

      <button @click="handleRegister" :disabled="loading" class="submit-btn">
        {{ loading ? 'æäº¤ä¸­...' : 'ç«‹å³æ³¨å†Œ' }}
      </button>

      <div class="footer-link">
        å·²æœ‰è´¦å·ï¼Ÿ <router-link to="/login">å»ç™»å½•</router-link>
      </div>
    </div>
  </div>
</template>

<script setup>
import { reactive, ref } from 'vue'
import { useRouter } from 'vue-router'
import request from '../api/request' // ä½¿ç”¨é…ç½®å¥½çš„ axios

const router = useRouter()
const loading = ref(false)

const form = reactive({
  username: '',
  email: '',
  password: '',
  role: 'user'
})

const handleRegister = async () => {
  // ç®€å•çš„éç©ºæ ¡éªŒ
  if (!form.username || !form.email || !form.password) {
    alert('è¯·å¡«å†™å®Œæ•´ä¿¡æ¯')
    return
  }

  loading.value = true
  try {
    // ğŸ”¥ è°ƒç”¨ Go åç«¯æ³¨å†Œæ¥å£
    // è¯·ç¡®è®¤ä½ çš„ Go è·¯ç”±æ˜¯ /auth/register è¿˜æ˜¯ /register
    await request.post('/auth/register', {
      username: form.username,
      email: form.email,
      password: form.password,
      role: form.role // å¦‚æœåç«¯æ”¯æŒç›´æ¥ä¼ è§’è‰²
    })

    alert('âœ… æ³¨å†ŒæˆåŠŸï¼è¯·ç™»å½•ã€‚')
    router.push('/login') // è·³è½¬å»ç™»å½•
  } catch (e) {
    console.error(e)
    alert('æ³¨å†Œå¤±è´¥: ' + (e.response?.data?.msg || e.message))
  } finally {
    loading.value = false
  }
}
</script>

<style scoped>
.register-container { display: flex; justify-content: center; align-items: center; height: 100vh; background: #2c3e50; }
.register-card { width: 350px; background: white; padding: 30px; border-radius: 10px; box-shadow: 0 4px 20px rgba(0,0,0,0.2); }
h2 { text-align: center; margin-bottom: 5px; color: #333; }
.subtitle { text-align: center; color: #666; font-size: 0.9em; margin-bottom: 20px; }
.form-item { margin-bottom: 15px; }
.form-item label { display: block; margin-bottom: 5px; font-weight: bold; font-size: 14px; }
input, select { width: 100%; padding: 10px; box-sizing: border-box; border: 1px solid #ddd; border-radius: 4px; }
.submit-btn { width: 100%; padding: 12px; background: #1890ff; color: white; border: none; border-radius: 4px; cursor: pointer; font-size: 16px; font-weight: bold; margin-top: 10px;}
.submit-btn:hover { background: #40a9ff; }
.footer-link { margin-top: 15px; text-align: center; font-size: 14px; }
.footer-link a { color: #1890ff; text-decoration: none; }
</style>
</file>

<file path="web/src/App.vue">
<template>
  <router-view />
</template>

<script setup>
// è¿™é‡Œé€šå¸¸ç•™ç©ºï¼Œæˆ–è€…æ”¾å…¨å±€é€»è¾‘
</script>

<style>
/* å…¨å±€é‡ç½®æ ·å¼ï¼Œå»æ‰æµè§ˆå™¨é»˜è®¤è¾¹è· */
body {
  margin: 0;
  padding: 0;
  font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, 'Helvetica Neue', Arial, sans-serif;
}
</style>
</file>

<file path="web/src/main.js">
// src/main.js
import { createApp } from 'vue'
import App from './App.vue'
import router from './router'
import { createPinia } from 'pinia'

// ğŸ”¥ 1. å¼•å…¥ Arco Design åŠå…¶æ ·å¼
import ArcoVue from '@arco-design/web-vue';
import '@arco-design/web-vue/dist/arco.css'; // åŠ¡å¿…å¼•å…¥ CSSï¼Œå¦åˆ™æ˜¯ä¸€å †ä¹±ç 

const app = createApp(App)

app.use(createPinia())
app.use(router)

// ğŸ”¥ 2. æŒ‚è½½ Arco
app.use(ArcoVue);

app.mount('#app')
</file>

<file path="web/.gitignore">
# Logs
logs
*.log
npm-debug.log*
yarn-debug.log*
yarn-error.log*
pnpm-debug.log*
lerna-debug.log*

node_modules
dist
dist-ssr
*.local

# Editor directories and files
.vscode/*
!.vscode/extensions.json
.idea
.DS_Store
*.suo
*.ntvs*
*.njsproj
*.sln
*.sw?
</file>

<file path="web/Dockerfile">
# Build Stage
FROM node:18-alpine AS builder

WORKDIR /app

# å®‰è£…ä¾èµ–
COPY package*.json ./
# æ·˜å®æºåŠ é€Ÿ (å¯é€‰)
# RUN npm config set registry https://registry.npmmirror.com
RUN npm install

# æ„å»º
COPY . .
RUN npm run build

# Production Stage
FROM nginx:alpine

# 1. å¤åˆ¶æ„å»ºäº§ç‰©
COPY --from=builder /app/dist /usr/share/nginx/html

# 2. å¤åˆ¶è‡ªå®šä¹‰ Nginx é…ç½®
COPY nginx.conf /etc/nginx/conf.d/default.conf

EXPOSE 80

CMD ["nginx", "-g", "daemon off;"]
</file>

<file path="web/index.html">
<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Chimera RAG</title>
</head>
<body>
<div id="app"></div>

<script type="module" src="/src/main.js"></script>
</body>
</html>
</file>

<file path="web/nginx.conf">
server {
    listen       80;
    server_name  localhost;

    # 1. å‰ç«¯é™æ€èµ„æº (Vue Build Output)
    location / {
        root   /usr/share/nginx/html;
        index  index.html index.htm;
        # ğŸ”¥ å…³é”®ï¼šæ”¯æŒ Vue Router History æ¨¡å¼
        # å¦‚æœæ‰¾ä¸åˆ°æ–‡ä»¶ï¼Œå°±å›é€€åˆ° index.htmlï¼Œè®©å‰ç«¯è·¯ç”±å¤„ç†
        try_files $uri $uri/ /index.html;
    }

    # 2. åç«¯æ¥å£è½¬å‘ (åå‘ä»£ç†)
    # å°† /api/v1/... è½¬å‘ç»™ Go å®¹å™¨
    location /api/ {
        # 'server' æ˜¯ docker-compose.yml ä¸­ Go æœåŠ¡çš„åå­—
        # 8080 æ˜¯ Go æœåŠ¡å†…éƒ¨æš´éœ²çš„ç«¯å£
        proxy_pass http://server:8080/api/;

        # ä¼ é€’çœŸå® IP å’Œå¤´ä¿¡æ¯
        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;

        # æ”¯æŒ SSE (æµå¼å¯¹è¯å…³é”®é…ç½®)
        proxy_buffering off;
        proxy_cache off;
        proxy_set_header Connection '';
        proxy_http_version 1.1;
        chunked_transfer_encoding on;
    }

    # é”™è¯¯é¡µé¢
    error_page   500 502 503 504  /50x.html;
    location = /50x.html {
        root   /usr/share/nginx/html;
    }
}
</file>

<file path="web/package.json">
{
  "name": "frontend-vue",
  "private": true,
  "version": "0.0.0",
  "type": "module",
  "scripts": {
    "dev": "vite",
    "build": "vite build",
    "preview": "vite preview"
  },
  "dependencies": {
    "@arco-design/web-vue": "^2.57.0",
    "@microsoft/fetch-event-source": "^2.0.1",
    "axios": "^1.13.2",
    "echarts": "^6.0.0",
    "markdown-it": "^14.1.0",
    "pinia": "^3.0.4",
    "vue": "^3.5.24",
    "vue-echarts": "^8.0.1",
    "vue-pdf-embed": "^2.1.3",
    "vue-router": "^4.6.4"
  },
  "devDependencies": {
    "@vitejs/plugin-vue": "^6.0.1",
    "vite": "npm:rolldown-vite@7.2.5"
  },
  "overrides": {
    "vite": "npm:rolldown-vite@7.2.5"
  }
}
</file>

<file path="web/README.md">
# Vue 3 + Vite

This template should help get you started developing with Vue 3 in Vite. The template uses Vue 3 `<script setup>` SFCs, check out the [script setup docs](https://v3.vuejs.org/api/sfc-script-setup.html#sfc-script-setup) to learn more.

Learn more about IDE Support for Vue in the [Vue Docs Scaling up Guide](https://vuejs.org/guide/scaling-up/tooling.html#ide-support).
</file>

<file path="web/vite.config.js">
import { defineConfig } from 'vite'
import vue from '@vitejs/plugin-vue'

export default defineConfig({
  plugins: [vue()],
  server: {
    // ç«¯å£å·å¯ä»¥å›ºå®šä¸€ä¸‹ï¼Œæ–¹ä¾¿è®°å¿†
    port: 3000,
    // ä»£ç†é…ç½®ï¼šè§£å†³è·¨åŸŸ
    proxy: {
      '/api': {
        target: 'http://localhost:8080', // æŒ‡å‘ä½ çš„ Go åç«¯
        changeOrigin: true,
        // rewrite: (path) => path.replace(/^\/api/, '') // ä½ çš„åç«¯è·¯ç”±æœ¬èº«å°±æœ‰ /apiï¼Œæ‰€ä»¥è¿™é‡Œä¸éœ€è¦ rewrite
      }
    }
  }
})
</file>

<file path="Makefile">
.PHONY: proto-go proto-py gen

# Go ä»£ç ç”Ÿæˆ
proto-go:
	@echo "ğŸš€ Generating Go Proto..."
	protoc --proto_path=. \
		--go_out=. --go_opt=module=Chimera \
		--go-grpc_out=. --go-grpc_opt=module=Chimera \
		api/runtime/v1/runtime.proto

# Python ä»£ç ç”Ÿæˆ
proto-py:
	@echo "ğŸš€ Generating Python Proto..."
	mkdir -p runtime/rpc
	# æ³¨æ„è¿™é‡Œ -I æŒ‡å‘äº† api/runtime/v1ï¼Œè¿™æ ·ç”Ÿæˆçš„æ–‡ä»¶å°±åœ¨æ ¹ç›®å½•ä¸‹
	python3 -m grpc_tools.protoc \
		-Iapi/runtime/v1 \
		--python_out=runtime/rpc \
		--grpc_python_out=runtime/rpc \
		runtime.proto
	# ä¿®å¤ Python ç›¸å¯¹å¯¼å…¥ (Mac syntax: sed -i '')
	sed -i '' 's/^import runtime_pb2/from . import runtime_pb2/' runtime/rpc/runtime_pb2_grpc.py
	# ç¡®ä¿æ˜¯ Python åŒ…
	touch runtime/rpc/__init__.py

# ä¸€é”®ç”Ÿæˆæ‰€æœ‰
gen: proto-go proto-py
	@echo "âœ… All Proto files generated successfully!"
</file>

<file path="docs/architecture/architecture_v0.6.0.md">
# ğŸŒŒ Chimera v0.6.0 æ¶æ„è®¾è®¡æ–¹æ¡ˆï¼šGraph-Native RAG

## 1. æ ¸å¿ƒè®¾è®¡å“²å­¦ (Design Philosophy)

æˆ‘ä»¬éœ€è¦æ‘’å¼ƒâ€œå›¾è°±åªæ˜¯å¤–æŒ‚â€çš„æƒ³æ³•ï¼Œè½¬å‘ **â€œç»“æ„-è¯­ä¹‰åŒèºæ—‹â€** æ¶æ„ã€‚
å‚è€ƒ **Cog-RAG** å’Œ **BookRAG**ï¼Œæˆ‘ä»¬å°†æ•°æ®åˆ†ä¸ºä¸¤å±‚ï¼š
1.  **è¯­ä¹‰å±‚ (Semantic Layer)**: ä¹Ÿå°±æ˜¯ Qdrant é‡Œçš„ Vector Chunksã€‚è´Ÿè´£â€œæ¨¡ç³ŠåŒ¹é…â€å’Œâ€œå¹¿åº¦å¬å›â€ã€‚
2.  **è®¤çŸ¥å±‚ (Cognitive Layer)**: ä¹Ÿå°±æ˜¯ NebulaGraph é‡Œçš„ Entities & Relationsã€‚è´Ÿè´£â€œç²¾ç¡®å¯¼èˆªâ€å’Œâ€œå¤šè·³æ¨ç†â€ã€‚

**v0.6.0 çš„å·®å¼‚åŒ–å–ç‚¹ï¼š**
*   **å¯è§£é‡Šæ€§**: ç”¨æˆ·ä¸ä»…èƒ½çœ‹åˆ°å¼•ç”¨çš„æ–‡æ¡£ç‰‡æ®µï¼Œè¿˜èƒ½çœ‹åˆ°ä¸€å¼ **æ€ç»´å¯¼å›¾ï¼ˆå­å›¾ï¼‰**ï¼Œæ˜¾ç¤º AI æ˜¯å¦‚ä½•ä»â€œAå®ä½“â€å…³è”åˆ°â€œBå®ä½“â€çš„ã€‚
*   **åŠ¨æ€æ€§**: ä¸åšé™æ€å›¾ï¼Œè€Œæ˜¯é€šè¿‡ LLM åœ¨ ETL é˜¶æ®µåŠ¨æ€æå–ï¼ˆProPEX æ€æƒ³ï¼‰ã€‚

---

## 2. æ•°æ®æ¨¡å‹è®¾è®¡ (Schema)

åœ¨ **NebulaGraph** ä¸­ï¼Œæˆ‘ä»¬éœ€è¦å®šä¹‰ä¸€å¥—é€šç”¨çš„ Schemaï¼Œæ—¢è¦ç®€å•åˆè¦èƒ½æ‰¿è½½å¤æ‚ä¸šåŠ¡ã€‚

### å›¾ç©ºé—´: `chimera_kb`

#### Tags (é¡¶ç‚¹ç±»å‹)
1.  **`Entity`** (å®ä½“)
    *   `name` (string): å®ä½“å (Primary Key, e.g., "DeepSeek")
    *   `type` (string): ç±»å‹ (e.g., "Model", "Organization")
    *   `desc` (string): æ‘˜è¦æè¿° (ç”¨äº disambiguation)
2.  **`Chunk`** (æ–‡æ¡£åˆ‡ç‰‡ - **å…³é”®ï¼å°†å›¾ä¸å‘é‡è”ç³»èµ·æ¥**)
    *   `chunk_id` (string): å¯¹åº” Qdrant é‡Œçš„ Point ID
    *   `source_id` (int): å¯¹åº” MySQL çš„ DataSource ID

#### Edge Types (è¾¹ç±»å‹)
1.  **`RELATION`** (å®ä½“é—´å…³ç³»)
    *   `desc` (string): å…³ç³»æè¿° (e.g., "developed_by", "competes_with")
    *   `weight` (double): æƒé‡
2.  **`MENTIONED_IN`** (å®ä½“å‡ºç°åœ¨æ–‡æ¡£ä¸­)
    *   **è¿™æ˜¯è¿æ¥ Cog-RAG â€œåŒè¶…å›¾â€æ¦‚å¿µçš„å…³é”®**ã€‚
    *   æ–¹å‘: `Entity` -> `Chunk`ã€‚è¡¨ç¤ºâ€œè¿™ä¸ªå®ä½“åœ¨è¿™ä¸ªåˆ‡ç‰‡é‡Œè¢«æåˆ°äº†â€ã€‚

---

## 3. é˜¶æ®µä¸€ï¼šå›¾è°±æ„å»ºæµæ°´çº¿ (Graph ETL)

å‚è€ƒ **ProPEX-RAG** å’Œ **TAdaRAG (Stage 1)**ï¼Œæˆ‘ä»¬ä¸ä½¿ç”¨ä¼ ç»Ÿçš„ BERT æ¨¡å‹åš NERï¼Œè€Œæ˜¯åˆ©ç”¨ **LLM (DeepSeek) + Prompt** è¿›è¡Œé«˜è´¨é‡æŠ½å–ã€‚

è¿™éƒ¨åˆ†é€»è¾‘å°†åœ¨ `runtime` ä¸­å®ç°ä¸€ä¸ªæ–°çš„ LangGraph å·¥ä½œæµï¼š`KGBuildWorkflow`ã€‚

### æµç¨‹æ­¥éª¤ï¼š
1.  **Chunking (ç°æœ‰)**: Docling è§£æ PDF å¾—åˆ°æ–‡æœ¬å—ã€‚
2.  **Extraction (æ–°å¢)**:
    *   å¯¹æ¯ä¸ª Chunkï¼Œå¹¶å‘è°ƒç”¨ LLMï¼ˆä½¿ç”¨ `ProPEX` é£æ ¼çš„ Promptï¼‰ã€‚
    *   **Prompt**: "ä»ä»¥ä¸‹æ–‡æœ¬ä¸­æå–å®ä½“å’Œå…³ç³»ï¼Œè¾“å‡º JSON æ ¼å¼ `[{head, relation, tail}, ...]`ã€‚æ³¨æ„ï¼šå¿½ç•¥é€šç”¨è¯æ±‡ã€‚"
3.  **Resolution (æ–°å¢ - å®ä½“å¯¹é½)**:
    *   **å±€éƒ¨å¯¹é½**: åœ¨å†…å­˜ä¸­åˆå¹¶åŒåå®ä½“ã€‚
    *   **åŒä¹‰è¯åˆå¹¶**: (v0.6.1è€ƒè™‘) ä½¿ç”¨ Embedding ç›¸ä¼¼åº¦åˆ¤æ–­ "LLM" å’Œ "Large Language Model" æ˜¯å¦ä¸ºä¸€ä¸ªç‚¹ã€‚
4.  **Ingestion (æ–°å¢)**:
    *   å†™å…¥ NebulaGraphï¼š
        *   `INSERT VERTEX Entity ...`
        *   `INSERT EDGE RELATION ...`
        *   **å…³é”®**: `INSERT EDGE MENTIONED_IN (Entity_ID -> Chunk_ID)`

---

## 4. é˜¶æ®µäºŒï¼šåŒè·¯æ£€ç´¢ä¸æ¨ç† (Inference)

å‚è€ƒ **HyperbolicRAG** å’Œ **Microsoft Azure RAG** çš„æœ€ä½³å®è·µï¼Œæˆ‘ä»¬é‡‡ç”¨ **â€œæ··åˆæ£€ç´¢ + åŠ¨æ€é‡æ’â€** ç­–ç•¥ã€‚

### è¿è¡Œæ—¶å·¥ä½œæµ (`workflows/graph_chat.py`):

#### Step 1: æ„å›¾åˆ†æä¸å…³é”®è¯æå– (Query Parsing)
*   LLM åˆ†æç”¨æˆ· Queryï¼Œæå–å‡º **Core Entities** (æ ¸å¿ƒå®ä½“)ã€‚
*   *ä¾‹å­*: ç”¨æˆ·é—® "DeepSeek å’Œ OpenAI çš„åŒºåˆ«ï¼Ÿ" -> æå– `["DeepSeek", "OpenAI"]`ã€‚

#### Step 2: åŒè·¯å¹¶å‘å¬å› (Parallel Retrieval)

*   **è·¯ A: å‘é‡æ£€ç´¢ (Vector Search)**
    *   ç”¨ Query Embedding å» Qdrant æœ Top-K Chunksã€‚
    *   *ç›®çš„*: å…œåº•ï¼Œé˜²æ­¢å›¾è°±é‡Œæ²¡æœ‰è¦†ç›–åˆ°çš„ç»†èŠ‚ã€‚

*   **è·¯ B: å›¾è°±éå† (Graph Traversal - Subgraph Retrieval)**
    *   **Anchor**: åœ¨ NebulaGraph ä¸­æ‰¾åˆ° `["DeepSeek", "OpenAI"]` è¿™ä¸¤ä¸ªèŠ‚ç‚¹ã€‚
    *   **Expansion (æ‰©æ•£)**: å‘å¤–è·³ 1~2 æ­¥ (1-2 hop)ï¼Œè·å–é‚»å±…èŠ‚ç‚¹å’Œå…³ç³»ã€‚
    *   **Pruning (å‰ªæ)**: ä½¿ç”¨ LLM æˆ– ç›¸ä¼¼åº¦ è¿‡æ»¤æ‰ä¸ç›¸å…³çš„é‚»å±…ï¼ˆæ¯”å¦‚è¿‡æ»¤æ‰æƒé‡ä½çš„è¾¹ï¼‰ã€‚
    *   **Linking**: é€šè¿‡ `MENTIONED_IN` è¾¹ï¼Œæ‰¾åˆ°è¿™äº›å®ä½“å…³è”çš„ `Chunk`ã€‚

#### Step 3: ä¸Šä¸‹æ–‡èåˆ (Context Fusion)
*   å°† **è·¯ A çš„æ–‡æœ¬** å’Œ **è·¯ B çš„ä¸‰å…ƒç»„/å…³ç³»æè¿°** æ‹¼æ¥åœ¨ä¸€èµ·ã€‚
*   **Prompt å¢å¼º**:
    ```text
    ã€çŸ¥è¯†å›¾è°±è·¯å¾„ã€‘:
    DeepSeek --(developed_by)--> High-Flyer
    DeepSeek --(competes_with)--> OpenAI
    
    ã€ç›¸å…³æ–‡æ¡£ç‰‡æ®µã€‘:
    ...
    ```

#### Step 4: ç­”æ¡ˆç”Ÿæˆä¸å¯è§†åŒ–æ•°æ®è¾“å‡º
*   LLM ç”Ÿæˆç­”æ¡ˆã€‚
*   **è§‚æµ‹æ€§ (æ ¸å¿ƒå–ç‚¹)**: å°† Step 2 ä¸­æ£€ç´¢åˆ°çš„ **å­å›¾ (Nodes + Edges)** åºåˆ—åŒ–ä¸º JSONï¼Œä¼ å›ç»™å‰ç«¯ã€‚å‰ç«¯ç”¨ D3.js æˆ– ECharts Graph æ¸²æŸ“å‡ºæ¥ï¼

---

## 5. å¼€å‘è®¡åˆ’ (Action Plan)

### åŸºç¡€è®¾æ–½ä¸ ETL (The Skeleton)
1.  **Nebula Store**: å®Œå–„ `core/stores/nebula_store.py`ï¼Œå®ç° `upsert_vertices`, `upsert_edges`ã€‚
2.  **Graph ETL Workflow**: å¼€å‘ `workflows/kg_builder.py`ï¼Œå®ç° LLM æŠ½å–é€»è¾‘ã€‚
3.  **Hook**: ä¿®æ”¹ `runtime_service.py` çš„ `SyncDataSource`ï¼Œåœ¨å†™å…¥ Qdrant çš„åŒæ—¶ï¼Œè§¦å‘ Graph ETLã€‚

### æ£€ç´¢é€»è¾‘ (The Brain)
1.  **Graph Search Skill**: åœ¨ `core/stores/nebula_store.py` ä¸­å®ç° `get_subgraph(entity_names, hops=2)`ã€‚
2.  **Hybrid Workflow**: åˆ›å»ºæ–°çš„ `GraphChatWorkflow`ï¼Œæ•´åˆ Vector + Graph æ£€ç´¢ç»“æœã€‚
3.  **Prompt Engineering**: è°ƒä¼˜å®ä½“æŠ½å–çš„ Promptï¼ˆå‚è€ƒ ProPEXï¼‰ï¼Œä¿è¯æŠ½å–å‡ºæ¥çš„å›¾è°±è´¨é‡ä¸è‡³äºå¤ªè„ã€‚

### å‰ç«¯å¯è§†åŒ– (The Face)
1.  **API å‡çº§**: ç¡®ä¿ `RunAgentResponse` çš„ `meta` æˆ– `payload` èƒ½æºå¸¦ `subgraph_json` æ•°æ®ã€‚
2.  **Vue ç»„ä»¶**: åœ¨ `Insights.vue` æˆ–èŠå¤©çª—å£ä¾§è¾¹æ ï¼Œå¢åŠ ä¸€ä¸ª **"çŸ¥è¯†ç½‘ç»œ"** é¢æ¿ï¼Œæ¸²æŸ“æœ¬æ¬¡å›ç­”ç”¨åˆ°çš„çŸ¥è¯†å›¾è°±ã€‚

---

## 6. ä»£ç é¢„è§ˆï¼šProPEX é£æ ¼çš„æŠ½å– Prompt

è¿™æ˜¯æˆ‘ä»¬å°†è¦ç”¨åœ¨ Python ç«¯çš„æ ¸å¿ƒ Prompt æ¨¡æ¿ï¼š

```yaml
# chimera-agents-runtime/prompts/extract_triplets.yaml
system: |
  ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„çŸ¥è¯†å›¾è°±æ„å»ºä¸“å®¶ã€‚ä½ çš„ä»»åŠ¡æ˜¯ä»ç»™å®šçš„æ–‡æœ¬ç‰‡æ®µä¸­æå–ç»“æ„åŒ–çš„çŸ¥è¯†ä¸‰å…ƒç»„ã€‚
  
  ã€æå–è§„åˆ™ã€‘ï¼š
  1. å®ä½“ (Nodes): è¯†åˆ«äººåã€ç»„ç»‡ã€æŠ€æœ¯æœ¯è¯­ã€åœ°ç‚¹ã€æ—¶é—´ç­‰å…³é”®æ¦‚å¿µã€‚
  2. å…³ç³» (Edges): è¯†åˆ«å®ä½“ä¹‹é—´æ˜ç¡®çš„åŠ¨ä½œæˆ–å±æ€§å…³è”ã€‚
  3. åŸå­æ€§: å®ä½“å’Œå…³ç³»åº”å°½å¯èƒ½ç®€æ´ï¼ˆå¦‚"è‹¹æœå…¬å¸"è€Œä¸æ˜¯"è‘—åçš„è‹¹æœå…¬å¸"ï¼‰ã€‚
  4. æ ¼å¼: è¾“å‡º JSON åˆ—è¡¨: [{"head": "å®ä½“A", "relation": "å…³ç³»", "tail": "å®ä½“B"}, ...]

  ã€å¾…å¤„ç†æ–‡æœ¬ã€‘:
  {{ text_chunk }}

  ã€è¾“å‡ºã€‘:
```

---
</file>

<file path=".gitignore">
# --- IDE & OS ---
.idea/
.vscode/
.DS_Store
*.swp

# --- Golang ---
/server/bin/
/server/vendor/
go.sum

# --- Python ---
__pycache__/
*.py[cod]
*$py.class
.venv/
env/
venv/
*.egg-info/

# --- Project Specific ---
# å¿½ç•¥ Docker æŒ‚è½½çš„æœ¬åœ°æ•°æ®ç›®å½•
/local_data/
# å¿½ç•¥ç¯å¢ƒå˜é‡æ–‡ä»¶
.env
*.pem

# --- Enterprise Edition (Closed Source) ---
# å¿½ç•¥ Go çš„ä¼ä¸šçº§ä»£ç 
server/enterprise/
server/cmd/server-ee/

# å¿½ç•¥ Python çš„ä¼ä¸šçº§ä»£ç  (ä¿ç•™ç›®å½•ç»“æ„ä»¥ä¾¿ importï¼Œä½†å¿½ç•¥å†…å®¹)
runtime/enterprise/core/connectors/*
!runtime/enterprise/core/connectors/__init__.py
runtime/enterprise/core/stores/*
!runtime/enterprise/core/stores/__init__.py
runtime/enterprise/workflows/*
!runtime/enterprise/workflows/__init__.py

# å¦‚æœä½ å¸Œæœ›å½»åº•å¿½ç•¥æ•´ä¸ªç›®å½•ï¼Œä¹Ÿå¯ä»¥ç›´æ¥å†™ï¼š
# runtime/enterprise/
# server/enterprise/
# ä½†ä¸Šé¢çš„å†™æ³•ä¿ç•™äº† __init__.pyï¼Œèƒ½é˜²æ­¢ Python æŠ¥é”™ "Module not found"

# å¿½ç•¥ Dockerfile çš„ä¼ä¸šç‰ˆæ„å»ºè„šæœ¬
Dockerfile.enterprise
docker-compose-ee.yml
</file>

<file path="LICENSE">
GNU AFFERO GENERAL PUBLIC LICENSE
                       Version 3, 19 November 2007

 Copyright (C) 2007 Free Software Foundation, Inc. <https://fsf.org/>
 Everyone is permitted to copy and distribute verbatim copies
 of this license document, but changing it is not allowed.

                            Preamble

  The GNU Affero General Public License is a free, copyleft license for
software and other kinds of works, specifically designed to ensure
cooperation with the community in the case of network server software.

  The licenses for most software and other practical works are designed
to take away your freedom to share and change the works.  By contrast,
our General Public Licenses are intended to guarantee your freedom to
share and change all versions of a program--to make sure it remains free
software for all its users.

  When we speak of free software, we are referring to freedom, not
price.  Our General Public Licenses are designed to make sure that you
have the freedom to distribute copies of free software (and charge for
them if you wish), that you receive source code or can get it if you
want it, that you can change the software or use pieces of it in new
free programs, and that you know you can do these things.

  Developers that use our General Public Licenses protect your rights
with two steps: (1) assert copyright on the software, and (2) offer
you this License which gives you legal permission to copy, distribute
and/or modify the software.

  A secondary benefit of defending all users' freedom is that
improvements made in alternate versions of the program, if they
receive widespread use, become available for other developers to
incorporate.  Many developers of free software are heartened and
encouraged by the resulting cooperation.  However, in the case of
software used on network servers, this result may fail to come about.
The GNU General Public License permits making a modified version and
letting the public access it on a server without ever releasing its
source code to the public.

  The GNU Affero General Public License is designed specifically to
ensure that, in such cases, the modified source code becomes available
to the community.  It requires the operator of a network server to
provide the source code of the modified version running there to the
users of that server.  Therefore, public use of a modified version, on
a publicly accessible server, gives the public access to the source
code of the modified version.

  An older license, called the Affero General Public License and
published by Affero, was designed to accomplish similar goals.  This is
a different license, not a version of the Affero GPL, but Affero has
released a new version of the Affero GPL which permits relicensing under
this license.

  The precise terms and conditions for copying, distribution and
modification follow.

                       TERMS AND CONDITIONS

  0. Definitions.

  "This License" refers to version 3 of the GNU Affero General Public License.

  "Copyright" also means copyright-like laws that apply to other kinds of
works, such as semiconductor masks.

  "The Program" refers to any copyrightable work licensed under this
License.  Each licensee is addressed as "you".  "Licensees" and
"recipients" may be individuals or organizations.

  To "modify" a work means to copy from or adapt all or part of the work
in a fashion requiring copyright permission, other than the making of an
exact copy.  The resulting work is called a "modified version" of the
earlier work or a work "based on" the earlier work.

  A "covered work" means either the unmodified Program or a work based
on the Program.

  To "propagate" a work means to do anything with it that, without
permission, would make you directly or secondarily liable for
infringement under applicable copyright law, except executing it on a
computer or modifying a private copy.  Propagation includes copying,
distribution (with or without modification), making available to the
public, and in some countries other activities as well.

  To "convey" a work means any kind of propagation that enables other
parties to make or receive copies.  Mere interaction with a user through
a computer network, with no transfer of a copy, is not conveying.

  An interactive user interface displays "Appropriate Legal Notices"
to the extent that it includes a convenient and prominently visible
feature that (1) displays an appropriate copyright notice, and (2)
tells the user that there is no warranty for the work (except to the
extent that warranties are provided), that licensees may convey the
work under this License, and how to view a copy of this License.  If
the interface presents a list of user commands or options, such as a
menu, a prominent item in the list meets this criterion.

  1. Source Code.

  The "source code" for a work means the preferred form of the work
for making modifications to it.  "Object code" means any non-source
form of a work.

  A "Standard Interface" means an interface that either is an official
standard defined by a recognized standards body, or, in the case of
interfaces specified for a particular programming language, one that
is widely used among developers working in that language.

  The "System Libraries" of an executable work include anything, other
than the work as a whole, that (a) is included in the normal form of
packaging a Major Component, but which is not part of that Major
Component, and (b) serves only to enable use of the work with that
Major Component, or to implement a Standard Interface for which an
implementation is available to the public in source code form.  A
"Major Component", in this context, means a major essential component
(kernel, window system, and so on) of the specific operating system
(if any) on which the executable work runs, or a compiler used to
produce the work, or an object code interpreter used to run it.

  The "Corresponding Source" for a work in object code form means all
the source code needed to generate, install, and (for an executable
work) run the object code and to modify the work, including scripts to
control those activities.  However, it does not include the work's
System Libraries, or general-purpose tools or generally available free
programs which are used unmodified in performing those activities but
which are not part of the work.  For example, Corresponding Source
includes interface definition files associated with source files for
the work, and the source code for shared libraries and dynamically
linked subprograms that the work is specifically designed to require,
such as by intimate data communication or control flow between those
subprograms and other parts of the work.

  The Corresponding Source need not include anything that users
can regenerate automatically from other parts of the Corresponding
Source.

  The Corresponding Source for a work in source code form is that
same work.

  2. Basic Permissions.

  All rights granted under this License are granted for the term of
copyright on the Program, and are irrevocable provided the stated
conditions are met.  This License explicitly affirms your unlimited
permission to run the unmodified Program.  The output from running a
covered work is covered by this License only if the output, given its
content, constitutes a covered work.  This License acknowledges your
rights of fair use or other equivalent, as provided by copyright law.

  You may make, run and propagate covered works that you do not
convey, without conditions so long as your license otherwise remains
in force.  You may convey covered works to others for the sole purpose
of having them make modifications exclusively for you, or provide you
with facilities for running those works, provided that you comply with
the terms of this License in conveying all material for which you do
not control copyright.  Those thus making or running the covered works
for you must do so exclusively on your behalf, under your direction
and control, on terms that prohibit them from making any copies of
your copyrighted material outside their relationship with you.

  Conveying under any other circumstances is permitted solely under
the conditions stated below.  Sublicensing is not allowed; section 10
makes it unnecessary.

  3. Protecting Users' Legal Rights From Anti-Circumvention Law.

  No covered work shall be deemed part of an effective technological
measure under any applicable law fulfilling obligations under article
11 of the WIPO copyright treaty adopted on 20 December 1996, or
similar laws prohibiting or restricting circumvention of such
measures.

  When you convey a covered work, you waive any legal power to forbid
circumvention of technological measures to the extent such circumvention
is effected by exercising rights under this License with respect to
the covered work, and you disclaim any intention to limit operation or
modification of the work as a means of enforcing, against the work's
users, your or third parties' legal rights to forbid circumvention of
technological measures.

  4. Conveying Verbatim Copies.

  You may convey verbatim copies of the Program's source code as you
receive it, in any medium, provided that you conspicuously and
appropriately publish on each copy an appropriate copyright notice;
keep intact all notices stating that this License and any
non-permissive terms added in accord with section 7 apply to the code;
keep intact all notices of the absence of any warranty; and give all
recipients a copy of this License along with the Program.

  You may charge any price or no price for each copy that you convey,
and you may offer support or warranty protection for a fee.

  5. Conveying Modified Source Versions.

  You may convey a work based on the Program, or the modifications to
produce it from the Program, in the form of source code under the
terms of section 4, provided that you also meet all of these conditions:

    a) The work must carry prominent notices stating that you modified
    it, and giving a relevant date.

    b) The work must carry prominent notices stating that it is
    released under this License and any conditions added under section
    7.  This requirement modifies the requirement in section 4 to
    "keep intact all notices".

    c) You must license the entire work, as a whole, under this
    License to anyone who comes into possession of a copy.  This
    License will therefore apply, along with any applicable section 7
    additional terms, to the whole of the work, and all its parts,
    regardless of how they are packaged.  This License gives no
    permission to license the work in any other way, but it does not
    invalidate such permission if you have separately received it.

    d) If the work has interactive user interfaces, each must display
    Appropriate Legal Notices; however, if the Program has interactive
    interfaces that do not display Appropriate Legal Notices, your
    work need not make them do so.

  A compilation of a covered work with other separate and independent
works, which are not by their nature extensions of the covered work,
and which are not combined with it such as to form a larger program,
in or on a volume of a storage or distribution medium, is called an
"aggregate" if the compilation and its resulting copyright are not
used to limit the access or legal rights of the compilation's users
beyond what the individual works permit.  Inclusion of a covered work
in an aggregate does not cause this License to apply to the other
parts of the aggregate.

  6. Conveying Non-Source Forms.

  You may convey a covered work in object code form under the terms
of sections 4 and 5, provided that you also convey the
machine-readable Corresponding Source under the terms of this License,
in one of these ways:

    a) Convey the object code in, or embodied in, a physical product
    (including a physical distribution medium), accompanied by the
    Corresponding Source fixed on a durable physical medium
    customarily used for software interchange.

    b) Convey the object code in, or embodied in, a physical product
    (including a physical distribution medium), accompanied by a
    written offer, valid for at least three years and valid for as
    long as you offer spare parts or customer support for that product
    model, to give anyone who possesses the object code either (1) a
    copy of the Corresponding Source for all the software in the
    product that is covered by this License, on a durable physical
    medium customarily used for software interchange, for a price no
    more than your reasonable cost of physically performing this
    conveying of source, or (2) access to copy the
    Corresponding Source from a network server at no charge.

    c) Convey individual copies of the object code with a copy of the
    written offer to provide the Corresponding Source.  This
    alternative is allowed only occasionally and noncommercially, and
    only if you received the object code with such an offer, in accord
    with subsection 6b.

    d) Convey the object code by offering access from a designated
    place (gratis or for a charge), and offer equivalent access to the
    Corresponding Source in the same way through the same place at no
    further charge.  You need not require recipients to copy the
    Corresponding Source along with the object code.  If the place to
    copy the object code is a network server, the Corresponding Source
    may be on a different server (operated by you or a third party)
    that supports equivalent copying facilities, provided you maintain
    clear directions next to the object code saying where to find the
    Corresponding Source.  Regardless of what server hosts the
    Corresponding Source, you remain obligated to ensure that it is
    available for as long as needed to satisfy these requirements.

    e) Convey the object code using peer-to-peer transmission, provided
    you inform other peers where the object code and Corresponding
    Source of the work are being offered to the general public at no
    charge under subsection 6d.

  A separable portion of the object code, whose source code is excluded
from the Corresponding Source as a System Library, need not be
included in conveying the object code work.

  A "User Product" is either (1) a "consumer product", which means any
tangible personal property which is normally used for personal, family,
or household purposes, or (2) anything designed or sold for incorporation
into a dwelling.  In determining whether a product is a consumer product,
doubtful cases shall be resolved in favor of coverage.  For a particular
product received by a particular user, "normally used" refers to a
typical or common use of that class of product, regardless of the status
of the particular user or of the way in which the particular user
actually uses, or expects or is expected to use, the product.  A product
is a consumer product regardless of whether the product has substantial
commercial, industrial or non-consumer uses, unless such uses represent
the only significant mode of use of the product.

  "Installation Information" for a User Product means any methods,
procedures, authorization keys, or other information required to install
and execute modified versions of a covered work in that User Product from
a modified version of its Corresponding Source.  The information must
suffice to ensure that the continued functioning of the modified object
code is in no case prevented or interfered with solely because
modification has been made.

  If you convey an object code work under this section in, or with, or
specifically for use in, a User Product, and the conveying occurs as
part of a transaction in which the right of possession and use of the
User Product is transferred to the recipient in perpetuity or for a
fixed term (regardless of how the transaction is characterized), the
Corresponding Source conveyed under this section must be accompanied
by the Installation Information.  But this requirement does not apply
if neither you nor any third party retains the ability to install
modified object code on the User Product (for example, the work has
been installed in ROM).

  The requirement to provide Installation Information does not include a
requirement to continue to provide support service, warranty, or updates
for a work that has been modified or installed by the recipient, or for
the User Product in which it has been modified or installed.  Access to a
network may be denied when the modification itself materially and
adversely affects the operation of the network or violates the rules and
protocols for communication across the network.

  Corresponding Source conveyed, and Installation Information provided,
in accord with this section must be in a format that is publicly
documented (and with an implementation available to the public in
source code form), and must require no special password or key for
unpacking, reading or copying.

  7. Additional Terms.

  "Additional permissions" are terms that supplement the terms of this
License by making exceptions from one or more of its conditions.
Additional permissions that are applicable to the entire Program shall
be treated as though they were included in this License, to the extent
that they are valid under applicable law.  If additional permissions
apply only to part of the Program, that part may be used separately
under those permissions, but the entire Program remains governed by
this License without regard to the additional permissions.

  When you convey a copy of a covered work, you may at your option
remove any additional permissions from that copy, or from any part of
it.  (Additional permissions may be written to require their own
removal in certain cases when you modify the work.)  You may place
additional permissions on material, added by you to a covered work,
for which you have or can give appropriate copyright permission.

  Notwithstanding any other provision of this License, for material you
add to a covered work, you may (if authorized by the copyright holders of
that material) supplement the terms of this License with terms:

    a) Disclaiming warranty or limiting liability differently from the
    terms of sections 15 and 16 of this License; or

    b) Requiring preservation of specified reasonable legal notices or
    author attributions in that material or in the Appropriate Legal
    Notices displayed by works containing it; or

    c) Prohibiting misrepresentation of the origin of that material, or
    requiring that modified versions of such material be marked in
    reasonable ways as different from the original version; or

    d) Limiting the use for publicity purposes of names of licensors or
    authors of the material; or

    e) Declining to grant rights under trademark law for use of some
    trade names, trademarks, or service marks; or

    f) Requiring indemnification of licensors and authors of that
    material by anyone who conveys the material (or modified versions of
    it) with contractual assumptions of liability to the recipient, for
    any liability that these contractual assumptions directly impose on
    those licensors and authors.

  All other non-permissive additional terms are considered "further
restrictions" within the meaning of section 10.  If the Program as you
received it, or any part of it, contains a notice stating that it is
governed by this License along with a term that is a further
restriction, you may remove that term.  If a license document contains
a further restriction but permits relicensing or conveying under this
License, you may add to a covered work material governed by the terms
of that license document, provided that the further restriction does
not survive such relicensing or conveying.

  If you add terms to a covered work in accord with this section, you
must place, in the relevant source files, a statement of the
additional terms that apply to those files, or a notice indicating
where to find the applicable terms.

  Additional terms, permissive or non-permissive, may be stated in the
form of a separately written license, or stated as exceptions;
the above requirements apply either way.

  8. Termination.

  You may not propagate or modify a covered work except as expressly
provided under this License.  Any attempt otherwise to propagate or
modify it is void, and will automatically terminate your rights under
this License (including any patent licenses granted under the third
paragraph of section 11).

  However, if you cease all violation of this License, then your
license from a particular copyright holder is reinstated (a)
provisionally, unless and until the copyright holder explicitly and
finally terminates your license, and (b) permanently, if the copyright
holder fails to notify you of the violation by some reasonable means
prior to 60 days after the cessation.

  Moreover, your license from a particular copyright holder is
reinstated permanently if the copyright holder notifies you of the
violation by some reasonable means, this is the first time you have
received notice of violation of this License (for any work) from that
copyright holder, and you cure the violation prior to 30 days after
your receipt of the notice.

  Termination of your rights under this section does not terminate the
licenses of parties who have received copies or rights from you under
this License.  If your rights have been terminated and not permanently
reinstated, you do not qualify to receive new licenses for the same
material under section 10.

  9. Acceptance Not Required for Having Copies.

  You are not required to accept this License in order to receive or
run a copy of the Program.  Ancillary propagation of a covered work
occurring solely as a consequence of using peer-to-peer transmission
to receive a copy likewise does not require acceptance.  However,
nothing other than this License grants you permission to propagate or
modify any covered work.  These actions infringe copyright if you do
not accept this License.  Therefore, by modifying or propagating a
covered work, you indicate your acceptance of this License to do so.

  10. Automatic Licensing of Downstream Recipients.

  Each time you convey a covered work, the recipient automatically
receives a license from the original licensors, to run, modify and
propagate that work, subject to this License.  You are not responsible
for enforcing compliance by third parties with this License.

  An "entity transaction" is a transaction transferring control of an
organization, or substantially all assets of one, or subdividing an
organization, or merging organizations.  If propagation of a covered
work results from an entity transaction, each party to that
transaction who receives a copy of the work also receives whatever
licenses to the work the party's predecessor in interest had or could
give under the previous paragraph, plus a right to possession of the
Corresponding Source of the work from the predecessor in interest, if
the predecessor has it or can get it with reasonable efforts.

  You may not impose any further restrictions on the exercise of the
rights granted or affirmed under this License.  For example, you may
not impose a license fee, royalty, or other charge for exercise of
rights granted under this License, and you may not initiate litigation
(including a cross-claim or counterclaim in a lawsuit) alleging that
any patent claim is infringed by making, using, selling, offering for
sale, or importing the Program or any portion of it.

  11. Patents.

  A "contributor" is a copyright holder who authorizes use under this
License of the Program or a work on which the Program is based.  The
work thus licensed is called the contributor's "contributor version".

  A contributor's "essential patent claims" are all patent claims
owned or controlled by the contributor, whether already acquired or
hereafter acquired, that would be infringed by some manner, permitted
by this License, of making, using, or selling its contributor version,
but do not include claims that would be infringed only as a
consequence of further modification of the contributor version.  For
purposes of this definition, "control" includes the right to grant
patent sublicenses in a manner consistent with the requirements of
this License.

  Each contributor grants you a non-exclusive, worldwide, royalty-free
patent license under the contributor's essential patent claims, to
make, use, sell, offer for sale, import and otherwise run, modify and
propagate the contents of its contributor version.

  In the following three paragraphs, a "patent license" is any express
agreement or commitment, however denominated, not to enforce a patent
(such as an express permission to practice a patent or covenant not to
sue for patent infringement).  To "grant" such a patent license to a
party means to make such an agreement or commitment not to enforce a
patent against the party.

  If you convey a covered work, knowingly relying on a patent license,
and the Corresponding Source of the work is not available for anyone
to copy, free of charge and under the terms of this License, through a
publicly available network server or other readily accessible means,
then you must either (1) cause the Corresponding Source to be so
available, or (2) arrange to deprive yourself of the benefit of the
patent license for this particular work, or (3) arrange, in a manner
consistent with the requirements of this License, to extend the patent
license to downstream recipients.  "Knowingly relying" means you have
actual knowledge that, but for the patent license, your conveying the
covered work in a country, or your recipient's use of the covered work
in a country, would infringe one or more identifiable patents in that
country that you have reason to believe are valid.

  If, pursuant to or in connection with a single transaction or
arrangement, you convey, or propagate by procuring conveyance of, a
covered work, and grant a patent license to some of the parties
receiving the covered work authorizing them to use, propagate, modify
or convey a specific copy of the covered work, then the patent license
you grant is automatically extended to all recipients of the covered
work and works based on it.

  A patent license is "discriminatory" if it does not include within
the scope of its coverage, prohibits the exercise of, or is
conditioned on the non-exercise of one or more of the rights that are
specifically granted under this License.  You may not convey a covered
work if you are a party to an arrangement with a third party that is
in the business of distributing software, under which you make payment
to the third party based on the extent of your activity of conveying
the work, and under which the third party grants, to any of the
parties who would receive the covered work from you, a discriminatory
patent license (a) in connection with copies of the covered work
conveyed by you (or copies made from those copies), or (b) primarily
for and in connection with specific products or compilations that
contain the covered work, unless you entered into that arrangement,
or that patent license was granted, prior to 28 March 2007.

  Nothing in this License shall be construed as excluding or limiting
any implied license or other defenses to infringement that may
otherwise be available to you under applicable patent law.

  12. No Surrender of Others' Freedom.

  If conditions are imposed on you (whether by court order, agreement or
otherwise) that contradict the conditions of this License, they do not
excuse you from the conditions of this License.  If you cannot convey a
covered work so as to satisfy simultaneously your obligations under this
License and any other pertinent obligations, then as a consequence you may
not convey it at all.  For example, if you agree to terms that obligate you
to collect a royalty for further conveying from those to whom you convey
the Program, the only way you could satisfy both those terms and this
License would be to refrain entirely from conveying the Program.

  13. Remote Network Interaction; Use with the GNU General Public License.

  Notwithstanding any other provision of this License, if you modify the
Program, your modified version must prominently offer all users
interacting with it remotely through a computer network (if your version
supports such interaction) an opportunity to receive the Corresponding
Source of your version by providing access to the Corresponding Source
from a network server at no charge, through some standard or customary
means of facilitating copying of software.  This Corresponding Source
shall include the Corresponding Source for any work covered by version 3
of the GNU General Public License that is incorporated pursuant to the
following paragraph.

  Notwithstanding any other provision of this License, you have
permission to link or combine any covered work with a work licensed
under version 3 of the GNU General Public License into a single
combined work, and to convey the resulting work.  The terms of this
License will continue to apply to the part which is the covered work,
but the work with which it is combined will remain governed by version
3 of the GNU General Public License.

  14. Revised Versions of this License.

  The Free Software Foundation may publish revised and/or new versions of
the GNU Affero General Public License from time to time.  Such new versions
will be similar in spirit to the present version, but may differ in detail to
address new problems or concerns.

  Each version is given a distinguishing version number.  If the
Program specifies that a certain numbered version of the GNU Affero General
Public License "or any later version" applies to it, you have the
option of following the terms and conditions either of that numbered
version or of any later version published by the Free Software
Foundation.  If the Program does not specify a version number of the
GNU Affero General Public License, you may choose any version ever published
by the Free Software Foundation.

  If the Program specifies that a proxy can decide which future
versions of the GNU Affero General Public License can be used, that proxy's
public statement of acceptance of a version permanently authorizes you
to choose that version for the Program.

  Later license versions may give you additional or different
permissions.  However, no additional obligations are imposed on any
author or copyright holder as a result of your choosing to follow a
later version.

  15. Disclaimer of Warranty.

  THERE IS NO WARRANTY FOR THE PROGRAM, TO THE EXTENT PERMITTED BY
APPLICABLE LAW.  EXCEPT WHEN OTHERWISE STATED IN WRITING THE COPYRIGHT
HOLDERS AND/OR OTHER PARTIES PROVIDE THE PROGRAM "AS IS" WITHOUT WARRANTY
OF ANY KIND, EITHER EXPRESSED OR IMPLIED, INCLUDING, BUT NOT LIMITED TO,
THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
PURPOSE.  THE ENTIRE RISK AS TO THE QUALITY AND PERFORMANCE OF THE PROGRAM
IS WITH YOU.  SHOULD THE PROGRAM PROVE DEFECTIVE, YOU ASSUME THE COST OF
ALL NECESSARY SERVICING, REPAIR OR CORRECTION.

  16. Limitation of Liability.

  IN NO EVENT UNLESS REQUIRED BY APPLICABLE LAW OR AGREED TO IN WRITING
WILL ANY COPYRIGHT HOLDER, OR ANY OTHER PARTY WHO MODIFIES AND/OR CONVEYS
THE PROGRAM AS PERMITTED ABOVE, BE LIABLE TO YOU FOR DAMAGES, INCLUDING ANY
GENERAL, SPECIAL, INCIDENTAL OR CONSEQUENTIAL DAMAGES ARISING OUT OF THE
USE OR INABILITY TO USE THE PROGRAM (INCLUDING BUT NOT LIMITED TO LOSS OF
DATA OR DATA BEING RENDERED INACCURATE OR LOSSES SUSTAINED BY YOU OR THIRD
PARTIES OR A FAILURE OF THE PROGRAM TO OPERATE WITH ANY OTHER PROGRAMS),
EVEN IF SUCH HOLDER OR OTHER PARTY HAS BEEN ADVISED OF THE POSSIBILITY OF
SUCH DAMAGES.

  17. Interpretation of Sections 15 and 16.

  If the disclaimer of warranty and limitation of liability provided
above cannot be given local legal effect according to their terms,
reviewing courts shall apply local law that most closely approximates
an absolute waiver of all civil liability in connection with the
Program, unless a warranty or assumption of liability accompanies a
copy of the Program in return for a fee.

                     END OF TERMS AND CONDITIONS

            How to Apply These Terms to Your New Programs

  If you develop a new program, and you want it to be of the greatest
possible use to the public, the best way to achieve this is to make it
free software which everyone can redistribute and change under these terms.

  To do so, attach the following notices to the program.  It is safest
to attach them to the start of each source file to most effectively
state the exclusion of warranty; and each file should have at least
the "copyright" line and a pointer to where the full notice is found.

    Chimera - The Observable AI Agent Platform. A dual-core (Go+Python) enterprise PaaS with full-stack observability and hot-pluggable agent capabilities.
    Copyright (C) 2025 stack-echo

    This program is free software: you can redistribute it and/or modify
    it under the terms of the GNU Affero General Public License as published
    by the Free Software Foundation, either version 3 of the License, or
    (at your option) any later version.

    This program is distributed in the hope that it will be useful,
    but WITHOUT ANY WARRANTY; without even the implied warranty of
    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
    GNU Affero General Public License for more details.

    You should have received a copy of the GNU Affero General Public License
    along with this program.  If not, see <https://www.gnu.org/licenses/>.

Also add information on how to contact you by electronic and paper mail.

  If your software can interact with users remotely through a computer
network, you should also make sure that it provides a way for users to
get its source.  For example, if your program is a web application, its
interface could display a "Source" link that leads users to an archive
of the code.  There are many ways you could offer source, and different
solutions will be better for different programs; see section 13 for the
specific requirements.

  You should also get your employer (if you work as a programmer) or school,
if any, to sign a "copyright disclaimer" for the program, if necessary.
For more information on this, and how to apply and follow the GNU AGPL, see
<https://www.gnu.org/licenses/>.
</file>

<file path="README_EN.md">
# ğŸ¦„ Chimera (v0.6.0)

> **The Observable AI Agent Platform.**
> **An Enterprise-grade PaaS for Multi-Agent Orchestration & RAG.**

[![License](https://img.shields.io/badge/license-AGPL%20v3-blue.svg)](LICENSE)
[![Go Report Card](https://goreportcard.com/badge/github.com/yourname/chimera)](https://goreportcard.com/report/github.com/yourname/chimera)
[![Python](https://img.shields.io/badge/python-3.10+-blue.svg)](https://www.python.org/)

[![English](https://img.shields.io/badge/-English-0077b5?style=for-the-badge)](README_EN.md)
[![ä¸­æ–‡](https://img.shields.io/badge/-ä¸­æ–‡-d52a1d?style=for-the-badge)](README.md)

**Chimera** is a dual-core AI infrastructure built on **Go (Control Plane)** and **Python (Inference Runtime)**. It decouples business logic from AI capabilities, providing full-stack observability from the API gateway down to LLM inference.

In **v0.6.0**, we have transitioned to an **Open Core Architecture**. This major refactoring decouples the core capabilities from enterprise-specific features, making Chimera both an out-of-the-box lightweight RAG system and a scalable PaaS platform for complex enterprise scenarios.

---

## âœ¨ v0.6.0 Highlights: The Architecture Shift

### ğŸ§¬ Open Core & Plugin Architecture
- **Decoupling**: Business logic and AI core are strictly separated. The Python Runtime introduces **Factory Patterns** and **Dynamic Loaders** to support "One Codebase, Two Modes".
- **Physical Isolation**: Enterprise-grade assets (e.g., Feishu/Lark integration, Knowledge Graph construction) are moved to the `enterprise/` directory, keeping the open-source repository clean.
- **Service Layering**: The Go server introduces `DataSourceService` and `ChatService`, combined with a `Registry` mechanism for non-intrusive feature injection.

### ğŸ”¬ Full-Stack Observability
- **White-Box Inference**: Trace the agent's "Thought Chain" in real-time.
- **Precise Metering**: Accurate token usage and latency statistics are collected in the Python Runtime and sent back to the Go Control Plane via gRPC for auditing.
- **Distributed Tracing**: Integrated with **OpenTelemetry (SigNoz)** for cross-language (Go -> Python) performance analysis.

### ğŸ§  Hybrid RAG
- **Vector Search (OSS)**: High-performance retrieval based on **Qdrant**.
- **GraphRAG (Enterprise)**: Knowledge Graph construction and retrieval based on **NebulaGraph**, designed for complex reasoning tasks.

---

## ğŸ› ï¸ Feature Matrix

| Feature | ğŸŸ¢ Community Edition (OSS) | ğŸ”µ Enterprise Edition (EE) |
| :--- | :--- | :--- |
| **Retrieval Model** | Vector Search (Qdrant) | **GraphRAG (Vector + Knowledge Graph)** |
| **Data Sources** | Local Files (PDF/Markdown) | **Feishu / DingTalk / Web Crawler** |
| **Doc Parsing** | Docling (OCR/Layout) | Docling + **Knowledge Extraction (NER/RE)** |
| **Deployment** | Single-node Docker Compose | **High Availability / K8s** |
| **Build System** | Standard Docker Images | **Layered Build (Core + Plugins)** |

---

## ğŸ—ï¸ Architecture & Directory

```text
Chimera/
â”œâ”€â”€ deploy/               # Docker Compose files (OSS & EE)
â”œâ”€â”€ server/               # [Go] Control Plane
â”‚   â”œâ”€â”€ cmd/
â”‚   â”‚   â”œâ”€â”€ server/       # ğŸŸ¢ OSS Entrypoint
â”‚   â”‚   â””â”€â”€ server-ee/    # ğŸ”µ Enterprise Entrypoint (Plugin Injection)
â”‚   â”œâ”€â”€ internal/core/    #    Interfaces & Registry
â”‚   â””â”€â”€ enterprise/       # ğŸ”’ Closed-source Business Logic
â”œâ”€â”€ runtime/              # [Python] Inference Runtime
â”‚   â”œâ”€â”€ core/
â”‚   â”‚   â”œâ”€â”€ managers/     #    Business Logic (ETL, Inference)
â”‚   â”‚   â””â”€â”€ connectors/   #    Base Connectors (File)
â”‚   â”œâ”€â”€ enterprise/       # ğŸ”’ Closed-source Plugins (Feishu, Nebula)
â”‚   â””â”€â”€ loader.py         #    Dynamic Plugin Loader
â””â”€â”€ web/                  # [Vue3] Frontend
```

---

## ğŸš€ Quick Start

### 1. Community Edition
Ideal for individual developers or small teams. Lightweight, no Graph Database required.

```bash
cd deploy
# Starts Postgres, Redis, MinIO, Qdrant, SigNoz, Server, Runtime
docker-compose up -d
```

### 2. Enterprise Edition
For environments requiring SaaS integrations or GraphRAG. (Requires `enterprise` source code).

```bash
cd deploy
# Starts full stack (includes NebulaGraph Cluster)
# Note: Automatically uses Dockerfile.ee to build images with enterprise code
docker-compose -f docker-compose-ee.yml up -d --build
```

---

## ğŸ’» Local Development Guide

### Python Runtime

```bash
cd runtime
# 1. Install dependencies
pip install -r requirements.txt

# 2. Start Service
# loader.py automatically detects if the 'enterprise' directory exists.
# If not found, it gracefully degrades to Core Mode.
python main.py
```
> **Note**: If you see `â„¹ï¸ No enterprise directory found`, you are running in Community Mode.

### Go Server

```bash
cd server
# 1. Install dependencies
go mod download

# 2. Start OSS Version (Clean Mode)
go run cmd/server/main.go

# 3. Start Enterprise Version (Injected Mode)
# Prerequisite: server/enterprise directory must exist
go run cmd/server-ee/main.go
```
> **Note**: Enterprise startup logs will show `ğŸ”“ [Enterprise] Loading Feishu Plugin...`.

---

## ğŸ“ˆ Roadmap

| Version | Milestone | Status |
| :--- | :--- | :--- |
| **v0.4.0** | Multi-tenancy & Isolation | âœ… |
| **v0.5.0** | Docling Integration & SigNoz Observability | âœ… |
| **v0.6.0** | **Commercial Refactoring (Current)** <br> - Open Core Architecture <br> - Pluggable Connectors & Stores <br> - Physical Code Isolation | ğŸ‰ |
| **v0.7.0** | **Memory & Permissions (Planning)** <br> - Redis Session (Long-term Memory) <br> - RBAC System | ğŸš§ |

## ğŸ“„ License

This project is licensed under the **GNU Affero General Public License v3.0 (AGPL v3)**.

*   **Allowed**: Free to use, modify, and learn.
*   **Obligation**: If you provide a service (SaaS) over a network using this software, you must make your modified source code available to users.
*   **Commercial License**: For closed-source commercial use or access to Enterprise Edition source code, please contact the author for authorization.

---

## ğŸ¤ Contribution

Issues and Pull Requests are welcome! For new data source connectors, please follow the interface defined in `core/connectors/base.py`.

*   **Core Features**: Submit to `server/internal` or `runtime/core`.
*   **New Plugins**: Please open an Issue for discussion first.
</file>

<file path="deploy/docker-compose.yml">
version: '3.8'

services:
  # =========================================
  # ğŸŸ¢ ä¸šåŠ¡åº”ç”¨å±‚ (OSS Core)
  # =========================================

  server:
    container_name: chimera_server_core
    build:
      context: ../server
      dockerfile: Dockerfile # ä½¿ç”¨å¼€æºç‰ˆæ„å»º
    restart: always
    ports:
      - "8080:8080"
    environment:
      # é€‚é… Go conf è¯»å–é€»è¾‘
      - DB_HOST=postgres
      - DB_USER=chimera_user
      - DB_PASSWORD=chimera_secret
      - DB_NAME=chimera_main
      - REDIS_HOST=redis
      - MINIO_ENDPOINT=minio:9000
      - MINIO_ACCESS_KEY=chimera_minio
      - MINIO_SECRET_KEY=chimera_minio_secret
      - AI_GRPC_HOST=runtime:50051
      - OTEL_ENDPOINT=signoz:4317
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_started
      minio:
        condition: service_started
    networks:
      - chimera_net

  runtime:
    container_name: chimera_runtime_core
    build:
      context: ../runtime
      dockerfile: Dockerfile # ä½¿ç”¨å¼€æºç‰ˆæ„å»º (.dockerignore æ’é™¤ enterprise)
    restart: always
    ports:
      - "50051:50051"
    environment:
      - PORT=50051
      - QDRANT_HOST=qdrant
      - QDRANT_PORT=6333
      - MINIO_ENDPOINT=minio:9000
      - MINIO_ACCESS_KEY=chimera_minio
      - MINIO_SECRET_KEY=chimera_minio_secret
      - OTEL_ENDPOINT=signoz:4317
      # ğŸ”¥ å…³é”®ï¼šä¸æ³¨å…¥ NEBULA_HOSTï¼Œè§¦å‘ä»£ç é™çº§ä¸ºçº¯å‘é‡æ¨¡å¼
      # - NEBULA_HOST=...
    volumes:
      - ../runtime/prompts:/app/prompts
    networks:
      - chimera_net

  web:
    container_name: chimera_web
    build:
      context: ../web
      dockerfile: Dockerfile
    restart: always
    ports:
      - "3000:80"
    depends_on:
      - server
    networks:
      - chimera_net

  # =========================================
  # ğŸ”µ åŸºç¡€è®¾æ–½å±‚ (Infrastructure Layer)
  # =========================================

  postgres:
    image: postgres:15-alpine
    container_name: chimera_postgres
    restart: always
    environment:
      POSTGRES_USER: chimera_user
      POSTGRES_PASSWORD: chimera_secret
      POSTGRES_DB: chimera_main
    ports:
      - "5432:5432"
    volumes:
      - ./local_data/postgres:/var/lib/postgresql/data
    networks:
      - chimera_net
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U chimera_user -d chimera_main"]
      interval: 5s
      timeout: 5s
      retries: 5

  redis:
    image: redis:alpine
    container_name: chimera_redis
    restart: always
    ports:
      - "6379:6379"
    command: redis-server --appendonly yes --requirepass chimera_secret
    volumes:
      - ./local_data/redis:/data
    networks:
      - chimera_net

  minio:
    image: minio/minio
    container_name: chimera_minio
    restart: always
    ports:
      - "9000:9000"
      - "9001:9001"
    environment:
      MINIO_ROOT_USER: chimera_minio
      MINIO_ROOT_PASSWORD: chimera_minio_secret
    command: server /data --console-address ":9001"
    volumes:
      - ./local_data/minio:/data
    networks:
      - chimera_net

  qdrant:
    image: qdrant/qdrant:latest
    container_name: chimera_qdrant
    restart: always
    ports:
      - "6333:6333"
      - "6334:6334"
    volumes:
      - ./local_data/qdrant:/qdrant/storage
    networks:
      - chimera_net

  signoz:
    image: signoz/signoz-otel-collector:latest
    container_name: chimera_signoz
    ports:
      - "4317:4317"
    networks:
      - chimera_net

networks:
  chimera_net:
    driver: bridge
</file>

<file path="go.mod">
module Chimera

go 1.24.0

toolchain go1.24.5

require (
	github.com/gin-contrib/cors v1.7.6
	github.com/gin-gonic/gin v1.11.0
	github.com/golang-jwt/jwt/v5 v5.3.0
	github.com/google/uuid v1.6.0
	github.com/minio/minio-go/v7 v7.0.97
	github.com/qdrant/go-client v1.16.2
	github.com/redis/go-redis/v9 v9.17.2
	github.com/spf13/viper v1.21.0
	golang.org/x/crypto v0.46.0
	google.golang.org/grpc v1.78.0
	google.golang.org/protobuf v1.36.11
	gorm.io/datatypes v1.2.7
	gorm.io/driver/postgres v1.6.0
	gorm.io/gorm v1.31.1
)

require (
	filippo.io/edwards25519 v1.1.0 // indirect
	github.com/bytedance/gopkg v0.1.3 // indirect
	github.com/bytedance/sonic v1.14.2 // indirect
	github.com/bytedance/sonic/loader v0.4.0 // indirect
	github.com/cespare/xxhash/v2 v2.3.0 // indirect
	github.com/cloudwego/base64x v0.1.6 // indirect
	github.com/dgryski/go-rendezvous v0.0.0-20200823014737-9f7001d12a5f // indirect
	github.com/dustin/go-humanize v1.0.1 // indirect
	github.com/fsnotify/fsnotify v1.9.0 // indirect
	github.com/gabriel-vasile/mimetype v1.4.12 // indirect
	github.com/gin-contrib/sse v1.1.0 // indirect
	github.com/go-ini/ini v1.67.0 // indirect
	github.com/go-playground/locales v0.14.1 // indirect
	github.com/go-playground/universal-translator v0.18.1 // indirect
	github.com/go-playground/validator/v10 v10.30.1 // indirect
	github.com/go-sql-driver/mysql v1.8.1 // indirect
	github.com/go-viper/mapstructure/v2 v2.4.0 // indirect
	github.com/goccy/go-json v0.10.5 // indirect
	github.com/goccy/go-yaml v1.19.1 // indirect
	github.com/jackc/pgpassfile v1.0.0 // indirect
	github.com/jackc/pgservicefile v0.0.0-20240606120523-5a60cdf6a761 // indirect
	github.com/jackc/pgx/v5 v5.7.6 // indirect
	github.com/jackc/puddle/v2 v2.2.2 // indirect
	github.com/jinzhu/inflection v1.0.0 // indirect
	github.com/jinzhu/now v1.1.5 // indirect
	github.com/json-iterator/go v1.1.12 // indirect
	github.com/klauspost/compress v1.18.2 // indirect
	github.com/klauspost/cpuid/v2 v2.3.0 // indirect
	github.com/klauspost/crc32 v1.3.0 // indirect
	github.com/leodido/go-urn v1.4.0 // indirect
	github.com/mattn/go-isatty v0.0.20 // indirect
	github.com/minio/crc64nvme v1.1.1 // indirect
	github.com/minio/md5-simd v1.1.2 // indirect
	github.com/modern-go/concurrent v0.0.0-20180306012644-bacd9c7ef1dd // indirect
	github.com/modern-go/reflect2 v1.0.2 // indirect
	github.com/pelletier/go-toml/v2 v2.2.4 // indirect
	github.com/philhofer/fwd v1.2.0 // indirect
	github.com/quic-go/qpack v0.6.0 // indirect
	github.com/quic-go/quic-go v0.58.0 // indirect
	github.com/rogpeppe/go-internal v1.14.1 // indirect
	github.com/rs/xid v1.6.0 // indirect
	github.com/sagikazarmark/locafero v0.11.0 // indirect
	github.com/sourcegraph/conc v0.3.1-0.20240121214520-5f936abd7ae8 // indirect
	github.com/spf13/afero v1.15.0 // indirect
	github.com/spf13/cast v1.10.0 // indirect
	github.com/spf13/pflag v1.0.10 // indirect
	github.com/subosito/gotenv v1.6.0 // indirect
	github.com/tinylib/msgp v1.6.1 // indirect
	github.com/twitchyliquid64/golang-asm v0.15.1 // indirect
	github.com/ugorji/go/codec v1.3.1 // indirect
	go.opentelemetry.io/otel v1.39.0 // indirect
	go.opentelemetry.io/otel/sdk/metric v1.39.0 // indirect
	go.uber.org/mock v0.6.0 // indirect
	go.yaml.in/yaml/v3 v3.0.4 // indirect
	golang.org/x/arch v0.23.0 // indirect
	golang.org/x/net v0.48.0 // indirect
	golang.org/x/sync v0.19.0 // indirect
	golang.org/x/sys v0.39.0 // indirect
	golang.org/x/text v0.32.0 // indirect
	google.golang.org/genproto/googleapis/rpc v0.0.0-20251222181119-0a764e51fe1b // indirect
	gopkg.in/yaml.v3 v3.0.1 // indirect
	gorm.io/driver/mysql v1.5.6 // indirect
)
</file>

<file path="README.md">
# ğŸ¦„ Chimera (v0.6.0)

> **The Observable AI Agent Platform.**
> **é¢å‘ä¼ä¸šçš„å¯è§‚æµ‹å¤šæ™ºèƒ½ä½“ PaaS å¹³å°ã€‚**

[![English](https://img.shields.io/badge/-English-0077b5?style=for-the-badge)](README_EN.md)
[![ä¸­æ–‡](https://img.shields.io/badge/-ä¸­æ–‡-d52a1d?style=for-the-badge)](README.md)


Chimera æ˜¯ä¸€ä¸ªåŸºäº **Go (Control Plane)** + **Python (Inference Runtime)** åŒæ ¸æ¶æ„çš„ä¼ä¸šçº§ AI åŸºç¡€è®¾æ–½ã€‚

åœ¨ **v0.6.0** ä¸­ï¼Œæˆ‘ä»¬å®Œæˆäº†**Open Coreï¼ˆæ ¸å¿ƒå¼€æºï¼‰** æ¶æ„é‡æ„ï¼Œå®ç°äº†æ ¸å¿ƒèƒ½åŠ›ä¸ä¼ä¸šçº§ç‰¹æ€§çš„è§£è€¦ã€‚ç°åœ¨ï¼ŒChimera æ—¢æ˜¯ä¸€ä¸ªå¼€ç®±å³ç”¨çš„è½»é‡çº§ RAG ç³»ç»Ÿï¼Œä¹Ÿæ˜¯ä¸€ä¸ªæ”¯æŒå¤æ‚ä¸šåŠ¡æ‰©å±•çš„ AI PaaS å¹³å°ã€‚

## âœ¨ v0.6.0 æ–°ç‰¹æ€§ï¼šæ¶æ„ç ´å±€

### ğŸ§¬ Open Core æ’ä»¶åŒ–æ¶æ„
- **æ ¸å¿ƒè§£è€¦**ï¼šå½»åº•å‰¥ç¦»äº†ä¸šåŠ¡é€»è¾‘ä¸ AI æ ¸å¿ƒã€‚Python è¿è¡Œæ—¶å¼•å…¥ **å·¥å‚æ¨¡å¼ (Factory)** ä¸ **åŠ¨æ€åŠ è½½å™¨ (Loader)**ï¼Œå®ç°â€œä¸€å¥—ä»£ç ï¼Œä¸¤ç§å½¢æ€â€ã€‚
- **ç‰©ç†éš”ç¦»**ï¼šä¼ä¸šçº§ä»£ç ï¼ˆå¦‚é£ä¹¦é›†æˆã€å›¾è°±æ„å»ºï¼‰ç§»å…¥ `enterprise/` ç›®å½•ï¼Œå¼€æºä»“åº“ä¿æŒçº¯å‡€ã€‚
- **Go æœåŠ¡åˆ†å±‚**ï¼šå¼•å…¥ `DataSourceService` ä¸ `ChatService`ï¼Œé…åˆ `Registry` æœºåˆ¶ï¼Œå®ç°æ— ä¾µå…¥å¼çš„åŠŸèƒ½æ³¨å…¥ã€‚

### ğŸ”¬ å…¨é“¾è·¯å¯è§‚æµ‹ (Observability)
- **ç™½ç›’åŒ–æ¨ç†**ï¼šå®æ—¶è¿½è¸ªæ™ºèƒ½ä½“çš„â€œæ€è€ƒè¿‡ç¨‹ (Thought Chain)â€ã€‚
- **ç²¾å‡†è®¡é‡**ï¼šPython è¿è¡Œæ—¶ç²¾ç¡®ç»Ÿè®¡ Token æ¶ˆè€—ä¸æ¨ç†è€—æ—¶ï¼Œé€šè¿‡ gRPC å›ä¼ è¿›è¡ŒæŒä¹…åŒ–å®¡è®¡ã€‚
- **åˆ†å¸ƒå¼è¿½è¸ª**ï¼šé›†æˆ **OpenTelemetry (SigNoz)**ï¼Œæä¾›è·¨è¯­è¨€ï¼ˆGo -> Pythonï¼‰çš„å‡½æ•°çº§æ€§èƒ½åˆ†æã€‚

### ğŸ§  æ··åˆå¢å¼ºæ£€ç´¢ (Hybrid RAG)
- **å‘é‡æ£€ç´¢ (OSS)**ï¼šåŸºäº **Qdrant** çš„é«˜æ€§èƒ½å‘é‡æœç´¢ã€‚
- **å›¾è°±å¢å¼º (Enterprise)**ï¼šåŸºäº **NebulaGraph** çš„çŸ¥è¯†å›¾è°±æ„å»ºä¸æ£€ç´¢ (GraphRAG)ï¼Œè§£å†³å¤æ‚æ¨ç†é—®é¢˜ã€‚

---

## ğŸ› ï¸ åŠŸèƒ½çŸ©é˜µ

| åŠŸèƒ½æ¨¡å— | ğŸŸ¢ å¼€æºç¤¾åŒºç‰ˆ (Community) | ğŸ”µ ä¼ä¸šå•†ç”¨ç‰ˆ (Enterprise) |
| :--- | :--- | :--- |
| **æ£€ç´¢æ¨¡å‹** | å‘é‡æ£€ç´¢ (Qdrant) | **GraphRAG (å‘é‡ + å›¾è°±)** |
| **æ•°æ®æº** | æœ¬åœ°æ–‡ä»¶ (PDF/Markdown) | **é£ä¹¦ / é’‰é’‰ / Web Crawler** |
| **æ–‡æ¡£è§£æ** | Docling (OCR/Layout) | Docling + **çŸ¥è¯†æŠ½å– (NER/RE)** |
| **éƒ¨ç½²æ¶æ„** | å•æœº Docker Compose | **é«˜å¯ç”¨é›†ç¾¤ / K8s** |
| **æ„å»ºä½“ç³»** | æ ‡å‡†é•œåƒ | **åˆ†å±‚æ„å»º (Core + Plugins)** |

---

## ğŸ—ï¸ ç›®å½•ç»“æ„

```text
Chimera/
â”œâ”€â”€ deploy/               # Docker ç¼–æ’æ–‡ä»¶ (OSS & EE)
â”œâ”€â”€ server/               # [Go] æ§åˆ¶é¢
â”‚   â”œâ”€â”€ cmd/
â”‚   â”‚   â”œâ”€â”€ server/       # ğŸŸ¢ å¼€æºç‰ˆå…¥å£
â”‚   â”‚   â””â”€â”€ server-ee/    # ğŸ”µ ä¼ä¸šç‰ˆå…¥å£ (æ³¨å…¥ Plugin)
â”‚   â”œâ”€â”€ internal/core/    #    æ¥å£å®šä¹‰ä¸æ³¨å†Œè¡¨
â”‚   â””â”€â”€ enterprise/       # ğŸ”’ é—­æºä¸šåŠ¡é€»è¾‘
â”œâ”€â”€ runtime/              # [Python] è®¡ç®—é¢
â”‚   â”œâ”€â”€ core/
â”‚   â”‚   â”œâ”€â”€ managers/     #    ä¸šåŠ¡é€»è¾‘ (ETL, Inference)
â”‚   â”‚   â””â”€â”€ connectors/   #    åŸºç¡€è¿æ¥å™¨ (File)
â”‚   â”œâ”€â”€ enterprise/       # ğŸ”’ é—­æºæ’ä»¶ (Feishu, Nebula, KG)
â”‚   â””â”€â”€ loader.py         #    åŠ¨æ€åŠ è½½å™¨
â””â”€â”€ web/                  # [Vue3] å‰ç«¯
```

---

## ğŸš€ å¿«é€Ÿå¼€å§‹

### 1. å¯åŠ¨å¼€æºç‰ˆ (Community Edition)

é€‚åˆä¸ªäººå¼€å‘è€…æˆ–å°å›¢é˜Ÿï¼Œè½»é‡çº§ï¼Œæ— éœ€å›¾æ•°æ®åº“ã€‚

```bash
cd deploy
# å¯åŠ¨ Postgres, Redis, MinIO, Qdrant, SigNoz, Server, Runtime
docker-compose up -d
```

### 2. å¯åŠ¨ä¼ä¸šç‰ˆ (Enterprise Edition)

é€‚åˆéœ€è¦é£ä¹¦é›†æˆæˆ–å›¾è°±å¢å¼ºçš„ä¼ä¸šç¯å¢ƒã€‚ï¼ˆéœ€æ‹¥æœ‰ `enterprise` æºç ç›®å½•ï¼‰

```bash
cd deploy
# å¯åŠ¨å…¨é‡æœåŠ¡ (åŒ…å« NebulaGraph é›†ç¾¤)
# æ³¨æ„ï¼šä¼šè‡ªåŠ¨ä½¿ç”¨ Dockerfile.ee æ„å»ºåŒ…å« enterprise ä»£ç çš„é•œåƒ
docker-compose -f docker-compose-ee.yml up -d --build
```

---

## ğŸ’» æœ¬åœ°å¼€å‘æŒ‡å—

å¦‚æœä½ éœ€è¦ä¿®æ”¹ä»£ç ï¼Œè¯·æŒ‰ç…§ä»¥ä¸‹æ–¹å¼å¯åŠ¨ã€‚

### Python Runtime

```bash
cd runtime
# 1. å®‰è£…ä¾èµ–
pip install -r requirements.txt

# 2. å¯åŠ¨æœåŠ¡
# loader.py ä¼šè‡ªåŠ¨æ£€æµ‹å½“å‰ç›®å½•ä¸‹æ˜¯å¦æœ‰ 'enterprise' æ–‡ä»¶å¤¹
# å¦‚æœæ²¡æœ‰ï¼Œè‡ªåŠ¨é™çº§ä¸º Core æ¨¡å¼
python main.py
```
> **æç¤º**: å¦‚æœçœ‹åˆ°æ—¥å¿— `â„¹ï¸ No enterprise directory found`ï¼Œè¯´æ˜è¿è¡Œåœ¨å¼€æºæ¨¡å¼ã€‚

### Go Server

```bash
cd server
# 1. å®‰è£…ä¾èµ–
go mod download

# 2. å¯åŠ¨å¼€æºç‰ˆ (çº¯å‡€æ¨¡å¼)
go run cmd/server/main.go

# 3. å¯åŠ¨ä¼ä¸šç‰ˆ (æ³¨å…¥æ¨¡å¼)
# å‰æï¼šserver/enterprise ç›®å½•å­˜åœ¨
go run cmd/server-ee/main.go
```
> **æç¤º**: ä¼ä¸šç‰ˆå¯åŠ¨æ—¶ä¼šæ‰“å° `ğŸ”“ [Enterprise] Loading Feishu Plugin...`ã€‚

---

## ğŸ“ˆ ç‰ˆæœ¬æ¼”è¿›

| ç‰ˆæœ¬ | é‡Œç¨‹ç¢‘                                                                          | çŠ¶æ€ |
| :--- |:-----------------------------------------------------------------------------| :--- |
| **v0.4.0** | å¤šç§Ÿæˆ·ä¸éš”ç¦»æ¶æ„                                                                     | âœ… |
| **v0.5.0** | å¼•å…¥å›¾è°±åŒè·¯å¬å›ä¸ SigNoz ç›‘æ§                                                          | âœ… |
| **v0.6.0** | **å•†ä¸šåŒ–æ¶æ„é‡æ„ (Current)** <br> - Open Core åŒæ ¸åˆ†ç¦» <br> - æ’ä»¶åŒ–è¿æ¥å™¨ä¸å­˜å‚¨ <br> - ç‰©ç†éš”ç¦»æ„å»ºä½“ç³» | ğŸ‰ |
| **v0.7.0** | **è®°å¿†ä¸æƒé™ (Planning)** <br> - Redis Session é•¿æœŸè®°å¿† <br> - RBAC æƒé™ä½“ç³»              | ğŸš§ |

## ğŸ“„ å¼€æºåè®® (License)

æœ¬é¡¹ç›®é‡‡ç”¨ **GNU Affero General Public License v3.0 (AGPL v3)** åè®®å¼€æºã€‚

*   **å…è®¸**: å…è´¹ä½¿ç”¨ã€ä¿®æ”¹ã€å­¦ä¹ ã€‚
*   **å¿…é¡»**: å¦‚æœæ‚¨åŸºäºæœ¬é¡¹ç›®é€šè¿‡ç½‘ç»œæä¾›æœåŠ¡ï¼ˆSaaSï¼‰ï¼Œå¿…é¡»å¼€æºæ‚¨çš„ä¿®æ”¹ä»£ç ã€‚
*   **å•†ä¸šæˆæƒ**: å¦‚éœ€é—­æºå•†ä¸šä½¿ç”¨æˆ–è·å–ä¼ä¸šç‰ˆæºç ï¼Œè¯·è”ç³»ä½œè€…è·å–æˆæƒã€‚

---

## ğŸ¤ è´¡çŒ®

æ¬¢è¿æäº¤ Issue å’Œ PRï¼å¯¹äºæ–°çš„æ•°æ®æºè¿æ¥å™¨ï¼Œè¯·éµå¾ª `core/connectors/base.py` ä¸­çš„æ¥å£è§„èŒƒã€‚

*   **æ ¸å¿ƒåŠŸèƒ½**: è¯·æäº¤è‡³ `server/internal` æˆ– `runtime/core`ã€‚
*   **æ–°æ’ä»¶**: å»ºè®®å…ˆæäº¤ Issue è®¨è®ºã€‚
</file>

</files>
